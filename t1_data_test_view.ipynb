{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dir = '/cwStorage/nodecw_group/jijh/hest_1k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(datasets.load_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "# 数据集脚本的本地路径\n",
    "dataset_script_path = '/cwStorage/nodecw_group/jijh/hest_1k/hest.py'\n",
    "\n",
    "# 本地数据集路径\n",
    "data_dir = '/cwStorage/nodecw_group/jijh/hest_1k'\n",
    "\n",
    "# 加载本地数据集脚本\n",
    "dataset = datasets.load_dataset(\n",
    "    dataset_script_path,\n",
    "    data_dir=data_dir,\n",
    "    name=\"custom_config\"  # 使用自定义配置名称\n",
    ")\n",
    "\n",
    "# 示例：查看数据集的训练集\n",
    "print(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home1/jijh/diffusion_project/ADiffusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "from src.pipeline.hest_loading import HESTDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设数据路径\n",
    "data_dir = \"/cwStorage/nodecw_group/jijh/hest_1k\"\n",
    "\n",
    "# 初始化数据集管理\n",
    "dataset = HESTDataset(data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.meta_df['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查询器官为 \"Brain\" 且疾病状态为 \"Healthy\" 的样本\n",
    "brain_samples = dataset.get_samples(\n",
    "    organ=\"Brain\", \n",
    "    oncotree_code=None,  # 根据需要填写\n",
    "    sample_ids=None,       # 根据需要填写\n",
    "    species='Mus musculus'          # 根据需要填写\n",
    ")\n",
    "\n",
    "print(f\"找到 {len(brain_samples)} 个样本。\")\n",
    "print(brain_samples[:3])  # 仅预览前三个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查询器官为 \"Brain\" 且疾病状态为 \"Healthy\" 的样本\n",
    "brain_samples = dataset.get_samples(\n",
    "    organ=\"Brain\", \n",
    "    oncotree_code=None,  # 根据需要填写\n",
    "    sample_ids=None       # 根据需要填写\n",
    ")\n",
    "\n",
    "print(f\"找到 {len(brain_samples)} 个样本。\")\n",
    "print(brain_samples[:3])  # 仅预览前三个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随便选一个样本\n",
    "sample = brain_samples[0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.load_st_data()\n",
    "sample.load_wsi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.wsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.spatial_plot_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- (1) 创建综合可视化图 ---\n",
    "# 默认使用预生成的空间转录组图像，如果没有则实时计算\n",
    "sample.visualize_comparison(\n",
    "    color='clusters',\n",
    "    use_precomputed_spatial_plot=True  # 可以手动切换到 False 以实时计算\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = brain_samples[1]\n",
    "test_sample.load_st_data()\n",
    "test_sample.load_wsi()\n",
    "test_sample.visualize_comparison(\n",
    "    color='clusters',\n",
    "    use_precomputed_spatial_plot=True  # 可以手动切换到 False 以实时计算\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.compute_metrics_statistics(samples=brain_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- (1) 创建综合可视化图 ---\n",
    "# 默认使用预生成的空间转录组图像，如果没有则实时计算\n",
    "sample.visualize_comparison(\n",
    "    color='clusters',\n",
    "    use_precomputed_spatial_plot=True  # 可以手动切换到 False 以实时计算\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Slide 使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sample.wsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print basic metadata\n",
    "slide = sample.wsi\n",
    "\n",
    "print(\"Dimensions (level 0):\", slide.dimensions)\n",
    "print(\"Number of levels:\", slide.level_count)\n",
    "print(\"Dimensions per level:\", slide.level_dimensions)\n",
    "print(\"Metadata properties:\")\n",
    "for key, value in slide.properties.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Define the region: top-left corner at (x, y), level number, and the size (width, height)\n",
    "location = (0, 0)  # top-left corner in level 0 coordinates\n",
    "level = 0          # highest resolution; use a higher level for a lower resolution\n",
    "size = (512, 512)  # size of the region to extract\n",
    "\n",
    "# Read the region; the result is a PIL Image\n",
    "region = slide.read_region(location, level, size)\n",
    "\n",
    "# Display the region (this will open the image in your default image viewer)\n",
    "region.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_downsample = 16.0  # e.g., you want a quarter of the full resolution\n",
    "best_level = slide.get_best_level_for_downsample(desired_downsample)\n",
    "print(\"Best level for a downsample of 16.0 is:\", best_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the desired level (e.g., level 2)\n",
    "target_level = 3\n",
    "\n",
    "# Get dimensions for the chosen level\n",
    "level_dimensions = slide.level_dimensions[target_level]\n",
    "\n",
    "# Extract the full image at the target level.\n",
    "# Note: location is (0, 0) in level 0 coordinates and size is in the units of the chosen level.\n",
    "region = slide.read_region((0, 0), target_level, level_dimensions)\n",
    "\n",
    "# Convert the image from RGBA to RGB (if transparency is not needed)\n",
    "region_rgb = region.convert(\"RGB\")\n",
    "\n",
    "# Display the image using the default image viewer (PIL's show method)\n",
    "region_rgb.show()\n",
    "\n",
    "# Always remember to close the slide after you are done\n",
    "slide.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 尝试切割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.adata.obsm['spatial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sample.adata.uns[\"spatial\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample.adata.uns[\"spatial\"]['ST']['images']['downscaled_fullres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "adata_test = sample.adata.to_memory().copy()\n",
    "sc.pl.spatial(adata_test, color='n_counts', spot_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_test.uns['spatial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(adata_test, color='n_counts', spot_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for extracting the tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import issparse\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import logging\n",
    "import seaborn as sns\n",
    "from scipy.spatial import cKDTree  # 用于计算最近邻距离\n",
    "\n",
    "# 配置 logging 模块，输出详细错误信息\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "\n",
    "def extract_tiles_and_expression(sample, \n",
    "                                 tile_size=None, \n",
    "                                 tile_size_strategy=\"median\",\n",
    "                                 tiles_output_dir=\"output_tiles\", \n",
    "                                 expr_output_dir=\"output_expr\",\n",
    "                                 max_workers=32):\n",
    "    \"\"\"\n",
    "    从 HESTSample 对象中提取瓦片和对应的表达量数据，并使用并发线程加速处理。\n",
    "    \n",
    "    瓦片大小的自动计算逻辑（基于临近 spot 的距离）：\n",
    "      - 若 tile_size 为 None，则根据 sample.adata.obs 中每个 spot 的 (pxl_col_in_fullres, pxl_row_in_fullres)\n",
    "        坐标构建 KD 树，并计算每个点到其最近邻（不包括自身）的欧氏距离。\n",
    "      - 用户可通过参数 tile_size_strategy 指定采用的统计量：\n",
    "          * \"min\"：所有最近邻距离的最小值；\n",
    "          * \"mean\"：所有最近邻距离的均值；\n",
    "          * \"median\"：所有最近邻距离的中位数（默认）；\n",
    "          * \"max\"：所有最近邻距离的最大值。\n",
    "      - 如果 tile_size 被指定，则直接使用固定值。\n",
    "    \n",
    "    瓦片边界处理策略：\n",
    "      - 对于每个 spot，以其坐标为中心、边长为 tile_size 构造正方形区域。\n",
    "      - 如果该区域部分在 WSI 范围内，则提取该部分有效区域，并粘贴到完整大小的白色背景上；\n",
    "      - 如果整个瓦片区域完全不在 WSI 范围内，则认为该点“出界”，不进行处理。\n",
    "    \n",
    "    参数:\n",
    "      sample (HESTSample): 包含空间转录组 AnnData 数据和全分辨率 WSI 的样本实例。\n",
    "      tile_size (int or None): 瓦片边长（单位像素）。为 None 时自动计算。\n",
    "      tile_size_strategy (str): 自动计算瓦片大小时采用的策略，可选 \"min\"、\"mean\"、\"median\"、\"max\"（默认 \"median\"）。\n",
    "      tiles_output_dir (str): 保存瓦片图像的目录。\n",
    "      expr_output_dir (str): 保存表达量数据 (.pt 文件) 的目录。\n",
    "      max_workers (int): 限制线程池的最大工作线程数，控制并发处理数量，避免内存占用过高。\n",
    "    \n",
    "    返回:\n",
    "      一个列表，每个元素为一个元组：(tile_filename, expr_filename, expr_vector)\n",
    "      \n",
    "    函数末尾会随机展示8个在范围内的瓦片及对应 spot 的 top5 基因表达的横向柱状图，\n",
    "    柱状图使用 seaborn 绘制，其画布与瓦片图像的子图大小一致。\n",
    "    \"\"\"\n",
    "    os.makedirs(tiles_output_dir, exist_ok=True)\n",
    "    os.makedirs(expr_output_dir, exist_ok=True)\n",
    "    \n",
    "    obs_df = sample.adata.obs\n",
    "\n",
    "    # 1. 检查坐标列是否存在。如果不存在，则使用 adata.obsm['spatial'] 作为坐标来源。\n",
    "    if 'pxl_col_in_fullres' not in obs_df.columns or 'pxl_row_in_fullres' not in obs_df.columns:\n",
    "        logging.info(\"Columns 'pxl_col_in_fullres' and/or 'pxl_row_in_fullres' not found in obs. Using adata.obsm['spatial'] as coordinates.\")\n",
    "        # 假设 adata.obsm['spatial'] 的第一列为 x 坐标，第二列为 y 坐标\n",
    "        obs_df['pxl_col_in_fullres'] = sample.adata.obsm['spatial'][:, 0]\n",
    "        obs_df['pxl_row_in_fullres'] = sample.adata.obsm['spatial'][:, 1]\n",
    "\n",
    "    # 2. 如果 tile_size 为 None，则自动计算\n",
    "    if tile_size is None:\n",
    "        points = np.column_stack((obs_df['pxl_col_in_fullres'], obs_df['pxl_row_in_fullres']))\n",
    "        tree = cKDTree(points)\n",
    "        dists, _ = tree.query(points, k=2)\n",
    "        nn_dists = dists[:, 1]  # 排除自身的最近邻距离\n",
    "        if tile_size_strategy == \"min\":\n",
    "            tile_size = int(round(np.min(nn_dists)))\n",
    "        elif tile_size_strategy == \"mean\":\n",
    "            tile_size = int(round(np.mean(nn_dists)))\n",
    "        elif tile_size_strategy == \"max\":\n",
    "            tile_size = int(round(np.max(nn_dists)))\n",
    "        else:  # 默认 \"median\"\n",
    "            tile_size = int(round(np.median(nn_dists)))\n",
    "        logging.info(f\"自动计算瓦片大小：{tile_size} 像素 (策略: {tile_size_strategy})\")\n",
    "    \n",
    "    X = sample.adata.X\n",
    "    full_width, full_height = sample.wsi.dimensions\n",
    "\n",
    "    valid_spots = []\n",
    "    out_of_bound_spots = []\n",
    "    for i in range(obs_df.shape[0]):\n",
    "        spot = obs_df.iloc[i]\n",
    "        col_coord = int(round(spot['pxl_col_in_fullres']))\n",
    "        row_coord = int(round(spot['pxl_row_in_fullres']))\n",
    "        half_tile = tile_size // 2\n",
    "        top_left_x = col_coord - half_tile\n",
    "        top_left_y = row_coord - half_tile\n",
    "        # 判断是否完全出界：右边界 ≤ 0 或 下边界 ≤ 0 或 左边界 ≥ full_width 或 上边界 ≥ full_height\n",
    "        if (top_left_x + tile_size) <= 0 or (top_left_y + tile_size) <= 0 or \\\n",
    "           top_left_x >= full_width or top_left_y >= full_height:\n",
    "            out_of_bound_spots.append((i, col_coord, row_coord, top_left_x, top_left_y))\n",
    "        else:\n",
    "            valid_spots.append((i, col_coord, row_coord, top_left_x, top_left_y))\n",
    "    \n",
    "    logging.info(f\"完全出界的点数：{len(out_of_bound_spots)}\")\n",
    "    \n",
    "    # 随机展示最多 8 个出界的瓦片以供检查\n",
    "    if out_of_bound_spots:\n",
    "        sample_indices = random.sample(out_of_bound_spots, min(8, len(out_of_bound_spots)))\n",
    "        fig, axes = plt.subplots(1, len(sample_indices), figsize=(16, 2))\n",
    "        if len(sample_indices) == 1:\n",
    "            axes = [axes]\n",
    "        for ax, (i, col_coord, row_coord, top_left_x, top_left_y) in zip(axes, sample_indices):\n",
    "            img = Image.new(\"RGB\", (tile_size, tile_size), (255, 255, 255))\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            draw.text((10, tile_size//2 - 10), \"Out-of-bound\", fill=(255, 0, 0))\n",
    "            ax.imshow(img)\n",
    "            ax.axis(\"off\")\n",
    "            ax.set_title(f\"Idx {i}\\n({col_coord}, {row_coord})\", fontsize=8)\n",
    "        plt.show()\n",
    "    \n",
    "    def process_tile(args):\n",
    "        i, col_coord, row_coord, top_left_x, top_left_y = args\n",
    "        # 构造文件名\n",
    "        tile_filename = os.path.join(tiles_output_dir, f\"{sample.sample_id}_{row_coord}_{col_coord}.png\")\n",
    "        expr_filename = os.path.join(expr_output_dir, f\"{sample.sample_id}_{row_coord}_{col_coord}.pt\")\n",
    "        \n",
    "        # 3. 如果文件已存在，则跳过当前 spot 的处理\n",
    "        if os.path.exists(tile_filename) and os.path.exists(expr_filename):\n",
    "            logging.info(f\"文件已存在，跳过: {tile_filename} 和 {expr_filename}\")\n",
    "            expr_vector = X[i, :]\n",
    "            if issparse(expr_vector):\n",
    "                expr_vector = expr_vector.toarray().squeeze()\n",
    "            else:\n",
    "                expr_vector = np.array(expr_vector).squeeze()\n",
    "            return (tile_filename, expr_filename, expr_vector)\n",
    "        \n",
    "        left = max(top_left_x, 0)\n",
    "        top = max(top_left_y, 0)\n",
    "        right = min(top_left_x + tile_size, full_width)\n",
    "        bottom = min(top_left_y + tile_size, full_height)\n",
    "        try:\n",
    "            region = sample.wsi.read_region((left, top), 0, (right - left, bottom - top))\n",
    "            region = region.convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            logging.error(\n",
    "                f\"瓦片提取失败，索引 {i}，中心坐标 ({col_coord}, {row_coord})，\"\n",
    "                f\"瓦片左上角 ({top_left_x}, {top_left_y})。异常类型：{type(e).__name__}，错误信息：{e}\",\n",
    "                exc_info=True\n",
    "            )\n",
    "            return None\n",
    "        \n",
    "        tile_img = Image.new(\"RGB\", (tile_size, tile_size), (255, 255, 255))\n",
    "        offset_x = left - top_left_x\n",
    "        offset_y = top - top_left_y\n",
    "        tile_img.paste(region, (offset_x, offset_y))\n",
    "        \n",
    "        expr_vector = X[i, :]\n",
    "        if issparse(expr_vector):\n",
    "            expr_vector = expr_vector.toarray().squeeze()\n",
    "        else:\n",
    "            expr_vector = np.array(expr_vector).squeeze()\n",
    "        expr_tensor = torch.tensor(expr_vector, dtype=torch.float32)\n",
    "        expr_sparse = expr_tensor.to_sparse()\n",
    "        \n",
    "        try:\n",
    "            tile_img.save(tile_filename)\n",
    "        except Exception as e:\n",
    "            logging.error(\n",
    "                f\"保存瓦片图像失败，索引 {i}，文件名：{tile_filename}。异常：{e}\",\n",
    "                exc_info=True\n",
    "            )\n",
    "            return None\n",
    "        try:\n",
    "            torch.save(expr_sparse, expr_filename)\n",
    "        except Exception as e:\n",
    "            logging.error(\n",
    "                f\"保存表达数据失败，索引 {i}，文件名：{expr_filename}。异常：{e}\",\n",
    "                exc_info=True\n",
    "            )\n",
    "            return None\n",
    "        \n",
    "        return (tile_filename, expr_filename, expr_vector)\n",
    "    \n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(process_tile, args) for args in valid_spots]\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"处理有效瓦片\"):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "    \n",
    "    # 随机展示8个在范围内的瓦片及其 top5 基因表达柱状图（上下两行）\n",
    "    if results:\n",
    "        sample_results = random.sample(results, min(8, len(results)))\n",
    "        n = len(sample_results)\n",
    "        fig, axes = plt.subplots(2, n, figsize=(n * 3, 2 * 3))\n",
    "        if n == 1:\n",
    "            axes = np.array([[axes[0]], [axes[1]]])\n",
    "        for j, (tile_filename, expr_filename, expr_vector) in enumerate(sample_results):\n",
    "            # 上行：展示瓦片图像\n",
    "            try:\n",
    "                img = Image.open(tile_filename)\n",
    "                axes[0, j].imshow(img)\n",
    "                axes[0, j].axis(\"off\")\n",
    "                title = os.path.basename(tile_filename).replace(\".png\", \"\")\n",
    "                axes[0, j].set_title(title, fontsize=8)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"展示瓦片失败: {tile_filename}，异常: {e}\", exc_info=True)\n",
    "                axes[0, j].axis(\"off\")\n",
    "            \n",
    "            # 下行：展示 top5 基因表达的横向柱状图，使用 seaborn 绘制\n",
    "            try:\n",
    "                expr_arr = np.array(expr_vector)\n",
    "                top5_idx = np.argsort(expr_arr)[-3:][::-1]\n",
    "                top5_values = expr_arr[top5_idx]\n",
    "                gene_names = np.array(sample.adata.var_names)[top5_idx]\n",
    "                sns.barplot(x=top5_values, y=gene_names, ax=axes[1, j], palette=\"Set2\", hue=gene_names)\n",
    "                axes[1, j].set_xlabel(\"\")\n",
    "                axes[1, j].set_ylabel(\"\")\n",
    "                axes[1, j].tick_params(axis='y', labelsize=6)\n",
    "                axes[1, j].tick_params(axis='x', labelsize=6)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"展示柱状图失败: {expr_filename}，异常: {e}\", exc_info=True)\n",
    "                axes[1, j].axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home1/jijh/diffusion_project/ADiffusion\")\n",
    "from src.pipeline.hest_loading import HESTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/cwStorage/nodecw_group/jijh/hest_1k\"\n",
    "dataset = HESTDataset(data_dir=data_dir)\n",
    "\n",
    "# 查询器官为 \"Brain\" \n",
    "brain_samples = dataset.get_samples(\n",
    "    organ=\"Brain\", \n",
    "    oncotree_code=None,  # 根据需要填写\n",
    "    sample_ids=None,       # 根据需要填写\n",
    "    species='Mus musculus'          # 根据需要填写\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"找到 {len(brain_samples)} 个样本。\")\n",
    "print(brain_samples[:3])  # 仅预览前三个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随便选一个样本\n",
    "sample = brain_samples[2]\n",
    "print(sample)\n",
    "sample.load_st_data()\n",
    "sample.load_wsi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.wsi.dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- (1) 创建综合可视化图 ---\n",
    "# 默认使用预生成的空间转录组图像，如果没有则实时计算\n",
    "sample.visualize_comparison(\n",
    "    color='clusters',\n",
    "    use_precomputed_spatial_plot=True  # 可以手动切换到 False 以实时计算\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_output_dir = '/cwStorage/nodecw_group/jijh/hest_output/output_tiles'\n",
    "expr_output_dir = '/cwStorage/nodecw_group/jijh/hest_output/output_expr'\n",
    "\n",
    "extract_tiles_and_expression(sample, tile_size=None, tiles_output_dir=tiles_output_dir, expr_output_dir=expr_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_output_dir = '/cwStorage/nodecw_group/jijh/hest_output/output_tiles'\n",
    "expr_output_dir = '/cwStorage/nodecw_group/jijh/hest_output/output_expr'\n",
    "\n",
    "extract_tiles_and_expression(sample, tile_size=None, tiles_output_dir=tiles_output_dir, expr_output_dir=expr_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/cwStorage/nodecw_group/jijh/hest_output'\n",
    "all_results = {}\n",
    "for sample in tqdm(brain_samples, desc=\"处理 Brain 样本\"):\n",
    "    logging.info(f\"开始处理样本 {sample.sample_id} ...\")\n",
    "    sample.load_st_data()\n",
    "    sample.load_wsi()\n",
    "    # 为每个样本建立独立的输出文件夹，避免文件混淆\n",
    "    sample_tiles_dir = os.path.join(save_dir, f\"{sample.sample_id}_tiles\")\n",
    "    sample_expr_dir = os.path.join(save_dir, f\"{sample.sample_id}_expr\")\n",
    "    \n",
    "    results = extract_tiles_and_expression(\n",
    "        sample, \n",
    "        tile_size=None, \n",
    "        tile_size_strategy=\"median\",\n",
    "        tiles_output_dir=sample_tiles_dir, \n",
    "        expr_output_dir=sample_expr_dir,\n",
    "        max_workers=32\n",
    "    )\n",
    "    all_results[sample.sample_id] = results\n",
    "    logging.info(f\"样本 {sample.sample_id} 处理完成，共处理瓦片数量：{len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.visualize_comparison(\n",
    "    color='clusters',\n",
    "    use_precomputed_spatial_plot=True  # 可以手动切换到 False 以实时计算\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = brain_samples[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.load_st_data()\n",
    "test_sample.load_wsi()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.adata.obsm['spatial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.visualize_comparison(\n",
    "    color='clusters',\n",
    "    use_precomputed_spatial_plot=True  # 可以手动切换到 False 以实时计算\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/cwStorage/nodecw_group/jijh/hest_1k\"\n",
    "dataset = HESTDataset(data_dir=data_dir)\n",
    "\n",
    "# 查询器官为 \"Brain\" \n",
    "brain_samples = dataset.get_samples(\n",
    "    organ=\"Brain\", \n",
    "    oncotree_code=None,  # 根据需要填写\n",
    "    sample_ids=None,       # 根据需要填写\n",
    "    species='Mus musculus'          # 根据需要填写\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"找到 {len(brain_samples)} 个样本。\")\n",
    "print(brain_samples[:3])  # 仅预览前三个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/cwStorage/nodecw_group/jijh/hest_output'\n",
    "all_results = {}\n",
    "for sample in tqdm(brain_samples, desc=\"处理 Brain 样本\"):\n",
    "    logging.info(f\"开始处理样本 {sample.sample_id} ...\")\n",
    "    sample.load_st_data()\n",
    "    sample.load_wsi()\n",
    "    # 为每个样本建立独立的输出文件夹，避免文件混淆\n",
    "    sample_tiles_dir = os.path.join(save_dir, f\"{sample.sample_id}_tiles\")\n",
    "    sample_expr_dir = os.path.join(save_dir, f\"{sample.sample_id}_expr\")\n",
    "    \n",
    "    results = extract_tiles_and_expression(\n",
    "        sample, \n",
    "        tile_size=None, \n",
    "        tile_size_strategy=\"median\",\n",
    "        tiles_output_dir=sample_tiles_dir, \n",
    "        expr_output_dir=sample_expr_dir,\n",
    "        max_workers=32\n",
    "    )\n",
    "    all_results[sample.sample_id] = results\n",
    "    logging.info(f\"样本 {sample.sample_id} 处理完成，共处理瓦片数量：{len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process all the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/cwStorage/nodecw_group/jijh/hest_1k\"\n",
    "dataset = HESTDataset(data_dir=data_dir)\n",
    "\n",
    "\n",
    "all_samples = dataset.get_samples(\n",
    "    organ=None, \n",
    "    oncotree_code=None,  # 根据需要填写\n",
    "    sample_ids=None,       # 根据需要填写\n",
    "    species=None        # 根据需要填写\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"找到 {len(all_samples)} 个样本。\")\n",
    "print(all_samples[:3])  # 仅预览前三个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/cwStorage/nodecw_group/jijh/hest_output'\n",
    "all_results = {}\n",
    "\n",
    "# Create a list to track failed samples\n",
    "failed_samples = []\n",
    "\n",
    "# Use all_samples instead of brain_samples\n",
    "for sample in tqdm(all_samples, desc=\"处理所有样本\"):\n",
    "    try:\n",
    "        # 为每个样本建立独立的输出文件夹\n",
    "        sample_tiles_dir = os.path.join(save_dir, f\"{sample.sample_id}_tiles\")\n",
    "        sample_expr_dir = os.path.join(save_dir, f\"{sample.sample_id}_expr\")\n",
    "        \n",
    "        # Check if the directories already contain processed files\n",
    "        if os.path.exists(sample_tiles_dir) and os.path.exists(sample_expr_dir):\n",
    "            # Check if any files exist in these directories\n",
    "            if len(os.listdir(sample_tiles_dir)) > 0 and len(os.listdir(sample_expr_dir)) > 0:\n",
    "                logging.info(f\"样本 {sample.sample_id} 已经处理过，跳过\")\n",
    "                continue\n",
    "        \n",
    "        logging.info(f\"开始处理样本 {sample.sample_id} ...\")\n",
    "        sample.load_st_data()\n",
    "        sample.load_wsi()\n",
    "        \n",
    "        results = extract_tiles_and_expression(\n",
    "            sample, \n",
    "            tile_size=None, \n",
    "            tile_size_strategy=\"median\",\n",
    "            tiles_output_dir=sample_tiles_dir, \n",
    "            expr_output_dir=sample_expr_dir,\n",
    "            max_workers=32\n",
    "        )\n",
    "        \n",
    "        all_results[sample.sample_id] = results\n",
    "        logging.info(f\"样本 {sample.sample_id} 处理完成，共处理瓦片数量：{len(results)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"处理样本 {sample.sample_id} 时出错: {str(e)}\", exc_info=True)\n",
    "        failed_samples.append((sample.sample_id, str(e)))\n",
    "\n",
    "# 打印失败的样本列表\n",
    "if failed_samples:\n",
    "    logging.warning(f\"处理失败的样本数量: {len(failed_samples)}\")\n",
    "    for sample_id, error in failed_samples:\n",
    "        logging.warning(f\"  - {sample_id}: {error}\")\n",
    "else:\n",
    "    logging.info(\"所有样本处理成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GPU",
   "language": "python",
   "name": "gpu_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
