{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import subprocess\n",
    "import shlex\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "os.chdir(\"/home1/jijh/diffusion_project/ADiffusion\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader # Use PyG's DataLoader\n",
    "from torch_geometric.nn import GPSConv, GATConv, global_add_pool\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix\n",
    "\n",
    "# Assume hest_loading is in the path or installed\n",
    "from src.pipeline.hest_loading import HESTDataset, HESTSample\n",
    "\n",
    "# Filter annoying warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Observation names are not unique.\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Variable names are not unique.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration Class\n",
    "class TrainingConfig:\n",
    "    # --- Hardware & Precision ---\n",
    "    GPU_IDS = [0,1,2] # <-- SPECIFY THE DESIRED GPU INDICES HERE\n",
    "    PRIMARY_GPU_ID = GPU_IDS[0] if GPU_IDS else 0\n",
    "    NUM_GPUS = len(GPU_IDS) if torch.cuda.is_available() and GPU_IDS else 0 # Number of GPUs to USE\n",
    "    PRIMARY_DEVICE_NAME = f\"cuda:{PRIMARY_GPU_ID}\" if NUM_GPUS > 0 else \"cpu\"\n",
    "    MIXED_PRECISION_TYPE = \"bf16\" # \"bf16\", \"fp16\", or \"no\"\n",
    "    DDP_MASTER_PORT = 29502 # Choose an unused port\n",
    "\n",
    "\n",
    "    # --- Data Paths ---\n",
    "    HEST_DATA_DIR = \"/cwStorage/nodecw_group/jijh/hest_1k\"\n",
    "    # Input VAE Latents (from previous step)\n",
    "    LATENT_DIR = \"/cwStorage/nodecw_group/jijh/hest_output_latents_bf16\"\n",
    "    # Output Directory for Processed Graphs\n",
    "    GRAPH_DATA_DIR = \"/cwStorage/nodecw_group/jijh/hest_graph_data_pca50_knn6\"\n",
    "    # Input VAE Model\n",
    "    VAE_MODEL_PATH = \"/cwStorage/nodecw_group/jijh/model_path/finetuned_taesd_v21_notebook_apr2.pt\"\n",
    "    # Input Pre-trained UNet (optional, for fine-tuning)\n",
    "    PRETRAINED_UNET_PATH = \"/cwStorage/nodecw_group/jijh/model_path/unet_ddp_bf16_ep15_bs32x3_lr0.0001_acc4.pt\" # Example path from previous run\n",
    "\n",
    "\n",
    "    # --- Preprocessing ---\n",
    "    PCA_N_COMPS = 50\n",
    "    SPATIAL_N_NEIGHBORS = 6 # KNN for graph construction\n",
    "    # Limit samples for faster testing?\n",
    "    PREPROCESS_MAX_SAMPLES = None # Set to a number (e.g., 10) for testing\n",
    "\n",
    "    # --- VAE ---\n",
    "    VAE_SD_VERSION = 'v2.1'\n",
    "    VAE_LATENT_CHANNELS = 4 # Should match precomputed latents\n",
    "\n",
    "    # --- Graph Conditioner (GPSConv based) ---\n",
    "    CONDITIONER_INPUT_DIM = PCA_N_COMPS\n",
    "    CONDITIONER_HIDDEN_DIM = 256 # Internal dimension of GPSConv\n",
    "    CONDITIONER_OUTPUT_DIM = 768 # MUST match UNet cross_attention_dim\n",
    "    CONDITIONER_N_LAYERS = 4    # Number of GPSConv layers\n",
    "    CONDITIONER_N_HEADS = 4     # Heads for multi-head attention in GPSConv\n",
    "    CONDITIONER_ATTN_DROPOUT = 0.1\n",
    "\n",
    "    # --- Diffusion (UNet) --- Parameters must match the pre-trained one if loading\n",
    "    UNET_SAMPLE_SIZE = 64  # Latent spatial dimensions\n",
    "    UNET_IN_CHANNELS = VAE_LATENT_CHANNELS\n",
    "    UNET_OUT_CHANNELS = VAE_LATENT_CHANNELS\n",
    "    UNET_BLOCK_OUT_CHANNELS = (320, 640, 1280, 1280)\n",
    "    UNET_DOWN_BLOCK_TYPES = ('CrossAttnDownBlock2D', 'CrossAttnDownBlock2D', 'CrossAttnDownBlock2D', 'DownBlock2D')\n",
    "    UNET_UP_BLOCK_TYPES = ('UpBlock2D', 'CrossAttnUpBlock2D', 'CrossAttnUpBlock2D', 'CrossAttnUpBlock2D')\n",
    "    UNET_CROSS_ATTENTION_DIM = CONDITIONER_OUTPUT_DIM # Ensure match\n",
    "\n",
    "    # --- Training Script Config ---\n",
    "    DIFFUSION_BATCH_SIZE_PER_GPU = 4 # Adjust based on GPU memory\n",
    "    DIFFUSION_NUM_EPOCHS = 20\n",
    "    DIFFUSION_LEARNING_RATE = 5e-5 # May need tuning\n",
    "    ACCUMULATION_STEPS = 4\n",
    "    NUM_WORKERS = 16 # DataLoader workers\n",
    "    SCHEDULER_TRAIN_TIMESTEPS = 1000\n",
    "    SAMPLING_INFERENCE_STEPS = 50 # For visualization during training\n",
    "    # SAMPLING_BATCH_SIZE = 16 # <-- NO LONGER NEEDED HERE, fixed in script\n",
    "\n",
    "    # --- Logging & Saving (Script) ---\n",
    "    CHECKPOINT_DIR = \"/cwStorage/nodecw_group/jijh/model_path/conditioned_diffusion_v1\"\n",
    "    LOG_DIR = \"/cwStorage/nodecw_group/jijh/training_log/conditioned_diffusion_v1\"\n",
    "    CHECKPOINT_FILENAME_PREFIX = \"cond_unet_gps\"\n",
    "    TRAIN_SCRIPT_PATH = \"/home1/jijh/diffusion_project/ADiffusion/src/pipeline/train_condition_diffusion_ddp.py\" # Path to the DDP script\n",
    "    # NEW: Define step-based sampling interval here\n",
    "    SAMPLE_INTERVAL_STEPS = 200\n",
    "    SAVE_INTERVAL_EPOCHS = 1 # Save every epoch by default now\n",
    "\n",
    "    @classmethod\n",
    "    def get_script_args(cls):\n",
    "        \"\"\"Generates CLI arguments for the DDP training script.\"\"\"\n",
    "        # This method remains unchanged, it correctly uses config values\n",
    "        args = [\n",
    "            f\"--graph_data_dir={cls.GRAPH_DATA_DIR}\",\n",
    "            f\"--latent_dir={cls.LATENT_DIR}\",\n",
    "            f\"--checkpoint_dir={cls.CHECKPOINT_DIR}\",\n",
    "            f\"--log_dir={cls.LOG_DIR}\",\n",
    "            f\"--vae_model_path={cls.VAE_MODEL_PATH}\",\n",
    "            f\"--vae_sd_version={cls.VAE_SD_VERSION}\",\n",
    "            f\"--pretrained_unet_path={cls.PRETRAINED_UNET_PATH}\" if cls.PRETRAINED_UNET_PATH else \"--pretrained_unet_path=None\",\n",
    "\n",
    "            f\"--epochs={cls.DIFFUSION_NUM_EPOCHS}\",\n",
    "            f\"--batch_size_per_gpu={cls.DIFFUSION_BATCH_SIZE_PER_GPU}\",\n",
    "            f\"--lr={cls.DIFFUSION_LEARNING_RATE}\",\n",
    "            f\"--accumulation_steps={cls.ACCUMULATION_STEPS}\",\n",
    "            f\"--mixed_precision={cls.MIXED_PRECISION_TYPE}\",\n",
    "            f\"--num_workers={cls.NUM_WORKERS}\",\n",
    "\n",
    "            f\"--pca_n_comps={cls.PCA_N_COMPS}\", # Pass PCA info\n",
    "            f\"--conditioner_input_dim={cls.CONDITIONER_INPUT_DIM}\",\n",
    "            f\"--conditioner_hidden_dim={cls.CONDITIONER_HIDDEN_DIM}\",\n",
    "            f\"--conditioner_output_dim={cls.CONDITIONER_OUTPUT_DIM}\",\n",
    "            f\"--conditioner_n_layers={cls.CONDITIONER_N_LAYERS}\",\n",
    "            f\"--conditioner_n_heads={cls.CONDITIONER_N_HEADS}\",\n",
    "            f\"--conditioner_attn_dropout={cls.CONDITIONER_ATTN_DROPOUT}\",\n",
    "\n",
    "            f\"--unet_sample_size={cls.UNET_SAMPLE_SIZE}\",\n",
    "            f\"--unet_in_channels={cls.UNET_IN_CHANNELS}\",\n",
    "            f\"--unet_out_channels={cls.UNET_OUT_CHANNELS}\",\n",
    "            f\"--unet_block_out_channels={','.join(map(str, cls.UNET_BLOCK_OUT_CHANNELS))}\",\n",
    "            f\"--unet_down_block_types={','.join(cls.UNET_DOWN_BLOCK_TYPES)}\",\n",
    "            f\"--unet_up_block_types={','.join(cls.UNET_UP_BLOCK_TYPES)}\",\n",
    "            f\"--unet_cross_attention_dim={cls.UNET_CROSS_ATTENTION_DIM}\",\n",
    "\n",
    "            f\"--scheduler_train_timesteps={cls.SCHEDULER_TRAIN_TIMESTEPS}\",\n",
    "            f\"--sampling_inference_steps={cls.SAMPLING_INFERENCE_STEPS}\",\n",
    "            f\"--sample_interval_steps={cls.SAMPLE_INTERVAL_STEPS}\",\n",
    "            f\"--save_interval={cls.SAVE_INTERVAL_EPOCHS}\",\n",
    "            f\"--checkpoint_filename_prefix={cls.CHECKPOINT_FILENAME_PREFIX}\",\n",
    "            f\"--log_interval=20\",\n",
    "        ]\n",
    "        return args\n",
    "\n",
    "# --- Instantiate config (run this cell again!) ---\n",
    "config = TrainingConfig()\n",
    "os.makedirs(config.GRAPH_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(config.LOG_DIR, exist_ok=True)\n",
    "# --- End of Cell 2 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ae730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration Class\n",
    "class TrainingConfig:\n",
    "    # --- Hardware & Precision ---\n",
    "    GPU_IDS = [0, 2] # <-- SPECIFY THE DESIRED GPU INDICES HERE\n",
    "    PRIMARY_GPU_ID = GPU_IDS[0] if GPU_IDS else 0\n",
    "    NUM_GPUS = len(GPU_IDS) if torch.cuda.is_available() and GPU_IDS else 0 # Number of GPUs to USE\n",
    "    PRIMARY_DEVICE_NAME = f\"cuda:{PRIMARY_GPU_ID}\" if NUM_GPUS > 0 else \"cpu\"\n",
    "    MIXED_PRECISION_TYPE = \"bf16\" # \"bf16\", \"fp16\", or \"no\"\n",
    "    DDP_MASTER_PORT = 29502 # Choose an unused port\n",
    "\n",
    "\n",
    "    # --- Data Paths ---\n",
    "    HEST_DATA_DIR = \"/cwStorage/nodecw_group/jijh/hest_1k\"\n",
    "    # Input VAE Latents (from previous step)\n",
    "    LATENT_DIR = \"/cwStorage/nodecw_group/jijh/hest_output_latents_bf16\"\n",
    "    # Output Directory for Processed Graphs\n",
    "    GRAPH_DATA_DIR = \"/cwStorage/nodecw_group/jijh/hest_graph_data_pca50_knn6\"\n",
    "    # Input VAE Model\n",
    "    VAE_MODEL_PATH = \"/cwStorage/nodecw_group/jijh/model_path/finetuned_taesd_v21_notebook_apr2.pt\"\n",
    "    # Input Pre-trained UNet (optional, for fine-tuning)\n",
    "    PRETRAINED_UNET_PATH = \"/cwStorage/nodecw_group/jijh/model_path/unet_ddp_bf16_ep15_bs32x3_lr0.0001_acc4.pt\" # Example path from previous run\n",
    "\n",
    "\n",
    "    # --- Preprocessing ---\n",
    "    PCA_N_COMPS = 50\n",
    "    SPATIAL_N_NEIGHBORS = 6 # KNN for graph construction\n",
    "    # Limit samples for faster testing?\n",
    "    PREPROCESS_MAX_SAMPLES = None # Set to a number (e.g., 10) for testing\n",
    "\n",
    "    # --- VAE ---\n",
    "    VAE_SD_VERSION = 'v2.1'\n",
    "    VAE_LATENT_CHANNELS = 4 # Should match precomputed latents\n",
    "\n",
    "    # --- Graph Conditioner (GPSConv based) ---\n",
    "    CONDITIONER_INPUT_DIM = PCA_N_COMPS\n",
    "    CONDITIONER_HIDDEN_DIM = 256 # Internal dimension of GPSConv\n",
    "    CONDITIONER_OUTPUT_DIM = 768 # MUST match UNet cross_attention_dim\n",
    "    CONDITIONER_N_LAYERS = 4    # Number of GPSConv layers\n",
    "    CONDITIONER_N_HEADS = 4     # Heads for multi-head attention in GPSConv\n",
    "    CONDITIONER_ATTN_DROPOUT = 0.1\n",
    "\n",
    "    # --- Diffusion (UNet) --- Parameters must match the pre-trained one if loading\n",
    "    UNET_SAMPLE_SIZE = 64  # Latent spatial dimensions\n",
    "    UNET_IN_CHANNELS = VAE_LATENT_CHANNELS\n",
    "    UNET_OUT_CHANNELS = VAE_LATENT_CHANNELS\n",
    "    UNET_BLOCK_OUT_CHANNELS = (320, 640, 1280, 1280)\n",
    "    UNET_DOWN_BLOCK_TYPES = ('CrossAttnDownBlock2D', 'CrossAttnDownBlock2D', 'CrossAttnDownBlock2D', 'DownBlock2D')\n",
    "    UNET_UP_BLOCK_TYPES = ('UpBlock2D', 'CrossAttnUpBlock2D', 'CrossAttnUpBlock2D', 'CrossAttnUpBlock2D')\n",
    "    UNET_CROSS_ATTENTION_DIM = CONDITIONER_OUTPUT_DIM # Ensure match\n",
    "\n",
    "    # --- Training Script Config ---\n",
    "    DIFFUSION_BATCH_SIZE_PER_GPU = 4 # Adjust based on GPU memory\n",
    "    DIFFUSION_NUM_EPOCHS = 20\n",
    "    DIFFUSION_LEARNING_RATE = 5e-5 # May need tuning\n",
    "    ACCUMULATION_STEPS = 4\n",
    "    NUM_WORKERS = 16 # DataLoader workers\n",
    "    SCHEDULER_TRAIN_TIMESTEPS = 1000\n",
    "    SAMPLING_INFERENCE_STEPS = 50 # For visualization during training\n",
    "    # SAMPLING_BATCH_SIZE = 16 # <-- NO LONGER NEEDED HERE, fixed in script\n",
    "\n",
    "    # --- Logging & Saving (Script) ---\n",
    "    CHECKPOINT_DIR = \"/cwStorage/nodecw_group/jijh/model_path/conditioned_diffusion_v1\"\n",
    "    LOG_DIR = \"/cwStorage/nodecw_group/jijh/training_log/conditioned_diffusion_v1\"\n",
    "    CHECKPOINT_FILENAME_PREFIX = \"cond_unet_gps\"\n",
    "    TRAIN_SCRIPT_PATH = \"/home1/jijh/diffusion_project/ADiffusion/src/pipeline/train_condition_diffusion_ddp.py\" # Path to the DDP script\n",
    "    # NEW: Define step-based sampling interval here\n",
    "    SAMPLE_INTERVAL_STEPS = 200\n",
    "    SAVE_INTERVAL_EPOCHS = 1 # Save every epoch by default now\n",
    "\n",
    "    @classmethod\n",
    "    def get_script_args(cls):\n",
    "        \"\"\"Generates CLI arguments for the DDP training script.\"\"\"\n",
    "        # This method remains unchanged, it correctly uses config values\n",
    "        args = [\n",
    "            f\"--graph_data_dir={cls.GRAPH_DATA_DIR}\",\n",
    "            f\"--latent_dir={cls.LATENT_DIR}\",\n",
    "            f\"--checkpoint_dir={cls.CHECKPOINT_DIR}\",\n",
    "            f\"--log_dir={cls.LOG_DIR}\",\n",
    "            f\"--vae_model_path={cls.VAE_MODEL_PATH}\",\n",
    "            f\"--vae_sd_version={cls.VAE_SD_VERSION}\",\n",
    "            f\"--pretrained_unet_path={cls.PRETRAINED_UNET_PATH}\" if cls.PRETRAINED_UNET_PATH else \"--pretrained_unet_path=None\",\n",
    "\n",
    "            f\"--epochs={cls.DIFFUSION_NUM_EPOCHS}\",\n",
    "            f\"--batch_size_per_gpu={cls.DIFFUSION_BATCH_SIZE_PER_GPU}\",\n",
    "            f\"--lr={cls.DIFFUSION_LEARNING_RATE}\",\n",
    "            f\"--accumulation_steps={cls.ACCUMULATION_STEPS}\",\n",
    "            f\"--mixed_precision={cls.MIXED_PRECISION_TYPE}\",\n",
    "            f\"--num_workers={cls.NUM_WORKERS}\",\n",
    "\n",
    "            f\"--pca_n_comps={cls.PCA_N_COMPS}\", # Pass PCA info\n",
    "            f\"--conditioner_input_dim={cls.CONDITIONER_INPUT_DIM}\",\n",
    "            f\"--conditioner_hidden_dim={cls.CONDITIONER_HIDDEN_DIM}\",\n",
    "            f\"--conditioner_output_dim={cls.CONDITIONER_OUTPUT_DIM}\",\n",
    "            f\"--conditioner_n_layers={cls.CONDITIONER_N_LAYERS}\",\n",
    "            f\"--conditioner_n_heads={cls.CONDITIONER_N_HEADS}\",\n",
    "            f\"--conditioner_attn_dropout={cls.CONDITIONER_ATTN_DROPOUT}\",\n",
    "\n",
    "            f\"--unet_sample_size={cls.UNET_SAMPLE_SIZE}\",\n",
    "            f\"--unet_in_channels={cls.UNET_IN_CHANNELS}\",\n",
    "            f\"--unet_out_channels={cls.UNET_OUT_CHANNELS}\",\n",
    "            f\"--unet_block_out_channels={','.join(map(str, cls.UNET_BLOCK_OUT_CHANNELS))}\",\n",
    "            f\"--unet_down_block_types={','.join(cls.UNET_DOWN_BLOCK_TYPES)}\",\n",
    "            f\"--unet_up_block_types={','.join(cls.UNET_UP_BLOCK_TYPES)}\",\n",
    "            f\"--unet_cross_attention_dim={cls.UNET_CROSS_ATTENTION_DIM}\",\n",
    "\n",
    "            f\"--scheduler_train_timesteps={cls.SCHEDULER_TRAIN_TIMESTEPS}\",\n",
    "            f\"--sampling_inference_steps={cls.SAMPLING_INFERENCE_STEPS}\",\n",
    "            f\"--sample_interval_steps={cls.SAMPLE_INTERVAL_STEPS}\",\n",
    "            f\"--save_interval={cls.SAVE_INTERVAL_EPOCHS}\",\n",
    "            f\"--checkpoint_filename_prefix={cls.CHECKPOINT_FILENAME_PREFIX}\",\n",
    "            f\"--log_interval=20\",\n",
    "        ]\n",
    "        return args\n",
    "\n",
    "# --- Instantiate config (run this cell again!) ---\n",
    "config = TrainingConfig()\n",
    "os.makedirs(config.GRAPH_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(config.LOG_DIR, exist_ok=True)\n",
    "# --- End of Cell 2 ---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
