{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 配置日志记录，便于调试和错误追踪\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "\n",
    "class MultiSampleTileExprDataset(Dataset):\n",
    "    \"\"\"\n",
    "    数据集同时加载图像和表达量数据，并解析文件名中的坐标信息。\n",
    "\n",
    "    数据目录组织要求：\n",
    "      - 根目录（root_dir）：/cwStorage/nodecw_group/jijh/hest_output\n",
    "      - 子文件夹命名方式：\n",
    "          * {sample_id}_tiles：存放瓦片图像\n",
    "          * {sample_id}_expr：存放对应的表达量数据\n",
    "      - 每个 _tiles 文件夹中，图像文件命名规则为：\n",
    "          <sample_id>_<col>_<row>.<ext>\n",
    "        与 _expr 文件夹中的表达量文件名一致（仅扩展名不同）。\n",
    "\n",
    "    参数:\n",
    "      - root_dir: 数据根目录\n",
    "      - transform: 图像预处理（默认为调整到 (512,512) 并归一化到 [-1,1]）\n",
    "      - image_exts: 图像文件的扩展名列表\n",
    "      - expr_ext: 表达量数据的扩展名（默认 '.pt'）\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, \n",
    "                 transform=None, \n",
    "                 image_exts=['.png', '.jpg', '.jpeg'], \n",
    "                 expr_ext='.pt'):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_exts = image_exts\n",
    "        self.expr_ext = expr_ext\n",
    "\n",
    "        # 默认图像预处理：调整尺寸、转 tensor 以及归一化\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((512, 512), interpolation=Image.LANCZOS),\n",
    "                transforms.ToTensor(),  # [0,1]\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                     std=[0.5, 0.5, 0.5])  # 映射到 [-1,1]\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "        # 1. 扫描 root_dir 下所有子文件夹，将 _tiles 和 _expr 文件夹按照 sample_id 配对\n",
    "        all_subdirs = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "        self.sample_pairs = {}  # key: sample_id, value: dict {'tiles': path, 'expr': path}\n",
    "        for d in tqdm(all_subdirs, desc=\"扫描子文件夹\"):\n",
    "            full_path = os.path.join(root_dir, d)\n",
    "            if d.endswith('_tiles'):\n",
    "                sample_id = d[:-len('_tiles')]\n",
    "                self.sample_pairs.setdefault(sample_id, {})['tiles'] = full_path\n",
    "            elif d.endswith('_expr'):\n",
    "                sample_id = d[:-len('_expr')]\n",
    "                self.sample_pairs.setdefault(sample_id, {})['expr'] = full_path\n",
    "\n",
    "        # 仅保留同时存在 _tiles 和 _expr 的样本\n",
    "        self.sample_pairs = {sid: paths for sid, paths in self.sample_pairs.items() \n",
    "                             if 'tiles' in paths and 'expr' in paths}\n",
    "        logging.info(f\"共找到 {len(self.sample_pairs)} 个样本配对。\")\n",
    "\n",
    "        # 2. 遍历每个样本的 _tiles 文件夹，建立图像与表达量文件的对应关系，同时解析坐标信息\n",
    "        self.file_pairs = []  # 每个元素为 {'sample_id': ..., 'image_path': ..., 'expr_path': ..., 'col': ..., 'row': ...}\n",
    "        for sample_id, paths in tqdm(self.sample_pairs.items(), desc=\"建立文件配对\", total=len(self.sample_pairs)):\n",
    "            tiles_dir = paths['tiles']\n",
    "            expr_dir = paths['expr']\n",
    "            # 使用 os.walk 支持子目录结构\n",
    "            for root_tiles, _, files in os.walk(tiles_dir):\n",
    "                for file in files:\n",
    "                    if any(file.lower().endswith(ext) for ext in self.image_exts):\n",
    "                        image_path = os.path.join(root_tiles, file)\n",
    "                        base_name = os.path.splitext(file)[0]\n",
    "                        # 解析文件名，假设最后两个下划线分割的部分分别为 col 和 row，\n",
    "                        # 如果文件名中含有多个下划线，sample_id 部分可能包含下划线\n",
    "                        parts = base_name.split('_')\n",
    "                        if len(parts) >= 3:\n",
    "                            try:\n",
    "                                # 取最后两个部分作为坐标，其余部分作为 sample_id_from_file\n",
    "                                col = int(parts[-2])\n",
    "                                row = int(parts[-1])\n",
    "                                sample_id_from_file = \"_\".join(parts[:-2])\n",
    "                            except ValueError:\n",
    "                                col, row = None, None\n",
    "                                sample_id_from_file = base_name\n",
    "                        else:\n",
    "                            col, row = None, None\n",
    "                            sample_id_from_file = base_name\n",
    "\n",
    "                        # 构造表达量文件路径（假设命名完全一致，仅扩展名不同）\n",
    "                        expr_file = base_name + self.expr_ext\n",
    "                        expr_path = os.path.join(expr_dir, expr_file)\n",
    "                        if os.path.exists(expr_path):\n",
    "                            self.file_pairs.append({\n",
    "                                'sample_id': sample_id,  # 来自文件夹配对\n",
    "                                'image_path': image_path,\n",
    "                                'expr_path': expr_path,\n",
    "                                'col': col,\n",
    "                                'row': row\n",
    "                            })\n",
    "                        else:\n",
    "                            logging.warning(f\"在样本 {sample_id} 中找不到与 {image_path} 对应的表达量文件 {expr_path}。\")\n",
    "        if not self.file_pairs:\n",
    "            raise ValueError(\"未找到任何有效的图像与表达量配对，请检查目录结构和文件命名规则。\")\n",
    "        logging.info(f\"共找到 {len(self.file_pairs)} 个有效文件配对。\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.file_pairs[idx]\n",
    "        sample_id = pair['sample_id']\n",
    "        image_path = pair['image_path']\n",
    "        expr_path = pair['expr_path']\n",
    "        col = pair['col']\n",
    "        row = pair['row']\n",
    "        \n",
    "        # 加载图像\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"加载图像失败：{image_path}，错误信息：{e}\")\n",
    "            raise e\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # 加载表达量数据\n",
    "        try:\n",
    "            expr_data = torch.load(expr_path)\n",
    "            if torch.is_tensor(expr_data) and expr_data.is_sparse:\n",
    "                expr_data = expr_data.to_dense()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"加载表达量数据失败：{expr_path}，错误信息：{e}\")\n",
    "            raise e\n",
    "        \n",
    "        return {\n",
    "            \"sample_id\": sample_id, \n",
    "            \"image\": image, \n",
    "            \"expression\": expr_data,\n",
    "            \"col\": col,\n",
    "            \"row\": row\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/cwStorage/nodecw_group/jijh/hest_output\"\n",
    "\n",
    "dataset = MultiSampleTileExprDataset(root_dir)\n",
    "logging.info(f\"数据集中共有 {len(dataset)} 个文件配对。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.data_process import construct_affinity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "from torch_geometric.data import Data\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "\n",
    "\n",
    "def extract_sample_data(dataset, sample_id):\n",
    "    \"\"\"\n",
    "    从 MultiSampleTileExprDataset 中提取指定 sample_id 的所有数据。\n",
    "    \n",
    "    返回：\n",
    "      - expr_list: list，每个元素为一个 tile 的表达量数据（numpy 数组）\n",
    "      - coords_list: list，每个元素为 [x, y] 坐标（x 对应 col，y 对应 row）\n",
    "      - image_paths: list，每个元素为对应 tile 的图像文件路径（仅作为指针）\n",
    "      - sample_ids: list，每个元素为 tile 对应的 sample_id\n",
    "    \"\"\"\n",
    "    logging.info(f\"开始提取 sample_id 为 {sample_id} 的数据。\")\n",
    "    sample_pairs = [pair for pair in dataset.file_pairs if pair['sample_id'] == sample_id]\n",
    "    if len(sample_pairs) == 0:\n",
    "        raise ValueError(f\"在数据集中未找到 sample_id 为 {sample_id} 的数据。\")\n",
    "    \n",
    "    expr_list = []\n",
    "    coords_list = []\n",
    "    image_paths = []\n",
    "    sample_ids = []\n",
    "    \n",
    "    for pair in sample_pairs:\n",
    "        # 加载表达量数据，并处理稀疏 tensor\n",
    "        expr_data = torch.load(pair['expr_path'])\n",
    "        if isinstance(expr_data, torch.Tensor):\n",
    "            if expr_data.is_sparse:\n",
    "                logging.debug(f\"表达量数据 {pair['expr_path']} 为稀疏 tensor，转换为密集格式。\")\n",
    "                expr_data = expr_data.to_dense()\n",
    "            expr_data = expr_data.cpu().numpy()\n",
    "        expr_list.append(expr_data)\n",
    "        \n",
    "        # 解析坐标（col 作为 x, row 作为 y）\n",
    "        x, y = pair['col'], pair['row']\n",
    "        coords_list.append([x, y])\n",
    "        \n",
    "        # 保存图像路径作为图像数据指针\n",
    "        image_paths.append(pair['image_path'])\n",
    "        sample_ids.append(pair['sample_id'])\n",
    "    \n",
    "    logging.info(f\"共提取到 {len(expr_list)} 个 tile 数据。\")\n",
    "    return expr_list, coords_list, image_paths, sample_ids\n",
    "\n",
    "\n",
    "def build_anndata(expr_list, coords_list, sample_ids, target_gene_num=2000):\n",
    "    \"\"\"\n",
    "    根据提取的表达数据、坐标和 sample_id 构建 AnnData 对象。\n",
    "    如果实际基因数少于 target_gene_num，则补零扩展至 target_gene_num。\n",
    "    \n",
    "    返回：\n",
    "      - adata: 构造好的 AnnData 对象，其中 obs 中保存 sample_id 和坐标，\n",
    "               obsm['spatial'] 中保存空间坐标。\n",
    "    \"\"\"\n",
    "    logging.info(\"开始构建 AnnData 对象。\")\n",
    "    # 构造表达矩阵\n",
    "    X = np.vstack(expr_list)  # 形状 (N, n_genes)\n",
    "    coords = np.array(coords_list)  # 形状 (N, 2)\n",
    "    n_samples, n_genes = X.shape\n",
    "    logging.info(f\"初始表达矩阵维度：{n_samples} 个样本，{n_genes} 个基因。\")\n",
    "    \n",
    "    # 若基因数不足 target_gene_num，则补零扩展\n",
    "    if n_genes < target_gene_num:\n",
    "        pad_width = target_gene_num - n_genes\n",
    "        logging.info(f\"基因数不足 {target_gene_num}，补零扩展 {pad_width} 个基因。\")\n",
    "        X = np.hstack([X, np.zeros((n_samples, pad_width))])\n",
    "        gene_names = [f\"gene_{i}\" for i in range(n_genes)] + [f\"pad_{i}\" for i in range(pad_width)]\n",
    "    else:\n",
    "        gene_names = [f\"gene_{i}\" for i in range(n_genes)]\n",
    "    \n",
    "    # 构造 AnnData 对象\n",
    "    adata = anndata.AnnData(X)\n",
    "    adata.var_names = gene_names\n",
    "    adata.obs['sample_id'] = sample_ids\n",
    "    adata.obs['x'] = coords[:, 0]\n",
    "    adata.obs['y'] = coords[:, 1]\n",
    "    adata.obsm['spatial'] = coords\n",
    "    \n",
    "    logging.info(f\"AnnData 对象构建完成，形状为 {adata.shape}。\")\n",
    "    return adata\n",
    "\n",
    "\n",
    "def add_qc_metrics(adata, mt_prefix='MT-'):\n",
    "    \"\"\"\n",
    "    计算质检指标（如总表达量、检测到的基因数等）。\n",
    "    如有需要，也可以在 adata.var 中标记线粒体基因，然后在 calculate_qc_metrics 中使用。\n",
    "    \n",
    "    参数：\n",
    "      - adata: AnnData 对象\n",
    "      - mt_prefix: 用于标记线粒体基因的前缀（可选）\n",
    "    \"\"\"\n",
    "    logging.info(\"开始计算质检指标。\")\n",
    "    # 如果有线粒体基因信息，可以将标记写入 adata.var\n",
    "    adata.var['mt'] = [gene.startswith(mt_prefix) for gene in adata.var_names]\n",
    "    sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], inplace=True)\n",
    "    logging.info(\"质检指标计算完成。\")\n",
    "\n",
    "\n",
    "def preprocess_anndata(adata, target_gene_num=2000, pca_n_comps=50):\n",
    "    \"\"\"\n",
    "    对 AnnData 对象进行预处理，包括归一化、对数转换、高变基因选择、数据缩放和 PCA 降维。\n",
    "    \n",
    "    如果高变基因数量不足 target_gene_num，则补零扩展。\n",
    "    \n",
    "    返回：\n",
    "      - 处理后的 AnnData 对象\n",
    "    \"\"\"\n",
    "    logging.info(\"开始预处理 AnnData 对象：归一化、对数转换、高变基因选择、缩放及 PCA。\")\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    \n",
    "    # 计算高变基因并选择前 target_gene_num 个\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=target_gene_num, flavor='seurat', inplace=True)\n",
    "    if adata.shape[1] < target_gene_num:\n",
    "        current_genes = adata.shape[1]\n",
    "        pad_width = target_gene_num - current_genes\n",
    "        logging.info(f\"高变基因数量不足 {target_gene_num}，补零 {pad_width} 列。\")\n",
    "        pad_data = np.zeros((adata.n_obs, pad_width))\n",
    "        if hasattr(adata.X, \"toarray\"):\n",
    "            X_dense = adata.X.toarray()\n",
    "        else:\n",
    "            X_dense = adata.X\n",
    "        X_new = np.hstack([X_dense, pad_data])\n",
    "        adata.X = X_new\n",
    "        pad_gene_names = [f\"pad_hvg_{i}\" for i in range(pad_width)]\n",
    "        adata.var = adata.var.append(pd.DataFrame(index=pad_gene_names))\n",
    "    else:\n",
    "        adata = adata[:, adata.var.highly_variable]\n",
    "    \n",
    "    sc.pp.scale(adata, max_value=10)\n",
    "    sc.tl.pca(adata, n_comps=pca_n_comps, svd_solver='arpack')\n",
    "    logging.info(f\"PCA 完成，PCA 结果维度为 {adata.obsm['X_pca'].shape}。\")\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def build_graph_data(adata, coords, sample_ids, image_paths,\n",
    "                     affinity_mode='radius', cutoff=1.0, n_neighbors=5,\n",
    "                     metric='euclidean', add_self_loop=False, pca_key='X_pca'):\n",
    "    \"\"\"\n",
    "    根据 AnnData 对象和空间坐标构建 torch_geometric 图数据。\n",
    "    \n",
    "    参数：\n",
    "      - adata: 经过预处理且包含 PCA 结果的 AnnData 对象，节点特征保存在 adata.obsm[pca_key]\n",
    "      - coords: 坐标数组，形状 (N, 2)\n",
    "      - sample_ids, image_paths: 用于记录节点的 sample_id 和图像路径\n",
    "      - affinity_mode, cutoff, n_neighbors, metric, add_self_loop: 构建 affinity matrix 的参数\n",
    "      \n",
    "    返回：\n",
    "      - graph_data: torch_geometric.data.Data 对象，包含节点特征、边信息和附加信息\n",
    "    \"\"\"\n",
    "    logging.info(\"开始构建图数据。\")\n",
    "    # 构建邻接矩阵，使用外部导入的 construct_affinity_matrix\n",
    "    affinity_matrix = construct_affinity_matrix(\n",
    "        coordinates=coords,\n",
    "        mode=affinity_mode,\n",
    "        cutoff=cutoff,\n",
    "        n_neighbors=n_neighbors,\n",
    "        metric=metric,\n",
    "        add_self_loop=add_self_loop\n",
    "    )\n",
    "    logging.info(f\"构建的 affinity matrix 非零元素数：{affinity_matrix.nnz}。\")\n",
    "    \n",
    "    # 提取 PCA 结果作为节点特征（注意调用 .copy() 避免负步长问题）\n",
    "    node_features = torch.tensor(adata.obsm[pca_key].copy(), dtype=torch.float)\n",
    "    \n",
    "    # 将 affinity_matrix 转换为 COO 格式，提取边索引和边权重\n",
    "    affinity_coo = affinity_matrix.tocoo()\n",
    "    edge_index = torch.tensor([affinity_coo.row, affinity_coo.col], dtype=torch.long)\n",
    "    edge_weight = torch.tensor(affinity_coo.data, dtype=torch.float)\n",
    "    \n",
    "    pos = torch.tensor(coords, dtype=torch.float)  # 节点空间坐标\n",
    "    \n",
    "    # 构造 torch_geometric 图数据对象\n",
    "    graph_data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_weight, pos=pos)\n",
    "    graph_data.sample_ids = sample_ids\n",
    "    graph_data.image_paths = image_paths\n",
    "    \n",
    "    logging.info(f\"图数据构建完成，节点数：{node_features.shape[0]}，边数：{edge_index.shape[1]}。\")\n",
    "    return graph_data\n",
    "\n",
    "\n",
    "def create_anndata_and_graph(dataset, sample_id,\n",
    "                             target_gene_num=2000,\n",
    "                             pca_n_comps=50,\n",
    "                             affinity_mode='radius',\n",
    "                             cutoff=1.0,\n",
    "                             n_neighbors=5,\n",
    "                             metric='euclidean',\n",
    "                             add_self_loop=False,\n",
    "                             pca_key='X_pca'):\n",
    "    \"\"\"\n",
    "    综合调用各个模块函数，根据指定 sample_id 从 dataset 中构建 AnnData 对象和 torch_geometric 图数据。\n",
    "    \n",
    "    返回：\n",
    "      - adata: 包含表达数据、质检指标、预处理和 PCA 结果的 AnnData 对象\n",
    "      - graph_data: 包含节点特征、边信息和附加信息（如图像路径、sample_id）的图数据对象\n",
    "    \"\"\"\n",
    "    logging.info(f\"开始创建 sample_id {sample_id} 的 AnnData 和图数据。\")\n",
    "    # 1. 数据提取\n",
    "    expr_list, coords_list, image_paths, sample_ids = extract_sample_data(dataset, sample_id)\n",
    "    coords = np.array(coords_list)\n",
    "    \n",
    "    # 2. 构建 AnnData\n",
    "    adata = build_anndata(expr_list, coords_list, sample_ids, target_gene_num=target_gene_num)\n",
    "    \n",
    "    # 3. 质检计算\n",
    "    add_qc_metrics(adata, mt_prefix='MT-')\n",
    "    \n",
    "    # 4. 预处理及降维（PCA）\n",
    "    adata = preprocess_anndata(adata, target_gene_num=target_gene_num, pca_n_comps=pca_n_comps)\n",
    "    \n",
    "    # 5. 构建图数据\n",
    "    graph_data = build_graph_data(adata, coords, sample_ids, image_paths,\n",
    "                                  affinity_mode=affinity_mode, cutoff=cutoff,\n",
    "                                  n_neighbors=n_neighbors, metric=metric,\n",
    "                                  add_self_loop=add_self_loop, pca_key=pca_key)\n",
    "    \n",
    "    logging.info(\"AnnData 与图数据创建完成。\")\n",
    "    return adata, graph_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 示例代码 ===================\n",
    "# 请确保 dataset 已经正确构造，例如：\n",
    "# from your_dataset_module import MultiSampleTileExprDataset\n",
    "# root_dir = \"/your/data/root_dir\"\n",
    "# dataset = MultiSampleTileExprDataset(root_dir)\n",
    "    \n",
    "target_sample_id = \"NCBI371\"  # 根据实际情况替换\n",
    "\n",
    "adata, graph_data = create_anndata_and_graph(\n",
    "    dataset=dataset,\n",
    "    sample_id=target_sample_id,\n",
    "    target_gene_num=2000,\n",
    "    pca_n_comps=50,\n",
    "    affinity_mode='number',  # 可选 'radius' 或 'number'\n",
    "    cutoff=None,             # mode='number' 时可以设为 None\n",
    "    n_neighbors=8,\n",
    "    metric='euclidean',\n",
    "    add_self_loop=True,\n",
    "    pca_key='X_pca'\n",
    ")\n",
    "logging.info(\"流程运行成功！\")\n",
    "print(adata)\n",
    "print(graph_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置日志记录\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "\n",
    "# 输出目录\n",
    "output_dir = \"/cwStorage/nodecw_group/jijh/hest_graph_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "logging.info(f\"输出目录设置为: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取所有的 sample_id（这里基于 dataset.sample_pairs 的 key）\n",
    "all_sample_ids = list(dataset.sample_pairs.keys())\n",
    "logging.info(f\"将处理 {len(all_sample_ids)} 个 sample_id。\")\n",
    "\n",
    "# 遍历每个 sample_id，生成图数据并保存\n",
    "for sid in all_sample_ids:\n",
    "    logging.info(f\"开始处理 sample_id: {sid}\")\n",
    "    try:\n",
    "        # 创建 AnnData 和图数据\n",
    "        adata, graph_data = create_anndata_and_graph(\n",
    "            dataset=dataset,\n",
    "            sample_id=sid,\n",
    "            target_gene_num=2000,\n",
    "            pca_n_comps=50,\n",
    "            affinity_mode='number',  # 固定邻居数模式\n",
    "            cutoff=None,             # number 模式下 cutoff 设为 None\n",
    "            n_neighbors=8,           # 邻居数设置为 8\n",
    "            metric='euclidean',\n",
    "            add_self_loop=True,\n",
    "            pca_key='X_pca'\n",
    "        )\n",
    "        # 保存生成的图数据（这里以 .pt 格式保存）\n",
    "        output_file = os.path.join(output_dir, f\"{sid}_graph.pt\")\n",
    "        torch.save(graph_data, output_file)\n",
    "        logging.info(f\"成功保存 sample_id {sid} 的图数据到: {output_file}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"处理 sample_id {sid} 时发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GPU",
   "language": "python",
   "name": "gpu_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
