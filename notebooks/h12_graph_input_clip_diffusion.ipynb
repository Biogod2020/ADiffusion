{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2919a8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded. Please ensure all paths are correct before proceeding.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import subprocess\n",
    "import shlex\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GPSConv, GATConv\n",
    "\n",
    "from diffusers import AutoencoderTiny, UNet2DConditionModel, DDPMScheduler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Configuration Class for Diffusion Training V3 ---\n",
    "class TrainingConfigDiffusion:\n",
    "    # --- Hardware & Precision ---\n",
    "    GPU_IDS = [0, 1]\n",
    "    NUM_GPUS = len(GPU_IDS) if torch.cuda.is_available() else 0\n",
    "    DDP_MASTER_PORT = 29505 \n",
    "    MIXED_PRECISION_TYPE = \"bf16\"\n",
    "\n",
    "    # --- Data & Model Paths ---\n",
    "    # [IMPORTANT] This MUST point to your new directory with preprocessed graphs (containing data.latent).\n",
    "    GRAPH_DATA_DIR = \"/cwStorage/nodecw_group/jijh/hest_graph_data_with_vae_latents\"      # <--- 必须修改\n",
    "    CHECKPOINT_DIR = \"/cwStorage/nodecw_group/jijh/model_path/conditioned_diffusion_v1_sampleN2\"      # <--- 必须修改\n",
    "    LOG_DIR = \"/cwStorage/nodecw_group/jijh/training_log/conditioned_diffusion_v1_sampleN2\"                # <--- 必须修改\n",
    "    VAE_MODEL_PATH = \"/cwStorage/nodecw_group/jijh/model_path/finetuned_taesd_v21_notebook_apr2.pt\"              # <--- 必须修改'\n",
    "\n",
    "    # <<< --- NEW CONFIGURATION PARAMETERS START --- >>>\n",
    "    # [IMPORTANT] Path to your pre-trained conditioner. Set to None if you want to train from scratch.\n",
    "    PRETRAINED_CONDITIONER_PATH = \"/cwStorage/nodecw_group/jijh/model_path/clip_preprocessed_v2/clip_graph_gigapath_preprocessed_ep50_step350_bs64x2_lr0.0001.pt\"\n",
    "    # [IMPORTANT] Set to True to freeze the conditioner and only train the UNet.\n",
    "    # Set to False to fine-tune both the conditioner and the UNet.\n",
    "    FREEZE_CONDITIONER = True \n",
    "    # <<< --- NEW CONFIGURATION PARAMETERS END --- >>>\n",
    "\n",
    "    PRETRAINED_UNET_PATH = \"/cwStorage/nodecw_group/jijh/model_path/unet_ddp_bf16_ep15_bs32x3_lr0.0001_acc4.pt\"\n",
    "    \n",
    "    # [NEW] Optional file to specify which samples to train on\n",
    "    # Set to a file path (e.g., \"/path/to/my_sample_ids.txt\") or leave as None to train on all.\n",
    "    TRAIN_SAMPLE_ID_FILE = \"/home1/jijh/diffusion_project/ADiffusion/test_sample_ids.txt\"                                    # <--- (可选) 修改\n",
    "\n",
    "    # Path to the new training script\n",
    "    TRAIN_SCRIPT_PATH = \"/home1/jijh/diffusion_project/ADiffusion/src/pipeline/train_condition_diffusion_ddp_v3.py\" # <--- 必须修改\n",
    "\n",
    "    # --- Model Architecture (ensure these match your data) ---\n",
    "    CONDITIONER_INPUT_DIM = 50\n",
    "    CONDITIONER_HIDDEN_DIM = 256\n",
    "    CONDITIONER_OUTPUT_DIM = 768\n",
    "    CONDITIONER_N_LAYERS = 4\n",
    "    CONDITIONER_N_HEADS = 4\n",
    "    CONDITIONER_ATTN_DROPOUT = 0.1\n",
    "    UNET_SAMPLE_SIZE = 32\n",
    "    UNET_IN_CHANNELS = 4\n",
    "    UNET_OUT_CHANNELS = 4\n",
    "    UNET_BLOCK_OUT_CHANNELS = \"320,640,1280,1280\"\n",
    "    UNET_DOWN_BLOCK_TYPES = \"DownBlock2D,CrossAttnDownBlock2D,CrossAttnDownBlock2D,DownBlock2D\"\n",
    "    UNET_UP_BLOCK_TYPES = \"UpBlock2D,CrossAttnUpBlock2D,CrossAttnUpBlock2D,UpBlock2D\"\n",
    "    UNET_CROSS_ATTENTION_DIM = CONDITIONER_OUTPUT_DIM\n",
    "\n",
    "    # --- Training Hyperparameters ---\n",
    "    EPOCHS = 150\n",
    "    BATCH_SIZE_PER_GPU = 32\n",
    "    LEARNING_RATE = 5e-5\n",
    "    ACCUMULATION_STEPS = 2\n",
    "    NUM_WORKERS = 16\n",
    "    \n",
    "    # --- Logging & Saving ---\n",
    "    CHECKPOINT_FILENAME_PREFIX = \"cond_unet_v3\"\n",
    "    SAVE_INTERVAL_EPOCHS = 50\n",
    "    SAMPLE_INTERVAL_STEPS = 100\n",
    "\n",
    "    @classmethod\n",
    "    def get_script_args(cls):\n",
    "        \"\"\"Generates command-line arguments for the new training script.\"\"\"\n",
    "        args = [\n",
    "            f\"--graph_data_dir={cls.GRAPH_DATA_DIR}\", f\"--checkpoint_dir={cls.CHECKPOINT_DIR}\",\n",
    "            f\"--log_dir={cls.LOG_DIR}\", f\"--vae_model_path={cls.VAE_MODEL_PATH}\",\n",
    "            f\"--epochs={cls.EPOCHS}\", f\"--batch_size_per_gpu={cls.BATCH_SIZE_PER_GPU}\",\n",
    "            f\"--lr={cls.LEARNING_RATE}\", f\"--accumulation_steps={cls.ACCUMULATION_STEPS}\",\n",
    "            f\"--mixed_precision={cls.MIXED_PRECISION_TYPE}\", f\"--num_workers={cls.NUM_WORKERS}\",\n",
    "            f\"--conditioner_input_dim={cls.CONDITIONER_INPUT_DIM}\",\n",
    "            f\"--conditioner_hidden_dim={cls.CONDITIONER_HIDDEN_DIM}\",\n",
    "            f\"--conditioner_output_dim={cls.CONDITIONER_OUTPUT_DIM}\",\n",
    "            f\"--conditioner_n_layers={cls.CONDITIONER_N_LAYERS}\",\n",
    "            f\"--conditioner_n_heads={cls.CONDITIONER_N_HEADS}\",\n",
    "            f\"--conditioner_attn_dropout={cls.CONDITIONER_ATTN_DROPOUT}\",\n",
    "            f\"--unet_sample_size={cls.UNET_SAMPLE_SIZE}\", f\"--unet_in_channels={cls.UNET_IN_CHANNELS}\",\n",
    "            f\"--unet_out_channels={cls.UNET_OUT_CHANNELS}\",\n",
    "            f\"--unet_block_out_channels={cls.UNET_BLOCK_OUT_CHANNELS}\",\n",
    "            f\"--unet_down_block_types={cls.UNET_DOWN_BLOCK_TYPES}\",\n",
    "            f\"--unet_up_block_types={cls.UNET_UP_BLOCK_TYPES}\",\n",
    "            f\"--unet_cross_attention_dim={cls.UNET_CROSS_ATTENTION_DIM}\",\n",
    "            f\"--save_interval={cls.SAVE_INTERVAL_EPOCHS}\",\n",
    "            f\"--sample_interval_steps={cls.SAMPLE_INTERVAL_STEPS}\",\n",
    "            f\"--checkpoint_filename_prefix={cls.CHECKPOINT_FILENAME_PREFIX}\",\n",
    "            f\"--pretrained_conditioner_path={cls.PRETRAINED_CONDITIONER_PATH}\",\n",
    "            f\"--freeze_conditioner={str(cls.FREEZE_CONDITIONER).lower()}\",\n",
    "            f\"--pretrained_unet_path={cls.PRETRAINED_UNET_PATH}\",\n",
    "        ]\n",
    "        # [NEW] Add the sample ID file argument only if it's specified\n",
    "        if cls.TRAIN_SAMPLE_ID_FILE:\n",
    "            args.append(f\"--train_sample_id_file={cls.TRAIN_SAMPLE_ID_FILE}\")\n",
    "        return args\n",
    "\n",
    "# Instantiate config and create directories\n",
    "config_diff = TrainingConfigDiffusion()\n",
    "os.makedirs(config_diff.CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(config_diff.LOG_DIR, exist_ok=True)\n",
    "print(\"Config loaded. Please ensure all paths are correct before proceeding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddebe4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing to Launch DDP Training for Diffusion Model V3 ---\n",
      "\n",
      "Launching command:\n",
      "/public/home/jijh/micromamba/envs/gpu_env/bin/python -m torch.distributed.run --nproc_per_node=2 --master_port=29505 /home1/jijh/diffusion_project/ADiffusion/src/pipeline/train_condition_diffusion_ddp_v3.py --graph_data_dir=/cwStorage/nodecw_group/jijh/hest_graph_data_with_vae_latents --checkpoint_dir=/cwStorage/nodecw_group/jijh/model_path/conditioned_diffusion_v1_sampleN2 --log_dir=/cwStorage/nodecw_group/jijh/training_log/conditioned_diffusion_v1_sampleN2 --vae_model_path=/cwStorage/nodecw_group/jijh/model_path/finetuned_taesd_v21_notebook_apr2.pt --epochs=150 --batch_size_per_gpu=32 --lr=5e-05 --accumulation_steps=2 --mixed_precision=bf16 --num_workers=16 --conditioner_input_dim=50 --conditioner_hidden_dim=256 --conditioner_output_dim=768 --conditioner_n_layers=4 --conditioner_n_heads=4 --conditioner_attn_dropout=0.1 --unet_sample_size=32 --unet_in_channels=4 --unet_out_channels=4 --unet_block_out_channels=320,640,1280,1280 --unet_down_block_types=DownBlock2D,CrossAttnDownBlock2D,CrossAttnDownBlock2D,DownBlock2D --unet_up_block_types=UpBlock2D,CrossAttnUpBlock2D,CrossAttnUpBlock2D,UpBlock2D --unet_cross_attention_dim=768 --save_interval=50 --sample_interval_steps=100 --checkpoint_filename_prefix=cond_unet_v3 --pretrained_conditioner_path=/cwStorage/nodecw_group/jijh/model_path/clip_preprocessed_v2/clip_graph_gigapath_preprocessed_ep50_step350_bs64x2_lr0.0001.pt --freeze_conditioner=true --pretrained_unet_path=/cwStorage/nodecw_group/jijh/model_path/unet_ddp_bf16_ep15_bs32x3_lr0.0001_acc4.pt --train_sample_id_file=/home1/jijh/diffusion_project/ADiffusion/test_sample_ids.txt\n",
      "------------------------------\n",
      "Script Output:\n",
      "------------------------------\n",
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "*****************************************\n",
      "usage: train_condition_diffusion_ddp_v3.py [-h] --graph_data_dir\n",
      "GRAPH_DATA_DIR --checkpoint_dir\n",
      "CHECKPOINT_DIR --log_dir LOG_DIR\n",
      "--vae_model_path VAE_MODEL_PATH\n",
      "[--pretrained_unet_path PRETRAINED_UNET_PATH]\n",
      "[--pretrained_conditioner_path PRETRAINED_CONDITIONER_PATH]\n",
      "[--freeze_conditioner]\n",
      "[--train_sample_id_file TRAIN_SAMPLE_ID_FILE]\n",
      "[--epochs EPOCHS]\n",
      "[--batch_size_per_gpu BATCH_SIZE_PER_GPU]\n",
      "[--lr LR]\n",
      "[--accumulation_steps ACCUMULATION_STEPS]\n",
      "[--mixed_precision {bf16,fp16,no}]\n",
      "[--num_workers NUM_WORKERS]\n",
      "--conditioner_input_dim\n",
      "CONDITIONER_INPUT_DIM\n",
      "--conditioner_hidden_dim\n",
      "CONDITIONER_HIDDEN_DIM\n",
      "--conditioner_output_dim\n",
      "CONDITIONER_OUTPUT_DIM\n",
      "--conditioner_n_layers\n",
      "CONDITIONER_N_LAYERS\n",
      "--conditioner_n_heads\n",
      "CONDITIONER_N_HEADS\n",
      "--conditioner_attn_dropout\n",
      "CONDITIONER_ATTN_DROPOUT\n",
      "--unet_sample_size UNET_SAMPLE_SIZE\n",
      "--unet_in_channels UNET_IN_CHANNELS\n",
      "--unet_out_channels\n",
      "UNET_OUT_CHANNELS\n",
      "--unet_block_out_channels\n",
      "UNET_BLOCK_OUT_CHANNELS\n",
      "--unet_down_block_types\n",
      "UNET_DOWN_BLOCK_TYPES\n",
      "--unet_up_block_types\n",
      "UNET_UP_BLOCK_TYPES\n",
      "--unet_cross_attention_dim\n",
      "UNET_CROSS_ATTENTION_DIM\n",
      "[--scheduler_train_timesteps SCHEDULER_TRAIN_TIMESTEPS]\n",
      "[--sampling_inference_steps SAMPLING_INFERENCE_STEPS]\n",
      "[--checkpoint_filename_prefix CHECKPOINT_FILENAME_PREFIX]\n",
      "[--log_interval LOG_INTERVAL]\n",
      "[--sample_interval_steps SAMPLE_INTERVAL_STEPS]\n",
      "[--save_interval SAVE_INTERVAL]\n",
      "[--seed SEED]\n",
      "train_condition_diffusion_ddp_v3.py: error: argument --freeze_conditioner: ignored explicit argument 'true'\n",
      "usage: train_condition_diffusion_ddp_v3.py [-h] --graph_data_dir\n",
      "GRAPH_DATA_DIR --checkpoint_dir\n",
      "CHECKPOINT_DIR --log_dir LOG_DIR\n",
      "--vae_model_path VAE_MODEL_PATH\n",
      "[--pretrained_unet_path PRETRAINED_UNET_PATH]\n",
      "[--pretrained_conditioner_path PRETRAINED_CONDITIONER_PATH]\n",
      "[--freeze_conditioner]\n",
      "[--train_sample_id_file TRAIN_SAMPLE_ID_FILE]\n",
      "[--epochs EPOCHS]\n",
      "[--batch_size_per_gpu BATCH_SIZE_PER_GPU]\n",
      "[--lr LR]\n",
      "[--accumulation_steps ACCUMULATION_STEPS]\n",
      "[--mixed_precision {bf16,fp16,no}]\n",
      "[--num_workers NUM_WORKERS]\n",
      "--conditioner_input_dim\n",
      "CONDITIONER_INPUT_DIM\n",
      "--conditioner_hidden_dim\n",
      "CONDITIONER_HIDDEN_DIM\n",
      "--conditioner_output_dim\n",
      "CONDITIONER_OUTPUT_DIM\n",
      "--conditioner_n_layers\n",
      "CONDITIONER_N_LAYERS\n",
      "--conditioner_n_heads\n",
      "CONDITIONER_N_HEADS\n",
      "--conditioner_attn_dropout\n",
      "CONDITIONER_ATTN_DROPOUT\n",
      "--unet_sample_size UNET_SAMPLE_SIZE\n",
      "--unet_in_channels UNET_IN_CHANNELS\n",
      "--unet_out_channels\n",
      "UNET_OUT_CHANNELS\n",
      "--unet_block_out_channels\n",
      "UNET_BLOCK_OUT_CHANNELS\n",
      "--unet_down_block_types\n",
      "UNET_DOWN_BLOCK_TYPES\n",
      "--unet_up_block_types\n",
      "UNET_UP_BLOCK_TYPES\n",
      "--unet_cross_attention_dim\n",
      "UNET_CROSS_ATTENTION_DIM\n",
      "[--scheduler_train_timesteps SCHEDULER_TRAIN_TIMESTEPS]\n",
      "[--sampling_inference_steps SAMPLING_INFERENCE_STEPS]\n",
      "[--checkpoint_filename_prefix CHECKPOINT_FILENAME_PREFIX]\n",
      "[--log_interval LOG_INTERVAL]\n",
      "[--sample_interval_steps SAMPLE_INTERVAL_STEPS]\n",
      "[--save_interval SAVE_INTERVAL]\n",
      "[--seed SEED]\n",
      "train_condition_diffusion_ddp_v3.py: error: argument --freeze_conditioner: ignored explicit argument 'true'\n",
      "E0608 22:25:41.043000 97892 micromamba/envs/gpu_env/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 2) local_rank: 0 (pid: 97971) of binary: /public/home/jijh/micromamba/envs/gpu_env/bin/python\n",
      "Traceback (most recent call last):\n",
      "File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "File \"<frozen runpy>\", line 88, in _run_code\n",
      "File \"/public/home/jijh/micromamba/envs/gpu_env/lib/python3.12/site-packages/torch/distributed/run.py\", line 923, in <module>\n",
      "main()\n",
      "File \"/public/home/jijh/micromamba/envs/gpu_env/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
      "return f(*args, **kwargs)\n",
      "^^^^^^^^^^^^^^^^^^\n",
      "File \"/public/home/jijh/micromamba/envs/gpu_env/lib/python3.12/site-packages/torch/distributed/run.py\", line 919, in main\n",
      "run(args)\n",
      "File \"/public/home/jijh/micromamba/envs/gpu_env/lib/python3.12/site-packages/torch/distributed/run.py\", line 910, in run\n",
      "elastic_launch(\n",
      "File \"/public/home/jijh/micromamba/envs/gpu_env/lib/python3.12/site-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
      "return launch_agent(self._config, self._entrypoint, list(args))\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "File \"/public/home/jijh/micromamba/envs/gpu_env/lib/python3.12/site-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n",
      "raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError:\n",
      "============================================================\n",
      "/home1/jijh/diffusion_project/ADiffusion/src/pipeline/train_condition_diffusion_ddp_v3.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "time      : 2025-06-08_22:25:41\n",
      "host      : gpucw1\n",
      "rank      : 1 (local_rank: 1)\n",
      "exitcode  : 2 (pid: 97972)\n",
      "error_file: <N/A>\n",
      "traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "time      : 2025-06-08_22:25:41\n",
      "host      : gpucw1\n",
      "rank      : 0 (local_rank: 0)\n",
      "exitcode  : 2 (pid: 97971)\n",
      "error_file: <N/A>\n",
      "traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "------------------------------\n",
      "--- Script Finished with code 1 ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Launch DDP Training Script for Diffusion V3\n",
    "\n",
    "print(\"\\n--- Preparing to Launch DDP Training for Diffusion Model V3 ---\")\n",
    "\n",
    "if not os.path.exists(config_diff.TRAIN_SCRIPT_PATH):\n",
    "    print(f\"Error: Training script '{config_diff.TRAIN_SCRIPT_PATH}' not found.\")\n",
    "else:\n",
    "    python_executable = sys.executable\n",
    "    modified_env = os.environ.copy()\n",
    "    cuda_visible_devices = \",\".join(map(str, config_diff.GPU_IDS))\n",
    "    modified_env[\"CUDA_VISIBLE_DEVICES\"] = cuda_visible_devices\n",
    "\n",
    "    cmd = [\n",
    "        python_executable, \"-m\", \"torch.distributed.run\",\n",
    "        f\"--nproc_per_node={config_diff.NUM_GPUS}\",\n",
    "        f\"--master_port={config_diff.DDP_MASTER_PORT}\",\n",
    "        config_diff.TRAIN_SCRIPT_PATH,\n",
    "    ]\n",
    "    cmd.extend(config_diff.get_script_args())\n",
    "\n",
    "    print(\"\\nLaunching command:\")\n",
    "    print(shlex.join(cmd))\n",
    "    print(\"-\" * 30 + \"\\nScript Output:\\n\" + \"-\" * 30)\n",
    "\n",
    "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "                               text=True, bufsize=1, encoding='utf-8', errors='replace',\n",
    "                               env=modified_env)\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None: break\n",
    "        if output: print(output.strip())\n",
    "    rc = process.poll()\n",
    "    print(\"-\" * 30 + f\"\\n--- Script Finished with code {rc} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701123e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GPU",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
