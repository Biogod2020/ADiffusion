{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import skimage.io as io\n",
    "import random\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_patches(image, cell_coords, patch_size=100):\n",
    "    \"\"\"\n",
    "    Extract image patches centered on given cell coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): The input image from which patches are to be extracted.\n",
    "    cell_coords (list of tuples): A list of (x, y) coordinates around which patches are to be extracted.\n",
    "    patch_size (int, optional): The size of the square patches to be extracted. Default is 100.\n",
    "\n",
    "    Returns:\n",
    "    list of numpy.ndarray: A list of extracted image patches, all of the same size.\n",
    "\n",
    "    Notes:\n",
    "    - If a patch extends beyond the image border, it will be padded with zeros to match the specified patch size.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    half_size = patch_size // 2\n",
    "    h, w = image.shape[:2]\n",
    "    different_shape_count = 0\n",
    "\n",
    "    # Ensure the input image has 3 dimensions\n",
    "    if len(image.shape) == 2:  # Grayscale image\n",
    "        image = image[:, :, np.newaxis]\n",
    "\n",
    "    for (x, y) in cell_coords:\n",
    "        x, y = int(x), int(y)\n",
    "        x_min, x_max = x - half_size, x + half_size\n",
    "        y_min, y_max = y - half_size, y + half_size\n",
    "\n",
    "        # Initialize the patch with zeros\n",
    "        patch = np.zeros((patch_size, patch_size, image.shape[2]), dtype=image.dtype)\n",
    "\n",
    "        # Calculate bounds for extracting the region from the image\n",
    "        x_start = max(0, x_min)\n",
    "        x_end = min(w, x_max)\n",
    "        y_start = max(0, y_min)\n",
    "        y_end = min(h, y_max)\n",
    "\n",
    "        # Calculate where to place the extracted region in the patch\n",
    "        patch_x_start = max(0, -x_min)\n",
    "        patch_x_end = patch_x_start + (x_end - x_start)\n",
    "        patch_y_start = max(0, -y_min)\n",
    "        patch_y_end = patch_y_start + (y_end - y_start)\n",
    "\n",
    "        # Assign the extracted region into the patch\n",
    "        patch[patch_y_start:patch_y_end, patch_x_start:patch_x_end] = image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        if patch.shape[:2] != (patch_size, patch_size):\n",
    "            different_shape_count += 1\n",
    "\n",
    "        patches.append(patch)\n",
    "\n",
    "    print(f\"Number of patches with different shapes before padding: {different_shape_count}\")\n",
    "    return patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    \"\"\"Initialize random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# Set random seed for reproducibility\n",
    "random_seed = 0\n",
    "seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"/public/home/jijh/st_project/cellbin_analysis/spatial_variation/wx_data/\"  # Directory containing the data files\n",
    "files = os.listdir(file_dir)  # List all files in the directory\n",
    "files = [i for i in files if i.endswith(\".h5ad\") and \"month\" in i]  # Filter files to include only those ending with \".h5ad\" and containing \"month\"\n",
    "file_paths = [os.path.join(file_dir, i) for i in files]  # Create full file paths for the filtered files\n",
    "adatas = {}  # Initialize an empty dictionary to store AnnData objects\n",
    "\n",
    "# Read each file and store the AnnData object in the dictionary\n",
    "for i in range(len(file_paths)):\n",
    "    adatas[files[i].split(\".\")[0]] = sc.read(file_paths[i])\n",
    "\n",
    "# Preprocess each AnnData object\n",
    "for key in adatas.keys():\n",
    "    sc.pp.normalize_total(adatas[key], target_sum=1e4)  # Normalize counts per cell\n",
    "    sc.pp.log1p(adatas[key])  # Logarithmize the data\n",
    "    # sc.pp.scale(adatas[key])  # Scale the data to unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract spatial coordinates for each cell\n",
    "cell_coords = {}\n",
    "for key in adatas.keys():\n",
    "    cell_coords[key] = adatas[key].obsm[\"spatial\"].copy()\n",
    "    \n",
    "# # Calculate the neighborhood graph\n",
    "# for key in adatas.keys():\n",
    "#     sc.pp.neighbors(adatas[key], n_neighbors=15, use_rep=\"spatial\", random_state=random_seed)\n",
    "    \n",
    "# # Extract the spatial neighbors\n",
    "# neighbors = {}\n",
    "# for key in adatas.keys():\n",
    "#     neighbors[key] = adatas[key].obsp[\"connectivities\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors, radius_neighbors_graph\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def construct_affinity_matrix(\n",
    "    coordinates,\n",
    "    mode='radius',\n",
    "    cutoff=1.0,\n",
    "    n_neighbors=5,\n",
    "    metric='euclidean'\n",
    "):\n",
    "    \"\"\"\n",
    "    Constructs a neighbors affinity matrix based on either radius cutoff or number of neighbors.\n",
    "\n",
    "    Parameters:\n",
    "    - coordinates: (N, D) array of cell coordinates.\n",
    "    - mode: 'radius' or 'number' to choose the cutoff method.\n",
    "    - cutoff: radius value if mode='radius'.\n",
    "    - n_neighbors: number of neighbors if mode='number'.\n",
    "    - metric: distance metric to use.\n",
    "\n",
    "    Returns:\n",
    "    - affinity_matrix: (N, N) sparse matrix with inverse distance weights.\n",
    "    - island_indices: List of indices representing island points.\n",
    "    \"\"\"\n",
    "    N = coordinates.shape[0]\n",
    "    island_indices = []\n",
    "\n",
    "    if mode == 'radius':\n",
    "        # Use radius_neighbors_graph to get adjacency based on radius\n",
    "        adjacency = radius_neighbors_graph(coordinates, radius=cutoff, mode='connectivity', metric=metric, include_self=False)\n",
    "\n",
    "        # Get distances for the connected pairs\n",
    "        nbrs = NearestNeighbors(radius=cutoff, metric=metric)\n",
    "        nbrs.fit(coordinates)\n",
    "        distances = nbrs.radius_neighbors(coordinates, return_distance=True)[0]\n",
    "        indices = nbrs.radius_neighbors(coordinates, return_distance=True)[1]\n",
    "\n",
    "        # Construct data for sparse matrix\n",
    "        row = []\n",
    "        col = []\n",
    "        data = []\n",
    "        for i in range(N):\n",
    "            neighbors = indices[i]\n",
    "            dists = distances[i]\n",
    "            for j, dist in zip(neighbors, dists):\n",
    "                if dist > 0:  # Avoid division by zero\n",
    "                    row.append(i)\n",
    "                    col.append(j)\n",
    "                    data.append(1.0 / dist)\n",
    "\n",
    "        affinity_matrix = csr_matrix((data, (row, col)), shape=(N, N))\n",
    "\n",
    "        # Identify island points (points with zero neighbors)\n",
    "        num_neighbors = adjacency.sum(axis=1).A1\n",
    "        island_indices = np.where(num_neighbors == 0)[0]\n",
    "        num_islands = len(island_indices)\n",
    "\n",
    "        # Visualization: Distribution of number of neighbors\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.hist(num_neighbors, bins=30, color='skyblue', edgecolor='black')\n",
    "        plt.title('Distribution of Number of Neighbors (Radius Cutoff)')\n",
    "        plt.xlabel('Number of Neighbors')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    elif mode == 'number':\n",
    "        if n_neighbors < 0:\n",
    "            raise ValueError(\"Number of neighbors must be non-negative.\")\n",
    "        elif n_neighbors == 0:\n",
    "            # All points are islands\n",
    "            affinity_matrix = csr_matrix((N, N), dtype=float)\n",
    "            island_indices = np.arange(N)\n",
    "            num_islands = N\n",
    "            # Visualization: All points have zero neighbors\n",
    "            plt.figure(figsize=(8,6))\n",
    "            plt.hist(np.zeros(N), bins=1, color='lightgreen', edgecolor='black')\n",
    "            plt.title('All Points are Islands (n_neighbors=0)')\n",
    "            plt.xlabel('Number of Neighbors')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "            return affinity_matrix, island_indices\n",
    "\n",
    "        # Ensure n_neighbors does not exceed N-1\n",
    "        actual_n_neighbors = min(n_neighbors, N-1)\n",
    "\n",
    "        # Use NearestNeighbors to get fixed number of neighbors\n",
    "        nbrs = NearestNeighbors(n_neighbors=actual_n_neighbors + 1, metric=metric)  # +1 because the first neighbor is itself\n",
    "        nbrs.fit(coordinates)\n",
    "        distances, indices = nbrs.kneighbors(coordinates)\n",
    "\n",
    "        # Exclude the first column (distance to itself)\n",
    "        distances = distances[:, 1:]\n",
    "        indices = indices[:, 1:]\n",
    "\n",
    "        # Handle cases where actual_n_neighbors < n_neighbors\n",
    "        # This can happen if N <= n_neighbors\n",
    "        valid_mask = distances > 0\n",
    "        distances = distances * valid_mask\n",
    "        indices = indices * valid_mask\n",
    "\n",
    "        # Construct data for sparse matrix\n",
    "        row = np.repeat(np.arange(N), actual_n_neighbors)\n",
    "        col = indices.flatten()\n",
    "        # Avoid division by zero\n",
    "        with np.errstate(divide='ignore'):\n",
    "            inv_distances = 1.0 / distances.flatten()\n",
    "        inv_distances[~np.isfinite(inv_distances)] = 0  # Handle zero distances\n",
    "\n",
    "        data = inv_distances\n",
    "\n",
    "        affinity_matrix = csr_matrix((data, (row, col)), shape=(N, N))\n",
    "\n",
    "        # Identify island points (points with zero neighbors)\n",
    "        # In number mode, typically no islands if n_neighbors >=1\n",
    "        # However, if actual_n_neighbors <1, some points may have zero neighbors\n",
    "        num_neighbors = (affinity_matrix > 0).sum(axis=1).A1\n",
    "        island_indices = np.where(num_neighbors == 0)[0]\n",
    "        num_islands = len(island_indices)\n",
    "\n",
    "        # Visualization: Distribution of distances to central cells\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.hist(distances.flatten(), bins=30, color='lightgreen', edgecolor='black')\n",
    "        plt.title('Distribution of Distances to Neighbors (Fixed Number of Neighbors)')\n",
    "        plt.xlabel('Distance')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be 'radius' or 'number'\")\n",
    "\n",
    "    # Plot the coordinates and highlight island points\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.scatter(coordinates[:,0], coordinates[:,1], c='blue', label='Points', alpha=0.6, edgecolor='k', s=50)\n",
    "    if len(island_indices) > 0:\n",
    "        plt.scatter(coordinates[island_indices,0], coordinates[island_indices,1], \n",
    "                    c='red', label='Island Points', edgecolor='k', s=100, marker='s')\n",
    "    plt.title('Cell Coordinates with Island Points Highlighted')\n",
    "    plt.xlabel('X Coordinate')\n",
    "    plt.ylabel('Y Coordinate')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Number of island points: {num_islands}\")\n",
    "    if num_islands > 0:\n",
    "        print(f\"Island point indices: {island_indices}\")\n",
    "\n",
    "    return affinity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = {}\n",
    "for key in cell_coords.keys():\n",
    "    neighbors[key] = construct_affinity_matrix(cell_coords[key], mode='radius', cutoff=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the plaque dataset\n",
    "img_dir = \"/public/home/jijh/st_project/cellbin_analysis/spatial_variation/wx_data/protein_seg_result/\"\n",
    "img_files = os.listdir(img_dir)\n",
    "img_files = [i for i in img_files if i.endswith(\".tiff\") and \"plaque\" in i]\n",
    "# Read the images\n",
    "\n",
    "imgs = {}\n",
    "for i in range(len(img_files)):\n",
    "    imgs[img_files[i].split(\".\")[0]] = io.imread(os.path.join(img_dir, img_files[i]))\n",
    "imgs.keys()\n",
    "# Rename the imgs to match the adata keys\n",
    "for key in list(imgs.keys()):\n",
    "    parts = key.split(\"_\")\n",
    "    if len(parts) > 1:\n",
    "        new_key = parts[1] + \"_\" + parts[2]\n",
    "        imgs[new_key] = imgs.pop(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches from the images\n",
    "patches = {}\n",
    "for key in imgs.keys():\n",
    "    patches[key] = extract_patches(imgs[key], cell_coords[key], patch_size=128)\n",
    "\n",
    "# Extract the positive patches\n",
    "positive_patches = {}\n",
    "for key in patches.keys():\n",
    "    pos_list = []\n",
    "    for i in range(len(patches[key])):\n",
    "        if np.sum(patches[key][i]) > 0:\n",
    "            pos_list.append(patches[key][i])\n",
    "    positive_patches[key] = pos_list\n",
    "\n",
    "# Convert the patches to binary and calculate the area of positive pixels for each patch\n",
    "binary_patches = {}\n",
    "for key in patches.keys():\n",
    "    binary_patches[key] = [patch > 0 for patch in patches[key]]\n",
    "# Calculate the area of positive pixels for each patch\n",
    "areas = {}\n",
    "for key in binary_patches.keys():\n",
    "    areas[key] = [np.sum(patch) for patch in binary_patches[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 5 patches with non-zero area for each image and plot them\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the number of patches to plot\n",
    "n_patches = 5\n",
    "\n",
    "# Plot the patches\n",
    "fig, axes = plt.subplots(nrows=len(areas), ncols=n_patches, figsize=(15, 15))\n",
    "axes = np.atleast_2d(axes)  # Ensure axes is 2D for consistent indexing\n",
    "\n",
    "for i, key in enumerate(areas.keys()):\n",
    "    non_zero_indices = np.where(np.array(areas[key]) > 0)[0]\n",
    "    chosen_indices = random.sample(list(non_zero_indices), n_patches)\n",
    "    for j, idx in enumerate(chosen_indices):\n",
    "        axes[i, j].imshow(patches[key][idx], cmap=\"gray\")\n",
    "        axes[i, j].set_title(f\"Area: {areas[key][idx]}\")\n",
    "        axes[i, j].axis(\"off\")\n",
    "    axes[i, 0].set_ylabel(key, rotation=0, size=\"large\", labelpad=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy.sparse\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def create_graph_data_dict(adatas, areas, neighbors, cell_coords):\n",
    "    \"\"\"\n",
    "    Create a dictionary of PyTorch Geometric Data objects from AnnData objects.\n",
    "    \n",
    "    Parameters:\n",
    "    - adatas: dict of AnnData objects\n",
    "    - areas: dict of patch areas\n",
    "    - neighbors: dict of connectivity matrices (affinity matrices with weights)\n",
    "    - cell_coords: dict of spatial coordinates\n",
    "    \n",
    "    Returns:\n",
    "    - graph_data_dict: dict of PyTorch Geometric Data objects\n",
    "    \"\"\"\n",
    "    graph_data_dict = {}\n",
    "\n",
    "    for key in tqdm(adatas.keys(), desc=\"Creating graph data\"):\n",
    "        # Ensure the keys match between adata and patches\n",
    "        if key not in areas:\n",
    "            print(f\"Warning: No patch area data for '{key}'. Skipping.\")\n",
    "            continue\n",
    "        if key not in neighbors:\n",
    "            print(f\"Warning: No neighbors data for '{key}'. Skipping.\")\n",
    "            continue\n",
    "        if key not in cell_coords:\n",
    "            print(f\"Warning: No cell coordinates data for '{key}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        adata = adatas[key]\n",
    "        num_cells = adata.n_obs\n",
    "\n",
    "        # Features: Gene expression data\n",
    "        # Assuming 'X' is already a NumPy array after preprocessing\n",
    "        features = adata.X\n",
    "        if scipy.sparse.issparse(features):\n",
    "            features = features.toarray()\n",
    "        features = torch.tensor(features, dtype=torch.float)\n",
    "\n",
    "        # Labels: Patch areas\n",
    "        label_areas = areas[key]\n",
    "        if len(label_areas) != num_cells:\n",
    "            print(f\"Warning: Number of patches and cells do not match for '{key}'.\")\n",
    "            # Handle mismatch by trimming to the minimum length\n",
    "            min_len = min(len(label_areas), num_cells)\n",
    "            label_areas = label_areas[:min_len]\n",
    "            features = features[:min_len]\n",
    "            num_cells = min_len  # Update num_cells accordingly\n",
    "\n",
    "        labels = torch.tensor(label_areas, dtype=torch.float).unsqueeze(1)  # Shape: [num_nodes, 1]\n",
    "\n",
    "        # Edges: Connectivity matrix (Affinity matrix with weights)\n",
    "        connectivity = neighbors[key].tocoo()\n",
    "\n",
    "        # Extract edge indices\n",
    "        edge_index = torch.tensor(\n",
    "            np.vstack([connectivity.row, connectivity.col]),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        # Extract edge weights (inverse distances)\n",
    "        edge_weights = torch.tensor(connectivity.data, dtype=torch.float).unsqueeze(1)  # Shape: [num_edges, 1]\n",
    "\n",
    "        # Create PyTorch Geometric Data object\n",
    "        data = Data(\n",
    "            x=features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_weights,\n",
    "            y=labels\n",
    "        )\n",
    "\n",
    "        # Optionally, add additional information (e.g., spatial coordinates)\n",
    "        spatial = torch.tensor(cell_coords[key], dtype=torch.float)\n",
    "        data.pos = spatial  # 'pos' is a standard attribute in PyTorch Geometric for node positions\n",
    "        \n",
    "\n",
    "        # Add to the dictionary\n",
    "        graph_data_dict[key] = data\n",
    "\n",
    "    return graph_data_dict\n",
    "\n",
    "\n",
    "\n",
    "# Create the graph dictionary\n",
    "graph_data_dict = create_graph_data_dict(adatas, areas, neighbors, cell_coords)\n",
    "\n",
    "\n",
    "# Efficiently convert patches to tensors in batch\n",
    "for key, graph in tqdm(graph_data_dict.items(), desc=\"Adding patches to graph data\"):\n",
    "    # Ensure patches[key] is a list of NumPy arrays\n",
    "    patches_tensor = torch.tensor(np.array(patches[key]), dtype=torch.float)  # Convert patches to a single tensor efficiently\n",
    "    graph.patches = patches_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_dict['13months-disease-replicate_1'].edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check system's gpu info\n",
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction & Represenation of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, global_mean_pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_replicate_name = '13months-disease-replicate_2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_val_datalist = []\n",
    "test_data = None\n",
    "\n",
    "for name, raw_data in graph_data_dict.items():\n",
    "    data = raw_data.clone()\n",
    "    data.y = (data.y > 0).float()  # Binarize\n",
    "\n",
    "    if name == test_replicate_name:\n",
    "        # This entire graph is our final test set.\n",
    "        test_data = data\n",
    "    else:\n",
    "        # We do random node-level splits for training & validation\n",
    "        num_nodes = data.x.size(0)\n",
    "        perm = torch.randperm(num_nodes)\n",
    "\n",
    "        train_cutoff = int(0.8 * num_nodes)\n",
    "        val_cutoff   = int(0.9 * num_nodes)\n",
    "\n",
    "        data.train_idx = perm[:train_cutoff]\n",
    "        data.val_idx   = perm[train_cutoff:val_cutoff]\n",
    "        data.mini_test_idx = perm[val_cutoff:]  # optional mini-test\n",
    "\n",
    "        train_val_datalist.append(data)\n",
    "\n",
    "# Move test_data to device\n",
    "test_data = test_data.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNClassifier(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels=1, residual=True, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # -- GCN Layer --\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_channels)\n",
    "        \n",
    "        # -- GraphSAGE Layer --\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_channels)\n",
    "\n",
    "        # Optional skip connection parameter\n",
    "        self.residual = residual\n",
    "\n",
    "        # -- Final MLP block --\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        # --- First layer: GCN ---\n",
    "        out1 = self.conv1(x, edge_index)\n",
    "        out1 = self.bn1(out1)\n",
    "        out1 = F.relu(out1)\n",
    "        out1 = self.dropout(out1)\n",
    "        \n",
    "        # --- Second layer: GraphSAGE ---\n",
    "        out2 = self.conv2(out1, edge_index)\n",
    "        out2 = self.bn2(out2)\n",
    "        out2 = F.relu(out2)\n",
    "        out2 = self.dropout(out2)\n",
    "        \n",
    "        # --- Residual Connection (optional) ---\n",
    "        if self.residual:\n",
    "            out2 = out1 + out2  # Skip connection\n",
    "\n",
    "        # If graph-level classification, you'd pool here:\n",
    "        #   out2 = global_mean_pool(out2, batch)\n",
    "        # But for node-level, we skip global pooling.\n",
    "\n",
    "        # --- Final MLP (per node) ---\n",
    "        out = self.mlp(out2)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train_classifier(model, optimizer, datalist):\n",
    "    \"\"\" Train on the 'train_idx' of each graph in datalist. \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for data in datalist:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index).squeeze()  # shape: [num_nodes]\n",
    "        \n",
    "        train_labels = data.y[data.train_idx].view(-1)\n",
    "        train_preds  = out[data.train_idx]              # shape: [num_train_nodes]\n",
    "        \n",
    "        loss = criterion(train_preds, train_labels)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Single optimizer step for all graphs combined\n",
    "    optimizer.step()\n",
    "    return total_loss / len(datalist)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_classifier(model, datalist, split=\"val_idx\"):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the given split of each graph in datalist.\n",
    "    Return average (loss, accuracy, AUC) across all graphs.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_nodes   = 0\n",
    "    all_labels    = []\n",
    "    all_scores    = []\n",
    "    \n",
    "    for data in datalist:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index).squeeze()\n",
    "        \n",
    "        idx = getattr(data, split)  # e.g. data.val_idx\n",
    "        labels = data.y[idx].view(-1)\n",
    "        preds  = out[idx]\n",
    "        \n",
    "        # BCEWithLogitsLoss\n",
    "        loss = criterion(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Accuracy\n",
    "        prob = torch.sigmoid(preds)\n",
    "        binary_pred = (prob > 0.5).float()\n",
    "        correct = (binary_pred == labels).sum().item()\n",
    "        \n",
    "        total_correct += correct\n",
    "        total_nodes   += len(labels)\n",
    "        \n",
    "        # For AUC\n",
    "        all_labels.append(labels.cpu())\n",
    "        all_scores.append(prob.cpu())\n",
    "    \n",
    "    avg_loss = total_loss / len(datalist)\n",
    "    avg_acc  = total_correct / total_nodes\n",
    "    \n",
    "    # Compute AUC across all graphs combined\n",
    "    all_labels = torch.cat(all_labels, dim=0).numpy()\n",
    "    all_scores = torch.cat(all_scores, dim=0).numpy()\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_scores)\n",
    "    except ValueError:\n",
    "        # If all labels are 0 or 1, AUC can be undefined\n",
    "        auc = float('nan')\n",
    "    \n",
    "    return avg_loss, avg_acc, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = train_val_datalist[0].x.size(1)\n",
    "\n",
    "pre_model = GNNClassifier(\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels=128,\n",
    "    dropout=0.6\n",
    ").to(device)\n",
    "\n",
    "pre_model.apply(weights_init)\n",
    "\n",
    "optimizer = torch.optim.Adam(pre_model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc = 0.0\n",
    "best_state = None\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_aucs = []\n",
    "\n",
    "EPOCHS = 1000\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Training on multiple graphs\"):\n",
    "    # 1) Train step (all training graphs)\n",
    "    train_loss = train_classifier(pre_model, optimizer, train_val_datalist)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # 2) Validation step (all training graphs)\n",
    "    val_loss, val_acc, val_auc = evaluate_classifier(pre_model, train_val_datalist, split=\"val_idx\")\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_aucs.append(val_auc)\n",
    "\n",
    "    # Track best model by validation accuracy\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = pre_model.state_dict()\n",
    "\n",
    "# Reload best model\n",
    "if best_state is not None:\n",
    "    pre_model.load_state_dict(best_state)\n",
    "\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Changes Over Epochs (Combined Training Set)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Validation Accuracy Changes Over Epochs (Combined)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_aucs, label='Validation AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.title('Validation AUC Changes Over Epochs (Combined)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_on_withheld_graph(model, data):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    \n",
    "    logits = model(data.x, data.edge_index).squeeze()\n",
    "    labels = data.y.view(-1)\n",
    "    \n",
    "    loss = criterion(logits, labels).item()\n",
    "    probs = torch.sigmoid(logits)\n",
    "    binary_pred = (probs > 0.5).float()\n",
    "    \n",
    "    correct = (binary_pred == labels).sum().item()\n",
    "    acc = correct / labels.size(0)\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(labels.cpu(), probs.cpu())\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    \n",
    "    return loss, acc, auc\n",
    "\n",
    "test_loss, test_acc, test_auc = test_on_withheld_graph(pre_model, test_data)\n",
    "print(f\"\\n=== Final Test on '{test_replicate_name}' ===\")\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f} | Test AUC: {test_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from the classifier\n",
    "pre_model.eval()\n",
    "data = graph_data_dict['8months-disease-replicate_1'].clone().to(device)\n",
    "with torch.no_grad():\n",
    "    logits = pre_model(data.x, data.edge_index).squeeze()\n",
    "    preds = (logits.sigmoid() > 0.5).float()\n",
    "\n",
    "# Identify positive nodes\n",
    "positive_nodes = (preds == 1).nonzero(as_tuple=True)[0]\n",
    "\n",
    "# Visualize a subset of the positive nodes' patches images\n",
    "num_images_to_plot = min(5, len(positive_nodes))  # Plot up to 5 images\n",
    "fig, axes = plt.subplots(1, num_images_to_plot, figsize=(15, 5))\n",
    "axes = np.atleast_1d(axes)\n",
    "\n",
    "# Randomly select positive nodes to plot\n",
    "random_positive_nodes = random.sample(list(positive_nodes), num_images_to_plot)\n",
    "\n",
    "for i, node in enumerate(random_positive_nodes):\n",
    "    patch = data.patches[node].squeeze().to(\"cpu\").numpy()\n",
    "    axes[i].imshow(patch, cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f\"Node: {node.item()}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the positive nodes in a dictionary\n",
    "positive_nodes_dict = {}\n",
    "\n",
    "for key, data in graph_data_dict.items():\n",
    "    data = data.clone().to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = pre_model(data.x, data.edge_index).squeeze()\n",
    "        preds = (logits.sigmoid() > 0.5).float()\n",
    "    positive_nodes = (preds == 1).nonzero(as_tuple=True)[0]\n",
    "    positive_nodes_dict[key] = positive_nodes\n",
    "\n",
    "#  Print the number of positive nodes for each replicate\n",
    "for key, nodes in positive_nodes_dict.items():\n",
    "    print(f\"Number of positive nodes in '{key}': {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_dict['8months-disease-replicate_1'].edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the graph data dictionary and the positive nodes dictionary\n",
    "save_dir = \"/public/home/jijh/diffusion_project/data_storage\"\n",
    "\n",
    "torch.save(graph_data_dict, os.path.join(save_dir,\"not_scaled_graph_data_dict.pth\"))\n",
    "torch.save(positive_nodes_dict, os.path.join(save_dir,\"not_scaled_positive_nodes_dict.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact plaque size prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, BatchNorm\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# =====================================\n",
    "# Step 1: Data Preparation\n",
    "# =====================================\n",
    "\n",
    "# Assuming graph_data_dict and positive_nodes_dict are predefined\n",
    "# Example:\n",
    "# graph_data_dict = {\n",
    "#     'graph1': Data(x=..., edge_index=..., y=...),\n",
    "#     'graph2': Data(x=..., edge_index=..., y=...),\n",
    "#     ...\n",
    "# }\n",
    "# positive_nodes_dict = {\n",
    "#     'graph1': torch.tensor([...]),\n",
    "#     'graph2': torch.tensor([...]),\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "test_replicate_name = '13months-disease-replicate_2'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_val_datalist = []\n",
    "test_data = None\n",
    "\n",
    "# Initialize scalers\n",
    "feature_scaler = StandardScaler()\n",
    "target_scaler = StandardScaler()\n",
    "\n",
    "# Collect all node features and targets for scaling\n",
    "all_features = []\n",
    "all_targets = []\n",
    "\n",
    "for name, raw_data in graph_data_dict.items():\n",
    "    data = raw_data.clone()\n",
    "    all_features.append(data.x.cpu().numpy())\n",
    "    all_targets.append(data.y.cpu().numpy())\n",
    "\n",
    "# Fit scalers\n",
    "all_features = np.vstack(all_features)\n",
    "feature_scaler.fit(all_features)\n",
    "\n",
    "all_targets = np.concatenate(all_targets).reshape(-1, 1)\n",
    "target_scaler.fit(all_targets)\n",
    "\n",
    "for name, raw_data in graph_data_dict.items():\n",
    "    data = raw_data.clone()\n",
    "    \n",
    "    # Normalize node features\n",
    "    data.x = torch.tensor(feature_scaler.transform(data.x.cpu()), dtype=torch.float32)\n",
    "    \n",
    "    # Normalize target\n",
    "    data.y = torch.tensor(target_scaler.transform(data.y.cpu().numpy().reshape(-1, 1)).flatten(), dtype=torch.float32)\n",
    "    \n",
    "    if name == test_replicate_name:\n",
    "        # Assign the entire test graph\n",
    "        test_data = data.to(device)\n",
    "        # Assign only positive nodes for testing\n",
    "        test_data.test_idx = positive_nodes_dict[name].to(device)\n",
    "    else:\n",
    "        # Retrieve positive nodes for the current graph\n",
    "        positive_nodes = positive_nodes_dict[name]\n",
    "        num_positive = positive_nodes.size(0)\n",
    "        \n",
    "        if num_positive == 0:\n",
    "            print(f\"No positive nodes found in '{name}'. Skipping this graph.\")\n",
    "            continue  # Skip graphs with no positive nodes\n",
    "        \n",
    "        # Shuffle positive node indices\n",
    "        perm = torch.randperm(num_positive)\n",
    "        \n",
    "        # Split positive nodes into train and validation\n",
    "        train_cutoff = int(0.8 * num_positive)\n",
    "        val_cutoff   = int(0.9 * num_positive)\n",
    "        \n",
    "        data.train_idx = positive_nodes[perm[:train_cutoff]].to(device)\n",
    "        data.val_idx   = positive_nodes[perm[train_cutoff:val_cutoff]].to(device)\n",
    "        # data.mini_test_idx = positive_nodes[perm[val_cutoff:]].to(device)  # Optional\n",
    "        \n",
    "        train_val_datalist.append(data.to(device))\n",
    "\n",
    "test_datalist = [test_data] if test_data is not None else []\n",
    "\n",
    "# =====================================\n",
    "# Step 2: Define the Simplified GNN Regressor Model\n",
    "# =====================================\n",
    "\n",
    "class SimplifiedGNNRegressor(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels=1, dropout=0.3):\n",
    "        super(SimplifiedGNNRegressor, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.bn1 = BatchNorm(hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.bn2 = BatchNorm(hidden_channels)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels // 2, out_channels)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()  # [num_nodes]\n",
    "\n",
    "# =====================================\n",
    "# Step 3: Initialize Model, Optimizer, and Loss Function\n",
    "# =====================================\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Linear, nn.Conv1d)):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "# Determine the number of input features\n",
    "if not train_val_datalist:\n",
    "    raise ValueError(\"No training/validation data available. Check positive_nodes_dict and graph_data_dict.\")\n",
    "in_channels = train_val_datalist[0].x.size(1)\n",
    "\n",
    "# Initialize the model\n",
    "model = SimplifiedGNNRegressor(\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels=64,  # Reduced from 128\n",
    "    dropout=0.3  # Reduced from 0.6\n",
    ").to(device)\n",
    "\n",
    "# Apply weight initialization\n",
    "model.apply(weights_init)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=100, verbose=True)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# =====================================\n",
    "# Step 4: Define Training and Evaluation Functions\n",
    "# =====================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_regressor(model, datalist, split=\"val_idx\"):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the given split of each graph in datalist.\n",
    "    Returns average MSE, MAE, RMSE, MAE overall, R², and all labels and predictions.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_mae = 0.0\n",
    "    total_nodes = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    for data in datalist:\n",
    "        out = model(data.x, data.edge_index).squeeze()\n",
    "        \n",
    "        idx = getattr(data, split, None)\n",
    "        if idx is None or idx.numel() == 0:\n",
    "            continue\n",
    "        \n",
    "        labels = data.y[idx].view(-1)\n",
    "        preds = out[idx]\n",
    "        \n",
    "        loss = criterion(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        mae = F.l1_loss(preds, labels, reduction='sum').item()\n",
    "        total_mae += mae\n",
    "        \n",
    "        total_nodes += labels.size(0)\n",
    "        \n",
    "        all_labels.append(labels.cpu())\n",
    "        all_preds.append(preds.cpu())\n",
    "    \n",
    "    if total_nodes == 0:\n",
    "        return float('nan'), float('nan'), float('nan'), float('nan'), None, None\n",
    "    \n",
    "    avg_loss = total_loss / len(datalist)\n",
    "    avg_mae = total_mae / total_nodes\n",
    "    \n",
    "    all_labels_np = torch.cat(all_labels, dim=0).numpy()\n",
    "    all_preds_np = torch.cat(all_preds, dim=0).numpy()\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(all_labels_np, all_preds_np))\n",
    "    mae_overall = mean_absolute_error(all_labels_np, all_preds_np)\n",
    "    r2 = r2_score(all_labels_np, all_preds_np)\n",
    "    \n",
    "    return avg_loss, avg_mae, rmse, mae_overall, r2, (all_labels_np, all_preds_np)\n",
    "\n",
    "def train_regressor(model, optimizer, datalist):\n",
    "    \"\"\" Train on the 'train_idx' of each graph in datalist. \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for data in datalist:\n",
    "        out = model(data.x, data.edge_index).squeeze()\n",
    "        \n",
    "        if data.train_idx.numel() == 0:\n",
    "            continue  # Skip if there are no training nodes\n",
    "        \n",
    "        train_labels = data.y[data.train_idx].view(-1)\n",
    "        train_preds  = out[data.train_idx]              # shape: [num_train_nodes]\n",
    "        \n",
    "        loss = criterion(train_preds, train_labels)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Gradient clipping (optional)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "    \n",
    "    # Single optimizer step for all graphs combined\n",
    "    optimizer.step()\n",
    "    \n",
    "    return total_loss / len(datalist)\n",
    "\n",
    "# =====================================\n",
    "# Step 5: Training Loop with Early Stopping\n",
    "# =====================================\n",
    "\n",
    "best_val_rmse = float('inf')\n",
    "best_state = None\n",
    "patience = 500\n",
    "trigger_times = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_maes = []\n",
    "val_rmses = []\n",
    "val_r2s = []\n",
    "\n",
    "test_losses = []\n",
    "test_maes = []\n",
    "test_rmses = []\n",
    "test_r2s = []\n",
    "\n",
    "EPOCHS = 5000\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Training\"):\n",
    "    # 1) Train step (all training graphs)\n",
    "    train_loss = train_regressor(model, optimizer, train_val_datalist)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # 2) Validation step (all training graphs)\n",
    "    val_loss, val_mae, val_rmse, val_mae_overall, val_r2, _ = evaluate_regressor(model, train_val_datalist, split=\"val_idx\")\n",
    "    val_losses.append(val_loss)\n",
    "    val_maes.append(val_mae)\n",
    "    val_rmses.append(val_rmse)\n",
    "    val_r2s.append(val_r2)\n",
    "\n",
    "    # 3) Update scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 4) Early Stopping Check\n",
    "    if not np.isnan(val_rmse) and val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_state = model.state_dict()\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "\n",
    "    if trigger_times >= patience:\n",
    "        print(\"Early stopping!\")\n",
    "        break\n",
    "\n",
    "    # Optional: Print progress every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Val RMSE={val_rmse:.4f}, Val R²={val_r2:.4f}\")\n",
    "\n",
    "# Load Best Model\n",
    "if best_state:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "print(f\"Best validation RMSE: {best_val_rmse:.4f}\")\n",
    "\n",
    "# =====================================\n",
    "# Step 6: Plotting Results\n",
    "# =====================================\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train MSE Loss')\n",
    "plt.plot(val_losses, label='Validation MSE Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Plot Validation RMSE and R²\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Validation RMSE', color=color)\n",
    "ax1.plot(val_rmses, color=color, label='Validation RMSE')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Validation R²', color=color)\n",
    "ax2.plot(val_r2s, color=color, label='Validation R²')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.title('Validation RMSE and R² Over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot: Predicted vs. Actual on Validation Set\n",
    "_, _, _, _, val_r2, (val_labels, val_preds) = evaluate_regressor(\n",
    "    model, \n",
    "    train_val_datalist, \n",
    "    split=\"val_idx\"\n",
    ")\n",
    "\n",
    "if val_labels is not None and val_preds is not None:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.scatterplot(x=val_labels, y=val_preds, alpha=0.6)\n",
    "    plt.plot([val_labels.min(), val_labels.max()], [val_labels.min(), val_labels.max()], 'r--')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title(f'Predicted vs. Actual Values on Validation Set\\nR² = {val_r2:.3f}')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No positive nodes available in the validation split for plotting.\")\n",
    "\n",
    "# =====================================\n",
    "# Step 7: Final Testing on Withheld Graph\n",
    "# =====================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_on_withheld_graph_regression(model, data):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index).squeeze()\n",
    "    \n",
    "    idx = data.test_idx  # Use only positive nodes for testing\n",
    "    if idx.numel() == 0:\n",
    "        print(\"No positive nodes in the test graph.\")\n",
    "        return float('nan'), float('nan'), float('nan'), float('nan')\n",
    "    \n",
    "    labels = data.y[idx].view(-1)\n",
    "    preds  = out[idx]\n",
    "    \n",
    "    # Inverse transform to original scale\n",
    "    labels = target_scaler.inverse_transform(labels.cpu().numpy().reshape(-1, 1)).flatten()\n",
    "    preds = target_scaler.inverse_transform(preds.cpu().numpy().reshape(-1, 1)).flatten()\n",
    "    \n",
    "    loss = mean_squared_error(labels, preds)\n",
    "    mae = mean_absolute_error(labels, preds)\n",
    "    rmse = np.sqrt(loss)\n",
    "    r2 = r2_score(labels, preds)\n",
    "    \n",
    "    return loss, mae, rmse, r2\n",
    "\n",
    "if test_data is not None:\n",
    "    test_loss, test_mae, test_rmse, test_r2 = test_on_withheld_graph_regression(model, test_data)\n",
    "    print(f\"\\n=== Final Test on '{test_replicate_name}' ===\")\n",
    "    print(f\"Test MSE: {test_loss:.4f} | Test MAE: {test_mae:.4f} | Test RMSE: {test_rmse:.4f} | Test R²: {test_r2:.4f}\")\n",
    "else:\n",
    "    print(\"No test data available.\")\n",
    "\n",
    "# Optional: Scatter Plot for Test Set\n",
    "if test_data is not None:\n",
    "    with torch.no_grad():\n",
    "        out = model(test_data.x, test_data.edge_index).squeeze()\n",
    "        idx = test_data.test_idx\n",
    "        labels = test_data.y[idx].view(-1)\n",
    "        preds = out[idx]\n",
    "        \n",
    "        # Inverse transform to original scale\n",
    "        labels = target_scaler.inverse_transform(labels.cpu().numpy().reshape(-1, 1)).flatten()\n",
    "        preds = target_scaler.inverse_transform(preds.cpu().numpy().reshape(-1, 1)).flatten()\n",
    "        \n",
    "        if len(labels) > 0:\n",
    "            test_r2 = r2_score(labels, preds)\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            sns.scatterplot(x=labels, y=preds, alpha=0.6)\n",
    "            plt.plot([labels.min(), labels.max()], [labels.min(), labels.max()], 'r--')\n",
    "            plt.xlabel('Actual Values')\n",
    "            plt.ylabel('Predicted Values')\n",
    "            plt.title(f'Predicted vs. Actual Values on Test Set\\nR² = {test_r2:.3f}')\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"No positive nodes available in the test split for plotting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nan_in_edge_indices(datalist):\n",
    "    for idx, data in enumerate(datalist):\n",
    "        edge_idx = data.edge_index\n",
    "        if torch.isnan(edge_idx).any():\n",
    "            print(f\"NaNs found in edge indices for graph index {idx}.\")\n",
    "            return True\n",
    "    print(\"No NaNs found in edge indices.\")\n",
    "    return False\n",
    "\n",
    "# Usage\n",
    "has_nan_edge = check_nan_in_edge_indices(train_val_datalist)\n",
    "if has_nan_edge:\n",
    "    # Handle NaNs appropriately\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Could Start From Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the saved dictionaries\n",
    "save_dir = \"/public/home/jijh/diffusion_project/data_storage\"\n",
    "graph_data_dict = torch.load(os.path.join(save_dir,\"graph_data_dict.pth\"))\n",
    "positive_nodes_dict = torch.load(os.path.join(save_dir,\"positive_nodes_dict.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to use diffusers to construct the latent conditional diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import transform functions from torchvision\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# Create a dataset of only positive patches\n",
    "class PositivePatchDataset(Dataset):\n",
    "    def __init__(self, patches, device):\n",
    "        self.patches = patches.to(device)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.patches.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patch = self.patches[idx]  # [1,128,128]\n",
    "        # Convert to PIL and back to tensor for augmentations\n",
    "        patch_np = (patch.squeeze(0).cpu().numpy() * 255).astype(np.uint8)\n",
    "        # Now apply transforms\n",
    "        patch_pil = transforms.ToPILImage()(patch_np)\n",
    "        patch_pil = self.transform(patch_pil)\n",
    "        patch_tensor = transforms.ToTensor()(patch_pil).to(self.patches.device)  # [1,128,128], float in [0,1]\n",
    "        return patch_tensor\n",
    "    \n",
    "# Filter for positive nodes\n",
    "positive_pathces = []\n",
    "\n",
    "for key, data in graph_data_dict.items():\n",
    "    positive_nodes = positive_nodes_dict[key].cpu()\n",
    "    positive_patches_sample = data.patches[positive_nodes].permute(0, 3, 1, 2)  # [num_positive, 1, 128, 128]\n",
    "    positive_pathces.append(positive_patches_sample)\n",
    "\n",
    "# Concatenate all positive patches\n",
    "positive_patches_sample = torch.cat(positive_pathces, dim=0)\n",
    "\n",
    "# Create a DataLoader for the positive patches\n",
    "positive_dataset = PositivePatchDataset(positive_patches_sample, device)\n",
    "plaque_loader = DataLoader(positive_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check torch version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoencoderKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the autoencoder model\n",
    "\n",
    "vae = AutoencoderKL(in_channels=1, out_channels=1, down_block_types=(\"DownEncoderBlock2D\", \"DownEncoderBlock2D\", ), \n",
    "                    up_block_types=(\"UpDecoderBlock2D\", \"UpDecoderBlock2D\", ), block_out_channels=(64, 128, )).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for loss calculation\n",
    "test_batch = next(iter(plaque_loader['val']))\n",
    "test_batch = test_batch.to(device)\n",
    "test_recon = vae(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure test_batch and test_recon are already defined\n",
    "# For example:\n",
    "# test_batch = ...         # Your original images tensor\n",
    "# test_recon = ...         # Your reconstructed images output (DecoderOutput)\n",
    "\n",
    "# Inspect the DecoderOutput to find the correct attribute\n",
    "print(\"Attributes of test_recon:\", dir(test_recon))\n",
    "\n",
    "# Assuming 'sample' is the correct attribute holding the images\n",
    "# If it's different, replace 'sample' with the correct attribute name\n",
    "\n",
    "# Create subplots: 2 rows (Original and Reconstructed) x 5 columns\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(5):\n",
    "    # Plot Original Image\n",
    "    orig_img = test_batch[i].squeeze().cpu().numpy()\n",
    "    if orig_img.ndim > 2:\n",
    "        orig_img = orig_img[0]  # Take first channel if multi-channel\n",
    "\n",
    "    axes[i].imshow(orig_img, cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f\"Original {i+1}\")\n",
    "\n",
    "    # Plot Reconstructed Image\n",
    "    try:\n",
    "        recon_img = test_recon.sample[i].squeeze().detach().cpu().numpy()\n",
    "    except AttributeError:\n",
    "        raise AttributeError(\"The 'DecoderOutput' object does not have a 'sample' attribute. Please check the correct attribute name.\")\n",
    "    \n",
    "    if recon_img.ndim > 2:\n",
    "        recon_img = recon_img[0]  # Take first channel if multi-channel\n",
    "\n",
    "    axes[i + 5].imshow(recon_img, cmap='gray')\n",
    "    axes[i + 5].axis('off')\n",
    "    axes[i + 5].set_title(f\"Reconstructed {i+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoencoderKL\n",
    "\n",
    "# Define the autoencoder model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vae = AutoencoderKL(in_channels=1, out_channels=1, down_block_types=(\"DownEncoderBlock2D\", \"DownEncoderBlock2D\", \"DownEncoderBlock2D\", \"DownEncoderBlock2D\"), \n",
    "                    up_block_types=(\"UpDecoderBlock2D\", \"UpDecoderBlock2D\", \"UpDecoderBlock2D\", \"UpDecoderBlock2D\"), block_out_channels=(64, 128, 256, 512), latent_channels = 16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Define the PositivePatchDataset\n",
    "class PositivePatchDataset(Dataset):\n",
    "    def __init__(self, patches):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patches (torch.Tensor): Tensor of patches with shape [N, 1, 128, 128]\n",
    "        \"\"\"\n",
    "        self.patches = patches  # Keep patches on CPU\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ToTensor(),  # Ensure tensor is in [0,1]\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.patches.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patch = self.patches[idx]  # [1,128,128]\n",
    "        patch_np = (patch.squeeze(0).cpu().numpy() * 255).astype(np.uint8)  # Convert to [0,255] uint8\n",
    "        patch_pil = Image.fromarray(patch_np, mode='L')  # Convert to PIL Image in grayscale\n",
    "        patch_transformed = self.transform(patch_pil)  # Apply augmentations\n",
    "        return patch_transformed  # [1,128,128], float in [0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming graph_data_dict and positive_nodes_dict are already defined\n",
    "# and device is set (e.g., device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Collect positive patches\n",
    "positive_patches = []\n",
    "\n",
    "for key, data in graph_data_dict.items():\n",
    "    positive_nodes = positive_nodes_dict[key].cpu()  # Ensure on CPU\n",
    "    positive_patches_sample = data.patches[positive_nodes].permute(0, 3, 1, 2)  # [num_positive, 1, 128, 128]\n",
    "    positive_patches.append(positive_patches_sample)\n",
    "\n",
    "# Concatenate all positive patches\n",
    "positive_patches_sample = torch.cat(positive_patches, dim=0)  # [total_positive, 1, 128, 128]\n",
    "\n",
    "# Create the dataset\n",
    "positive_dataset = PositivePatchDataset(positive_patches_sample)\n",
    "\n",
    "# Split into training and validation sets (e.g., 80% train, 20% val)\n",
    "train_size = int(0.8 * len(positive_dataset))\n",
    "val_size = len(positive_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(positive_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "num_workers = 0  # Set to 0 for notebook environments\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True if torch.cuda.is_available() else False  # Optimize data transfer to GPU\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# Combine into a dictionary for easy access\n",
    "plaque_loader = {'train': train_loader, 'val': val_loader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values range of the patches from the positive_dataset\n",
    "patch_values = []\n",
    "for patch in positive_dataset:\n",
    "    patch_values.append(patch.numpy().flatten())\n",
    "\n",
    "patch_values = np.array(patch_values)\n",
    "patch_min = patch_values.min()\n",
    "patch_max = patch_values.max()\n",
    "\n",
    "patch_min, patch_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm  # Use tqdm for notebook\n",
    "import os\n",
    "\n",
    "# Define Loss Function and Optimizer\n",
    "reconstruction_loss_fn = nn.BCEWithLogitsLoss(reduction='mean')  # Binary Cross-Entropy with Logits Loss\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-4)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # Optional\n",
    "\n",
    "# Training Parameters\n",
    "num_epochs = 20\n",
    "log_interval = 100      # How often to log training status\n",
    "save_interval = 5       # How often to save the model\n",
    "visualize_interval = max(1, num_epochs // 5)  # Visualize every 1/5 of total epochs\n",
    "warmup_epochs = 10       # Number of epochs to warm-up the KL term\n",
    "\n",
    "# Create a directory to save models\n",
    "os.makedirs('vae_checkpoints', exist_ok=True)\n",
    "\n",
    "# Lists to store loss values for plotting\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Function to visualize reconstructions\n",
    "def visualize_reconstructions(model, dataloader, device, epoch, num_images=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = next(iter(dataloader))  # Retrieve only data\n",
    "        data = data.to(device)\n",
    "        latent_dist = model.encode(data).latent_dist  # Obtain latent distribution\n",
    "        recon_data = model.decode(latent_dist.sample()).sample  # Decode sampled latent vectors\n",
    "\n",
    "        # Move tensors to CPU and convert to numpy\n",
    "        data = data.cpu().numpy()\n",
    "        recon_data = recon_data.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(num_images):\n",
    "        # Original Image\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(data[i].squeeze(), cmap='gray')\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Reconstructed Image\n",
    "        plt.subplot(2, num_images, i + 1 + num_images)\n",
    "        plt.imshow(recon_data[i].squeeze(), cmap='gray')\n",
    "        plt.title(\"Reconstructed\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Reconstruction at Epoch {epoch}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Loop\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Training Phase\n",
    "    vae.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    \n",
    "    # Initialize tqdm progress bar for training\n",
    "    train_bar = tqdm(plaque_loader['train'], desc=f\"Epoch {epoch}/{num_epochs} [Train]\", leave=False)\n",
    "    \n",
    "    for batch_idx, data in enumerate(train_bar):\n",
    "        data = data.to(device)  # Move data to device\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: Encode and Decode\n",
    "        latent_dist = vae.encode(data).latent_dist  # Obtain latent distribution\n",
    "        recon_data = vae.decode(latent_dist.sample()).sample  # Decode sampled latent vectors\n",
    "        \n",
    "        # Extract mu and logvar\n",
    "        mu = latent_dist.mean\n",
    "        logvar = latent_dist.logvar\n",
    "        \n",
    "        # Compute Loss\n",
    "        recon_loss = reconstruction_loss_fn(recon_data, data)\n",
    "        kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        # Calculate annealing factor\n",
    "        annealing_factor = min(1.0, epoch / warmup_epochs)\n",
    "        loss = recon_loss + kl_loss * annealing_factor\n",
    "        \n",
    "        # Backward and Optimize\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(vae.parameters(), max_norm=10.0)  # Optional: Gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "        # Update tqdm progress bar with loss\n",
    "        train_bar.set_postfix({'Loss': loss.item(), 'Recon': recon_loss.item(), 'KL': kl_loss.item()})\n",
    "    \n",
    "    # Calculate average training loss for the epoch\n",
    "    average_train_loss = epoch_train_loss / len(plaque_loader['train'])\n",
    "    train_losses.append(average_train_loss)\n",
    "    \n",
    "    # Validation Phase\n",
    "    vae.eval()\n",
    "    epoch_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(plaque_loader['val'], desc=f\"Epoch {epoch}/{num_epochs} [Val]\", leave=False)\n",
    "        for data in val_bar:\n",
    "            data = data.to(device)\n",
    "            latent_dist = vae.encode(data).latent_dist  # Obtain latent distribution\n",
    "            recon_data = vae.decode(latent_dist.sample()).sample  # Decode sampled latent vectors\n",
    "            \n",
    "            # Extract mu and logvar\n",
    "            mu = latent_dist.mean\n",
    "            logvar = latent_dist.logvar\n",
    "            \n",
    "            # Compute Loss\n",
    "            recon_loss = reconstruction_loss_fn(recon_data, data)\n",
    "            kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "            loss = recon_loss + kl_loss * annealing_factor\n",
    "            \n",
    "            # Update validation loss\n",
    "            epoch_val_loss += loss.item()\n",
    "            \n",
    "            # Update tqdm progress bar with loss\n",
    "            val_bar.set_postfix({'Loss': loss.item(), 'Recon': recon_loss.item(), 'KL': kl_loss.item()})\n",
    "    \n",
    "    # Calculate average validation loss for the epoch\n",
    "    average_val_loss = epoch_val_loss / len(plaque_loader['val'])\n",
    "    val_losses.append(average_val_loss)\n",
    "    \n",
    "    print(f\"Epoch [{epoch}/{num_epochs}] | Train Loss: {average_train_loss:.4f} | Val Loss: {average_val_loss:.4f}\")\n",
    "    \n",
    "    # # Step the scheduler\n",
    "    # scheduler.step()\n",
    "    \n",
    "    # Save checkpoint periodically\n",
    "    if epoch % save_interval == 0 or epoch == num_epochs:\n",
    "        checkpoint_path = f'vae_checkpoints/vae_bce_hidden16_epoch_{epoch}.pth'\n",
    "        torch.save(vae.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved model checkpoint at {checkpoint_path}\")\n",
    "    \n",
    "    # Visualize Reconstructions at specified intervals\n",
    "    if epoch % visualize_interval == 0 or epoch == num_epochs:\n",
    "        visualize_reconstructions(vae, plaque_loader['val'], device, epoch, num_images=5)\n",
    "\n",
    "# Plot Training and Validation Losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "vae.load_state_dict(torch.load('vae_checkpoints/vae_epoch_10.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions(vae, plaque_loader['val'], device, epoch=10, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the latent representation of a sample batch\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    data = next(iter(plaque_loader['val']))  # Retrieve only data\n",
    "    data = data.to(device)\n",
    "    latent_dist = vae.encode(data).latent_dist  # Obtain latent distribution\n",
    "    latent_sample = latent_dist.sample()  # Sample latent vectors\n",
    "\n",
    "# Check the shape of the latent sample\n",
    "latent_sample.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGAE (Variational Graph Auto-Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_zinb_reconstruction(\n",
    "    original_counts: torch.Tensor,\n",
    "    mu: torch.Tensor,\n",
    "    pi: torch.Tensor,\n",
    "    alpha: torch.Tensor,\n",
    "    num_samples: int = 100,\n",
    "    gene_idx: int = 0,\n",
    "    title: str = \"ZINB Reconstruction\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize reconstruction quality by comparing original counts vs. reconstructed ZINB means.\n",
    "    Args:\n",
    "        original_counts (torch.Tensor): Original count matrix, shape (num_nodes, num_genes).\n",
    "        mu (torch.Tensor): Reconstructed NB means, shape (num_nodes, num_genes).\n",
    "        pi (torch.Tensor): Zero-inflation probabilities, shape (num_nodes, num_genes).\n",
    "        alpha (torch.Tensor): Inverse dispersion, shape (num_nodes, num_genes) or (1, num_genes).\n",
    "        num_samples (int): Number of cells to sample for visualization.\n",
    "        gene_idx (int): Index of the gene to visualize.\n",
    "        title (str): Title for the plot.\n",
    "    \"\"\"\n",
    "    # Move to CPU and convert to numpy for plotting\n",
    "    original_np = original_counts.cpu().numpy()\n",
    "    mu_np = mu.cpu().numpy()\n",
    "    pi_np = pi.cpu().numpy()\n",
    "    alpha_np = alpha.cpu().numpy()\n",
    "\n",
    "    num_nodes = original_np.shape[0]\n",
    "    # Randomly sample some cells to visualize\n",
    "    indices = np.random.choice(num_nodes, size=min(num_samples, num_nodes), replace=False)\n",
    "\n",
    "    # Extract the gene of interest\n",
    "    original_gene = original_np[indices, gene_idx]\n",
    "    mu_gene = mu_np[indices, gene_idx]\n",
    "    pi_gene = pi_np[indices, gene_idx]\n",
    "    alpha_gene = alpha_np[indices, gene_idx] if alpha_np.shape[0] == num_nodes else alpha_np[0, gene_idx]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # ---- Subplot 1: Original vs. Reconstructed Means (scatter) ----\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(range(len(indices)), original_gene, color='blue', alpha=0.6, label='Original Counts')\n",
    "    plt.scatter(range(len(indices)), mu_gene, color='red', alpha=0.6, label='Reconstructed Mean (mu)')\n",
    "    plt.title(f\"{title}\\nGene {gene_idx} - Original vs. Mean\")\n",
    "    plt.xlabel(\"Sampled Cell Index\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "\n",
    "    # ---- Subplot 2: Zero-inflation Probabilities (and alpha, optional) ----\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(range(len(indices)), pi_gene, color='green', alpha=0.6, label='Zero-inflation (pi)')\n",
    "    # Optionally show alpha for each cell if you want\n",
    "    if alpha_gene.ndim == 0:\n",
    "        # alpha is a scalar\n",
    "        alpha_str = f\"alpha = {alpha_gene:.4f}\"\n",
    "        plt.text(0.5, 0.5, alpha_str, fontsize=12, transform=plt.gca().transAxes)\n",
    "    else:\n",
    "        # alpha is cell-specific; let's just plot it\n",
    "        plt.scatter(range(len(indices)), alpha_gene, color='orange', alpha=0.6, label='Alpha (dispersion)')\n",
    "\n",
    "    plt.title(f\"Gene {gene_idx} - pi & alpha\")\n",
    "    plt.xlabel(\"Sampled Cell Index\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, BatchNorm\n",
    "from torch_geometric.nn.models import VGAE\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Encoder with optional skip connections, batch norm\n",
    "# ---------------------------------------------------\n",
    "class GraphEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim, latent_dim, use_gat=False):\n",
    "        super().__init__()\n",
    "        self.use_gat = use_gat\n",
    "\n",
    "        # Layer 1\n",
    "        if use_gat:\n",
    "            self.conv1 = GATConv(in_channels, hidden_dim, heads=1, dropout=0.1)\n",
    "        else:\n",
    "            self.conv1 = GCNConv(in_channels, hidden_dim)\n",
    "        self.bn1 = BatchNorm(hidden_dim)\n",
    "\n",
    "        # Layer 2\n",
    "        if use_gat:\n",
    "            self.conv2 = GATConv(hidden_dim, hidden_dim, heads=1, dropout=0.1)\n",
    "        else:\n",
    "            self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "\n",
    "        # Optional skip connection\n",
    "        self.skip = nn.Linear(in_channels, hidden_dim, bias=False)\n",
    "\n",
    "        # Mean and log-variance\n",
    "        self.mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.logstd = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        # Set up the activation function\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x_skip = self.skip(x)\n",
    "\n",
    "        # Convolution block 1\n",
    "        x1 = self.conv1(x, edge_index)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.leaky_relu(x1)\n",
    "\n",
    "        # Convolution block 2\n",
    "        x2 = self.conv2(x1, edge_index)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = x2 + x_skip  # skip connection\n",
    "        x2 = self.leaky_relu(x2)\n",
    "\n",
    "        # Mean & logstd\n",
    "        mu = self.mean(x2)\n",
    "        logstd = self.logstd(x2)\n",
    "        return mu, logstd\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# ZINB Decoder for feature reconstruction\n",
    "# ------------------------------------------------------\n",
    "class ZINBDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder that outputs parameters of the ZINB distribution:\n",
    "      mu, alpha, pi\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim, out_channels):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc2 = nn.Linear(latent_dim, 3 * out_channels)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = self.leaky_relu(self.fc1(z))\n",
    "        h_out = self.fc2(h)  # (N, 3*out_channels)\n",
    "\n",
    "        out_ch = h_out.size(1) // 3\n",
    "        log_mu    = h_out[:, 0*out_ch : 1*out_ch]\n",
    "        log_alpha = h_out[:, 1*out_ch : 2*out_ch]\n",
    "        logit_pi  = h_out[:, 2*out_ch : 3*out_ch]\n",
    "\n",
    "        # In the ZINBDecoder, modify how mu and alpha are computed to prevent overflow:\n",
    "        mu = torch.exp(torch.clamp(log_mu, min=-10, max=10))\n",
    "        alpha = torch.exp(torch.clamp(log_alpha, min=-10, max=10))\n",
    "        pi    = torch.sigmoid(logit_pi)\n",
    "\n",
    "        return mu, alpha, pi\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# VGAE Model Composition\n",
    "# ------------------------------------------------------\n",
    "class SOTAVGAE(VGAE):\n",
    "    \"\"\"\n",
    "    Inherits from PyG's VGAE.\n",
    "    We'll decode adjacency with recon_loss(z, edge_index),\n",
    "    and decode features with our ZINBDecoder.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__(encoder)\n",
    "        self.zinb_decoder = decoder\n",
    "\n",
    "    def reconstruct_features(self, z):\n",
    "        mu, alpha, pi = self.zinb_decoder(z)\n",
    "        if torch.isnan(mu).any() or torch.isnan(alpha).any() or torch.isnan(pi).any():\n",
    "            print(\"NaN detected in ZINB parameters\")\n",
    "        return mu, alpha, pi\n",
    "    \n",
    "# ------------------------------------------------------\n",
    "# Zero-Inflated Negative Binomial Loss function\n",
    "# ------------------------------------------------------\n",
    "def zero_inflated_negative_binomial_loss(x, mu, alpha, pi, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Exactly as defined earlier. Copied here for completeness.\n",
    "    \"\"\"\n",
    "    x = x.float()\n",
    "    mu = mu.float()\n",
    "    alpha = alpha.float()\n",
    "    pi = pi.float()\n",
    "\n",
    "    # Ensure that the values are within a safe range\n",
    "    mu    = torch.clamp(mu, min=eps)  # Ensure no zero value for mu\n",
    "    alpha = torch.clamp(alpha, min=eps)  # Avoid zero alpha\n",
    "    pi    = torch.clamp(pi, min=eps, max=1 - eps)  # Avoid zero or one pi\n",
    "\n",
    "    # NB log prob\n",
    "    log_nb = (\n",
    "        torch.lgamma(x + alpha)\n",
    "        - torch.lgamma(alpha)\n",
    "        - torch.lgamma(x + 1)\n",
    "        + alpha * torch.log(alpha / (mu + alpha) + eps)\n",
    "        + x * torch.log(mu / (mu + alpha) + eps)\n",
    "    )\n",
    "\n",
    "    zero_ix = (x < 0.5).float()\n",
    "    log_prob_zero = torch.log(\n",
    "        pi + (1.0 - pi) * torch.exp(log_nb) + eps\n",
    "    ) * zero_ix\n",
    "\n",
    "    log_prob_non_zero = (\n",
    "        torch.log((1.0 - pi) + eps) + log_nb\n",
    "    ) * (1.0 - zero_ix)\n",
    "\n",
    "    log_prob = log_prob_zero + log_prob_non_zero\n",
    "\n",
    "    nll = -log_prob.sum()  # sum over all i,j\n",
    "    return nll / x.numel()  # average\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Training loop (modified for ZINB)\n",
    "# ------------------------------------------------------\n",
    "# Optional Gradient Clipping in Training Loop:\n",
    "def train_multi_graph_vgae(\n",
    "    model, \n",
    "    train_graphs, \n",
    "    optimizer,\n",
    "    total_epochs=100,\n",
    "    alpha=1.0,\n",
    "    kl_warmup=20\n",
    "):\n",
    "    all_epoch_losses = []\n",
    "    visualization_interval = max(1, total_epochs // 10)\n",
    "\n",
    "    epoch_pbar = tqdm(range(1, total_epochs + 1), desc=\"Training\", unit=\"epoch\")\n",
    "    for epoch in epoch_pbar:\n",
    "        model.train()\n",
    "        kl_weight = min(1.0, epoch / kl_warmup)\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        graph_pbar = tqdm(train_graphs, desc=f\"Epoch {epoch}\", leave=False, unit=\"graph\")\n",
    "        for data in graph_pbar:\n",
    "            z = model.encode(data.x, data.edge_index)\n",
    "\n",
    "            # Adjacency\n",
    "            loss_adj = model.recon_loss(z, data.edge_index)\n",
    "\n",
    "            # ZINB feature reconstruction\n",
    "            mu, alpha_param, pi = model.reconstruct_features(z)\n",
    "            loss_feat = zero_inflated_negative_binomial_loss(data.x, mu, alpha_param, pi)\n",
    "\n",
    "            # KL\n",
    "            kl_div = model.kl_loss() / data.num_nodes\n",
    "\n",
    "            # Combined\n",
    "            recon_weight = 10.0  # Adjust as needed\n",
    "            loss = loss_adj + alpha * loss_feat * recon_weight + kl_weight * kl_div\n",
    "            epoch_loss += loss\n",
    "\n",
    "            graph_pbar.set_postfix({\n",
    "                'Adj Loss': f\"{loss_adj.item():.4f}\",\n",
    "                'Feat(ZINB)': f\"{loss_feat.item():.4f}\",\n",
    "                'KL': f\"{kl_div.item():.4f}\",\n",
    "            })\n",
    "\n",
    "        epoch_loss.backward()\n",
    "\n",
    "        # Clip gradients to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss = epoch_loss.item() / len(train_graphs)\n",
    "        all_epoch_losses.append(avg_loss)\n",
    "        epoch_pbar.set_postfix({'AvgLoss/Graph': f\"{avg_loss:.4f}\"})\n",
    "\n",
    "        # ---- Visualization ----\n",
    "        if epoch % visualization_interval == 0 or epoch == 1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # Pick the first training graph for demonstration\n",
    "                data_vis = train_graphs[0]\n",
    "                z_vis = model.encode(data_vis.x, data_vis.edge_index)\n",
    "                mu_vis, alpha_vis, pi_vis = model.reconstruct_features(z_vis)\n",
    "                \n",
    "                # Let's visualize gene index 0 (or another gene of interest)\n",
    "                visualize_zinb_reconstruction(\n",
    "                    original_counts=data_vis.x,\n",
    "                    mu=mu_vis,\n",
    "                    pi=pi_vis,\n",
    "                    alpha=alpha_vis,\n",
    "                    gene_idx=0,\n",
    "                    title=f\"Epoch {epoch} Reconstruction (ZINB)\"\n",
    "                )\n",
    "\n",
    "    # Plot final training loss curve\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(range(1, total_epochs+1), all_epoch_losses, label='Training Loss')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"VGAE Multi-Graph Training Loss (ZINB)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return all_epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graphs = [\n",
    "    graph_data_dict['8months-disease-replicate_1'],\n",
    "    graph_data_dict['13months-disease-replicate_1'],\n",
    "    graph_data_dict['8months-disease-replicate_2']\n",
    "]\n",
    "test_graph = graph_data_dict['13months-disease-replicate_2']\n",
    "\n",
    "some_graph = train_graphs[0]\n",
    "in_channels = some_graph.x.shape[1]   # e.g. 2766\n",
    "hidden_dim = 256\n",
    "latent_dim = 128\n",
    "\n",
    "encoder = GraphEncoder(in_channels, hidden_dim, latent_dim, use_gat=False)\n",
    "decoder = ZINBDecoder(latent_dim, out_channels=in_channels)\n",
    "\n",
    "graph_vae = SOTAVGAE(encoder, decoder)\n",
    "optimizer = torch.optim.Adam(graph_vae.parameters(), lr=1e-3)\n",
    "\n",
    "train_losses = train_multi_graph_vgae(\n",
    "    graph_vae, \n",
    "    train_graphs, \n",
    "    optimizer,\n",
    "    total_epochs=40,\n",
    "    alpha=1.0,     # weight for the ZINB feature loss\n",
    "    kl_warmup=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GPU",
   "language": "python",
   "name": "gpu_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
