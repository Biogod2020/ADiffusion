{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "# import skimage.io as io\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "os.chdir('/public/home/jijh/diffusion_project/ADiffusion')\n",
    "import importlib\n",
    "import src.preprocessing.data_process\n",
    "importlib.reload(src.preprocessing.data_process)\n",
    "from src.preprocessing.data_process import extract_patches, create_graph_data_dict, construct_affinity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    \"\"\"Initialize random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# Set random seed for reproducibility\n",
    "random_seed = 0\n",
    "seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_dir = \"/public/home/jijh/st_project/cellbin_analysis/spatial_variation/wx_data/\"  # Directory containing the data files\n",
    "files = os.listdir(file_dir)  # List all files in the directory\n",
    "files = [i for i in files if i.endswith(\".h5ad\") and \"month\" in i]  # Filter files to include only those ending with \".h5ad\" and containing \"month\"\n",
    "file_paths = [os.path.join(file_dir, i) for i in files]  # Create full file paths for the filtered files\n",
    "adatas = {}  # Initialize an empty dictionary to store AnnData objects\n",
    "\n",
    "# Read each file and store the AnnData object in the dictionary\n",
    "for i in range(len(file_paths)):\n",
    "    adatas[files[i].split(\".\")[0]] = sc.read(file_paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess each AnnData object\n",
    "for key in tqdm(adatas.keys(), desc=\"Preprocessing datasets\"):\n",
    "    sc.pp.normalize_total(adatas[key], target_sum=1e4)  # Normalize counts per cell\n",
    "    sc.pp.log1p(adatas[key])  # Logarithmize the data\n",
    "    adatas[key].layers[\"raw\"] = adatas[key].X.copy()  # Store the raw data in the \"raw\" layer\n",
    "    sc.pp.scale(adatas[key], max_value=10)  # Scale the data to have a maximum value of 10\n",
    "    sc.tl.pca(adatas[key], svd_solver=\"arpack\")  # Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract spatial coordinates for each cell\n",
    "cell_coords = {}\n",
    "for key in adatas.keys():\n",
    "    cell_coords[key] = adatas[key].obsm[\"spatial\"].copy()\n",
    "neighbors = {}\n",
    "for key in cell_coords.keys():\n",
    "    neighbors[key] = construct_affinity_matrix(cell_coords[key], mode=\"radius\", cutoff=150, add_self_loop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "# Load the plaque dataset\n",
    "img_dir = \"/public/home/jijh/st_project/cellbin_analysis/spatial_variation/wx_data/protein_seg_result/\"\n",
    "img_files = os.listdir(img_dir)\n",
    "img_files = [i for i in img_files if i.endswith(\".tiff\") and \"plaque\" in i]\n",
    "# Read the images\n",
    "\n",
    "imgs = {}\n",
    "for i in range(len(img_files)):\n",
    "    imgs[img_files[i].split(\".\")[0]] = io.imread(os.path.join(img_dir, img_files[i]))\n",
    "imgs.keys()\n",
    "# Rename the imgs to match the adata keys\n",
    "for key in list(imgs.keys()):\n",
    "    parts = key.split(\"_\")\n",
    "    if len(parts) > 1:\n",
    "        new_key = parts[1] + \"_\" + parts[2]\n",
    "        imgs[new_key] = imgs.pop(key)\n",
    "\n",
    "\n",
    "# Extract patches from the images\n",
    "patches = {}\n",
    "for key in imgs.keys():\n",
    "    patches[key] = extract_patches(imgs[key], cell_coords[key], patch_size=128)\n",
    "\n",
    "# Convert the patches to binary and calculate the area of positive pixels for each patch\n",
    "binary_patches = {}\n",
    "for key in patches.keys():\n",
    "    binary_patches[key] = [patch > 0 for patch in patches[key]]\n",
    "# Calculate the area of positive pixels for each patch\n",
    "areas = {}\n",
    "for key in binary_patches.keys():\n",
    "    areas[key] = [np.sum(patch) for patch in binary_patches[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph dictionary\n",
    "graph_data_dict = create_graph_data_dict(adatas=adatas, neighbors=neighbors, cell_coords=cell_coords, embeddings=\"X\", areas=areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My personal STAGATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class STAGATE_GAE(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            heads_per_layer: list = [1, 1],\n",
    "            hidden_channels: list = [256, 256],\n",
    "            dropout: float = 0.0,\n",
    "            edge_dropout: float = 0.0,\n",
    "    ):\n",
    "        super(STAGATE_GAE, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.heads_per_layer = heads_per_layer\n",
    "        self.dropout = dropout\n",
    "        self.edge_dropout = edge_dropout\n",
    "        self.num_layers = len(hidden_channels)\n",
    "\n",
    "        self.encoder_convs = nn.ModuleList()\n",
    "        self.decoder_convs = nn.ModuleList()\n",
    "\n",
    "        # Encoder\n",
    "        for i in range(self.num_layers):\n",
    "            conv_in_channels = in_channels if i == 0 else hidden_channels[i - 1]\n",
    "            conv_out_channels = hidden_channels[i]\n",
    "            heads = heads_per_layer[i]\n",
    "            gat_conv = GATConv(\n",
    "                conv_in_channels,\n",
    "                conv_out_channels,\n",
    "                heads=heads,\n",
    "                dropout=dropout,\n",
    "                add_self_loops=True,\n",
    "                concat=False\n",
    "            )\n",
    "            self.encoder_convs.append(gat_conv)\n",
    "\n",
    "        # Decoder (Symmetric to the encoder)\n",
    "        for i in range(self.num_layers - 1, -1, -1):\n",
    "            # 使用上一层 decoder 的输出维度作为输入，例如：\n",
    "            conv_in_channels = hidden_channels[i]  # 或根据多头机制加权\n",
    "            conv_out_channels = in_channels if i == 0 else hidden_channels[i - 1]\n",
    "            heads = heads_per_layer[i]\n",
    "            gat_conv = GATConv(\n",
    "                conv_in_channels,\n",
    "                conv_out_channels,\n",
    "                heads=heads,\n",
    "                dropout=dropout,\n",
    "                add_self_loops=True,\n",
    "                concat=False\n",
    "            )\n",
    "            self.decoder_convs.append(gat_conv)\n",
    "\n",
    "        # Initialize weights using Xavier initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"\n",
    "        Initialize weights of GATConv layers using Xavier (Glorot) initialization.\n",
    "        \"\"\"\n",
    "        if isinstance(module, GATConv):\n",
    "            # 对于 lin_src，确保其不为 None 再进行初始化\n",
    "            if hasattr(module, 'lin_src') and module.lin_src is not None:\n",
    "                if module.lin_src.weight is not None:\n",
    "                    nn.init.xavier_uniform_(module.lin_src.weight)\n",
    "                if module.lin_src.bias is not None:\n",
    "                    nn.init.zeros_(module.lin_src.bias)\n",
    "\n",
    "            # 对于 lin_dst，同样先进行 None 检查\n",
    "            if hasattr(module, 'lin_dst') and module.lin_dst is not None:\n",
    "                if module.lin_dst.weight is not None:\n",
    "                    nn.init.xavier_uniform_(module.lin_dst.weight)\n",
    "                if module.lin_dst.bias is not None:\n",
    "                    nn.init.zeros_(module.lin_dst.bias)\n",
    "                \n",
    "            # Attention 权重初始化\n",
    "            if hasattr(module, 'att') and module.att is not None:\n",
    "                nn.init.xavier_uniform_(module.att)\n",
    "\n",
    "    def forward(self, data: Data, return_hidden=False):\n",
    "        \"\"\"\n",
    "        Forward pass through the encoder and decoder.\n",
    "\n",
    "        Parameters:\n",
    "        - data: PyTorch Geometric Data object containing `x` and `edge_index`.\n",
    "        - return_hidden: If True, returns hidden representations from all layers.\n",
    "\n",
    "        Returns:\n",
    "        - Reconstructed node embeddings or a tuple of (reconstructed embeddings, hidden layers).\n",
    "        \"\"\"\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        hiddens_per_layer = []\n",
    "\n",
    "        # Encoder\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.encoder_convs[i](x, edge_index)\n",
    "            x = F.elu(x)\n",
    "            hiddens_per_layer.append(x)\n",
    "\n",
    "        # Decoder\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            # Assuming symmetric architecture; adjust if different\n",
    "            # Concatenate with the corresponding encoder layer output if needed\n",
    "            # Here, it's simplified\n",
    "            x = self.decoder_convs[i](x, edge_index)\n",
    "            x = F.elu(x)\n",
    "            hiddens_per_layer.append(x)\n",
    "\n",
    "        if return_hidden:\n",
    "            return x, hiddens_per_layer\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = graph_data_dict['13months-disease-replicate_1'].clone()\n",
    "# Test for a single forward pass\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "in_channels = data.x.size(-1)\n",
    "\n",
    "model = STAGATE_GAE(in_channels=in_channels, hidden_channels=[512, 30], heads_per_layer=[1, 1], dropout=0.0).to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 训练过程定义：train_STAGATE_GAE\n",
    "# -------------------------------\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = True\n",
    "\n",
    "def train_STAGATE_GAE(graph_data: Data,\n",
    "                      hidden_channels=[512, 30],\n",
    "                      n_epochs=1000,\n",
    "                      lr=0.001,\n",
    "                      weight_decay=0.0001,\n",
    "                      gradient_clipping=5.0,\n",
    "                      random_seed=0,\n",
    "                      verbose=True,\n",
    "                      device=None):\n",
    "    \"\"\"\n",
    "    训练图注意力自编码器（STAGATE_GAE）。\n",
    "\n",
    "    参数:\n",
    "    - graph_data: torch_geometric.data.Data 对象，包含节点特征 x 和边索引 edge_index。\n",
    "    - hidden_channels: 编码器各层的输出维度列表。\n",
    "    - n_epochs: 总训练轮数。\n",
    "    - lr: 学习率。\n",
    "    - weight_decay: 权重衰减。\n",
    "    - gradient_clipping: 梯度裁剪阈值。\n",
    "    - random_seed: 随机种子。\n",
    "    - verbose: 是否打印训练过程中日志信息。\n",
    "    - device: 设备，如果为 None，则自动选择 GPU (若可用) 或 CPU。\n",
    "\n",
    "    返回:\n",
    "    - model: 训练后的模型\n",
    "    - latent_rep: 节点的低维潜在表示（取自 encoder 最后一层的输出）\n",
    "    - loss_list: 各轮训练损失列表\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 设置随机种子\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "    # 将数据移动到设备上\n",
    "    graph_data = graph_data.to(device)\n",
    "\n",
    "    # 模型初始化：in_channels 为节点特征维度\n",
    "    in_channels = graph_data.x.size(-1)\n",
    "    # 注意：heads_per_layer 这里设为全 1，使得每层输出维度不改变（因 concat=False）\n",
    "    model = STAGATE_GAE(in_channels=in_channels,\n",
    "                        hidden_channels=hidden_channels,\n",
    "                        heads_per_layer=[1] * len(hidden_channels),\n",
    "                        dropout=0.0).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_list = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(1, n_epochs + 1), desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播，获得重构后的节点特征\n",
    "        out = model(graph_data)\n",
    "        # 使用均方误差损失重构原始节点特征\n",
    "        loss = F.mse_loss(out, graph_data.x)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        if verbose and epoch % 100 == 0:\n",
    "            print(f\"Epoch: {epoch:4d}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # 训练结束后提取潜在表示\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 此处采用 forward(return_hidden=True) 得到所有层的隐藏表示，\n",
    "        # 我们选取 encoder 部分最后一层的输出作为节点的潜在表示\n",
    "        _, hiddens = model(graph_data, return_hidden=True)\n",
    "        # encoder 隐藏表示位于 hiddens[0] ~ hiddens[model.num_layers-1]\n",
    "        latent_rep = hiddens[model.num_layers - 1]\n",
    "    \n",
    "    latent_rep_np = latent_rep.cpu().numpy()\n",
    "\n",
    "    return model, latent_rep_np, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用训练过程，hidden_channels 设为 [512, 30]\n",
    "model, latent_rep, loss_list = train_STAGATE_GAE(\n",
    "        data,\n",
    "        hidden_channels=[512, 30],\n",
    "        n_epochs=2000,  # 可根据需求增加训练轮数\n",
    "        lr=0.001,\n",
    "        weight_decay=0.0001,\n",
    "        gradient_clipping=5.0,\n",
    "        random_seed=42,\n",
    "        verbose=True,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss_list, label='Training Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# latent_rep 即为节点的低维表示，可供后续聚类或可视化使用\n",
    "print(\"Latent representation shape:\", latent_rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adatas['13months-disease-replicate_1'].copy()\n",
    "adata.obsm['X_STAGATE'] = latent_rep\n",
    "sc.pp.neighbors(adata, use_rep=\"X_STAGATE\", n_neighbors=30)\n",
    "sc.tl.leiden(adata, key_added=\"leiden_STAGATE\", resolution=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(adata, color=\"leiden_STAGATE\", spot_size=10, title=\"STAGATE Clustering\", ncols=3, frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用它的数据构建方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def Cal_Spatial_Net(adata, rad_cutoff=None, k_cutoff=None, model='Radius', verbose=True):\n",
    "    \"\"\"\\\n",
    "    Construct the spatial neighbor networks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata\n",
    "        AnnData object of scanpy package.\n",
    "    rad_cutoff\n",
    "        radius cutoff when model='Radius'\n",
    "    k_cutoff\n",
    "        The number of nearest neighbors when model='KNN'\n",
    "    model\n",
    "        The network construction model. When model=='Radius', the spot is connected to spots whose distance is less than rad_cutoff. When model=='KNN', the spot is connected to its first k_cutoff nearest neighbors.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The spatial networks are saved in adata.uns['Spatial_Net']\n",
    "    \"\"\"\n",
    "\n",
    "    assert(model in ['Radius', 'KNN'])\n",
    "    if verbose:\n",
    "        print('------Calculating spatial graph...')\n",
    "    coor = pd.DataFrame(adata.obsm['spatial'])\n",
    "    coor.index = adata.obs.index\n",
    "    coor.columns = ['imagerow', 'imagecol']\n",
    "\n",
    "    if model == 'Radius':\n",
    "        nbrs = sklearn.neighbors.NearestNeighbors(radius=rad_cutoff).fit(coor)\n",
    "        distances, indices = nbrs.radius_neighbors(coor, return_distance=True)\n",
    "        KNN_list = []\n",
    "        for it in range(indices.shape[0]):\n",
    "            KNN_list.append(pd.DataFrame(zip([it]*indices[it].shape[0], indices[it], distances[it])))\n",
    "    \n",
    "    if model == 'KNN':\n",
    "        nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=k_cutoff+1).fit(coor)\n",
    "        distances, indices = nbrs.kneighbors(coor)\n",
    "        KNN_list = []\n",
    "        for it in range(indices.shape[0]):\n",
    "            KNN_list.append(pd.DataFrame(zip([it]*indices.shape[1],indices[it,:], distances[it,:])))\n",
    "\n",
    "    KNN_df = pd.concat(KNN_list)\n",
    "    KNN_df.columns = ['Cell1', 'Cell2', 'Distance']\n",
    "\n",
    "    Spatial_Net = KNN_df.copy()\n",
    "    Spatial_Net = Spatial_Net.loc[Spatial_Net['Distance']>0,]\n",
    "    id_cell_trans = dict(zip(range(coor.shape[0]), np.array(coor.index), ))\n",
    "    Spatial_Net['Cell1'] = Spatial_Net['Cell1'].map(id_cell_trans)\n",
    "    Spatial_Net['Cell2'] = Spatial_Net['Cell2'].map(id_cell_trans)\n",
    "    if verbose:\n",
    "        print('The graph contains %d edges, %d cells.' %(Spatial_Net.shape[0], adata.n_obs))\n",
    "        print('%.4f neighbors per cell on average.' %(Spatial_Net.shape[0]/adata.n_obs))\n",
    "\n",
    "    adata.uns['Spatial_Net'] = Spatial_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transfer_pytorch_Data(adata):\n",
    "    G_df = adata.uns['Spatial_Net'].copy()\n",
    "    cells = np.array(adata.obs_names)\n",
    "    cells_id_tran = dict(zip(cells, range(cells.shape[0])))\n",
    "    G_df['Cell1'] = G_df['Cell1'].map(cells_id_tran)\n",
    "    G_df['Cell2'] = G_df['Cell2'].map(cells_id_tran)\n",
    "\n",
    "    G = sp.coo_matrix((np.ones(G_df.shape[0]), (G_df['Cell1'], G_df['Cell2'])), shape=(adata.n_obs, adata.n_obs))\n",
    "    G = G + sp.eye(G.shape[0])\n",
    "\n",
    "    edgeList = np.nonzero(G)\n",
    "    if type(adata.X) == np.ndarray:\n",
    "        data = Data(edge_index=torch.LongTensor(np.array(\n",
    "            [edgeList[0], edgeList[1]])), x=torch.FloatTensor(adata.X))  # .todense()\n",
    "    else:\n",
    "        data = Data(edge_index=torch.LongTensor(np.array(\n",
    "            [edgeList[0], edgeList[1]])), x=torch.FloatTensor(adata.X.todense()))  # .todense()\n",
    "    return data\n",
    "\n",
    "def Batch_Data(adata, num_batch_x, num_batch_y, spatial_key=['X', 'Y'], plot_Stats=False):\n",
    "    Sp_df = adata.obs.loc[:, spatial_key].copy()\n",
    "    Sp_df = np.array(Sp_df)\n",
    "    batch_x_coor = [np.percentile(Sp_df[:, 0], (1/num_batch_x)*x*100) for x in range(num_batch_x+1)]\n",
    "    batch_y_coor = [np.percentile(Sp_df[:, 1], (1/num_batch_y)*x*100) for x in range(num_batch_y+1)]\n",
    "\n",
    "    Batch_list = []\n",
    "    for it_x in range(num_batch_x):\n",
    "        for it_y in range(num_batch_y):\n",
    "            min_x = batch_x_coor[it_x]\n",
    "            max_x = batch_x_coor[it_x+1]\n",
    "            min_y = batch_y_coor[it_y]\n",
    "            max_y = batch_y_coor[it_y+1]\n",
    "            temp_adata = adata.copy()\n",
    "            temp_adata = temp_adata[temp_adata.obs[spatial_key[0]].map(lambda x: min_x <= x <= max_x)]\n",
    "            temp_adata = temp_adata[temp_adata.obs[spatial_key[1]].map(lambda y: min_y <= y <= max_y)]\n",
    "            Batch_list.append(temp_adata)\n",
    "    if plot_Stats:\n",
    "        f, ax = plt.subplots(figsize=(1, 3))\n",
    "        plot_df = pd.DataFrame([x.shape[0] for x in Batch_list], columns=['#spot/batch'])\n",
    "        sns.boxplot(y='#spot/batch', data=plot_df, ax=ax)\n",
    "        sns.stripplot(y='#spot/batch', data=plot_df, ax=ax, color='red', size=5)\n",
    "    return Batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adatas['13months-disease-replicate_1'].copy()\n",
    "Cal_Spatial_Net(adata, rad_cutoff=150, model='Radius', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Transfer_pytorch_Data(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用训练过程，hidden_channels 设为 [512, 30]\n",
    "model, latent_rep, loss_list = train_STAGATE_GAE(\n",
    "        data,\n",
    "        hidden_channels=[512, 30],\n",
    "        n_epochs=2000,  # 可根据需求增加训练轮数\n",
    "        lr=0.001,\n",
    "        weight_decay=0.0001,\n",
    "        gradient_clipping=5.0,\n",
    "        random_seed=42,\n",
    "        verbose=True,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss_list, label='Training Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# latent_rep 即为节点的低维表示，可供后续聚类或可视化使用\n",
    "print(\"Latent representation shape:\", latent_rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm['X_STAGATE'] = latent_rep\n",
    "sc.pp.neighbors(adata, use_rep=\"X_STAGATE\", n_neighbors=30)\n",
    "sc.tl.leiden(adata, key_added=\"leiden_STAGATE\", resolution=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(adata, color=\"leiden_STAGATE\", spot_size=10, title=\"STAGATE Clustering\", ncols=3, frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 我的数据搭建，它的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional\n",
    "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
    "                                    OptTensor)\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "\n",
    "\n",
    "class STAGATEconv(MessagePassing):\n",
    "    r\"\"\"The graph attentional operator from the `\"Graph Attention Networks\"\n",
    "    <https://arxiv.org/abs/1710.10903>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\alpha_{i,i}\\mathbf{\\Theta}\\mathbf{x}_{i} +\n",
    "        \\sum_{j \\in \\mathcal{N}(i)} \\alpha_{i,j}\\mathbf{\\Theta}\\mathbf{x}_{j},\n",
    "\n",
    "    where the attention coefficients :math:`\\alpha_{i,j}` are computed as\n",
    "\n",
    "    .. math::\n",
    "        \\alpha_{i,j} =\n",
    "        \\frac{\n",
    "        \\exp\\left(\\mathrm{LeakyReLU}\\left(\\mathbf{a}^{\\top}\n",
    "        [\\mathbf{\\Theta}\\mathbf{x}_i \\, \\Vert \\, \\mathbf{\\Theta}\\mathbf{x}_j]\n",
    "        \\right)\\right)}\n",
    "        {\\sum_{k \\in \\mathcal{N}(i) \\cup \\{ i \\}}\n",
    "        \\exp\\left(\\mathrm{LeakyReLU}\\left(\\mathbf{a}^{\\top}\n",
    "        [\\mathbf{\\Theta}\\mathbf{x}_i \\, \\Vert \\, \\mathbf{\\Theta}\\mathbf{x}_k]\n",
    "        \\right)\\right)}.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int or tuple): Size of each input sample, or :obj:`-1` to\n",
    "            derive the size from the first input(s) to the forward method.\n",
    "            A tuple corresponds to the sizes of source and target\n",
    "            dimensionalities.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        heads (int, optional): Number of multi-head-attentions.\n",
    "            (default: :obj:`1`)\n",
    "        concat (bool, optional): If set to :obj:`False`, the multi-head\n",
    "            attentions are averaged instead of concatenated.\n",
    "            (default: :obj:`True`)\n",
    "        negative_slope (float, optional): LeakyReLU angle of the negative\n",
    "            slope. (default: :obj:`0.2`)\n",
    "        dropout (float, optional): Dropout probability of the normalized\n",
    "            attention coefficients which exposes each node to a stochastically\n",
    "            sampled neighborhood during training. (default: :obj:`0`)\n",
    "        add_self_loops (bool, optional): If set to :obj:`False`, will not add\n",
    "            self-loops to the input graph. (default: :obj:`True`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "    _alpha: OptTensor\n",
    "\n",
    "    def __init__(self, in_channels: Union[int, Tuple[int, int]],\n",
    "                 out_channels: int, heads: int = 1, concat: bool = True,\n",
    "                 negative_slope: float = 0.2, dropout: float = 0.0,\n",
    "                 add_self_loops: bool = True, bias: bool = True, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super(STAGATEconv, self).__init__(node_dim=0, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.concat = concat\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        # In case we are operating in bipartite graphs, we apply separate\n",
    "        # transformations 'lin_src' and 'lin_dst' to source and target nodes:\n",
    "        # if isinstance(in_channels, int):\n",
    "        #     self.lin_src = Linear(in_channels, heads * out_channels,\n",
    "        #                           bias=False, weight_initializer='glorot')\n",
    "        #     self.lin_dst = self.lin_src\n",
    "        # else:\n",
    "        #     self.lin_src = Linear(in_channels[0], heads * out_channels, False,\n",
    "        #                           weight_initializer='glorot')\n",
    "        #     self.lin_dst = Linear(in_channels[1], heads * out_channels, False,\n",
    "        #                           weight_initializer='glorot')\n",
    "\n",
    "        self.lin_src = nn.Parameter(torch.zeros(size=(in_channels, out_channels)))\n",
    "        nn.init.xavier_normal_(self.lin_src.data, gain=1.414)\n",
    "        self.lin_dst = self.lin_src\n",
    "\n",
    "\n",
    "        # The learnable parameters to compute attention coefficients:\n",
    "        self.att_src = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        self.att_dst = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        nn.init.xavier_normal_(self.att_src.data, gain=1.414)\n",
    "        nn.init.xavier_normal_(self.att_dst.data, gain=1.414)\n",
    "\n",
    "        # if bias and concat:\n",
    "        #     self.bias = Parameter(torch.Tensor(heads * out_channels))\n",
    "        # elif bias and not concat:\n",
    "        #     self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        # else:\n",
    "        #     self.register_parameter('bias', None)\n",
    "\n",
    "        self._alpha = None\n",
    "        self.attentions = None\n",
    "\n",
    "        # self.reset_parameters()\n",
    "\n",
    "    # def reset_parameters(self):\n",
    "    #     self.lin_src.reset_parameters()\n",
    "    #     self.lin_dst.reset_parameters()\n",
    "    #     glorot(self.att_src)\n",
    "    #     glorot(self.att_dst)\n",
    "    #     # zeros(self.bias)\n",
    "\n",
    "    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
    "                size: Size = None, return_attention_weights=None, attention=True, tied_attention = None):\n",
    "        # type: (Union[Tensor, OptPairTensor], Tensor, Size, NoneType) -> Tensor  # noqa\n",
    "        # type: (Union[Tensor, OptPairTensor], SparseTensor, Size, NoneType) -> Tensor  # noqa\n",
    "        # type: (Union[Tensor, OptPairTensor], Tensor, Size, bool) -> Tuple[Tensor, Tuple[Tensor, Tensor]]  # noqa\n",
    "        # type: (Union[Tensor, OptPairTensor], SparseTensor, Size, bool) -> Tuple[Tensor, SparseTensor]  # noqa\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            return_attention_weights (bool, optional): If set to :obj:`True`,\n",
    "                will additionally return the tuple\n",
    "                :obj:`(edge_index, attention_weights)`, holding the computed\n",
    "                attention weights for each edge. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        H, C = self.heads, self.out_channels\n",
    "\n",
    "        # We first transform the input node features. If a tuple is passed, we\n",
    "        # transform source and target node features via separate weights:\n",
    "        if isinstance(x, Tensor):\n",
    "            assert x.dim() == 2, \"Static graphs not supported in 'GATConv'\"\n",
    "            # x_src = x_dst = self.lin_src(x).view(-1, H, C)\n",
    "            x_src = x_dst = torch.mm(x, self.lin_src).view(-1, H, C)\n",
    "        else:  # Tuple of source and target node features:\n",
    "            x_src, x_dst = x\n",
    "            assert x_src.dim() == 2, \"Static graphs not supported in 'GATConv'\"\n",
    "            x_src = self.lin_src(x_src).view(-1, H, C)\n",
    "            if x_dst is not None:\n",
    "                x_dst = self.lin_dst(x_dst).view(-1, H, C)\n",
    "\n",
    "        x = (x_src, x_dst)\n",
    "\n",
    "        if not attention:\n",
    "            return x[0].mean(dim=1)\n",
    "            # return x[0].view(-1, self.heads * self.out_channels)\n",
    "\n",
    "        if tied_attention == None:\n",
    "            # Next, we compute node-level attention coefficients, both for source\n",
    "            # and target nodes (if present):\n",
    "            alpha_src = (x_src * self.att_src).sum(dim=-1)\n",
    "            alpha_dst = None if x_dst is None else (x_dst * self.att_dst).sum(-1)\n",
    "            alpha = (alpha_src, alpha_dst)\n",
    "            self.attentions = alpha\n",
    "        else:\n",
    "            alpha = tied_attention\n",
    "\n",
    "\n",
    "        if self.add_self_loops:\n",
    "            if isinstance(edge_index, Tensor):\n",
    "                # We only want to add self-loops for nodes that appear both as\n",
    "                # source and target nodes:\n",
    "                num_nodes = x_src.size(0)\n",
    "                if x_dst is not None:\n",
    "                    num_nodes = min(num_nodes, x_dst.size(0))\n",
    "                num_nodes = min(size) if size is not None else num_nodes\n",
    "                edge_index, _ = remove_self_loops(edge_index)\n",
    "                edge_index, _ = add_self_loops(edge_index, num_nodes=num_nodes)\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                edge_index = set_diag(edge_index)\n",
    "\n",
    "        # propagate_type: (x: OptPairTensor, alpha: OptPairTensor)\n",
    "        out = self.propagate(edge_index, x=x, alpha=alpha, size=size)\n",
    "\n",
    "        alpha = self._alpha\n",
    "        assert alpha is not None\n",
    "        self._alpha = None\n",
    "\n",
    "        if self.concat:\n",
    "            out = out.view(-1, self.heads * self.out_channels)\n",
    "        else:\n",
    "            out = out.mean(dim=1)\n",
    "\n",
    "        # if self.bias is not None:\n",
    "        #     out += self.bias\n",
    "\n",
    "        if isinstance(return_attention_weights, bool):\n",
    "            if isinstance(edge_index, Tensor):\n",
    "                return out, (edge_index, alpha)\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                return out, edge_index.set_value(alpha, layout='coo')\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def message(self, x_j: Tensor, alpha_j: Tensor, alpha_i: OptTensor,\n",
    "                index: Tensor, ptr: OptTensor,\n",
    "                size_i: Optional[int]) -> Tensor:\n",
    "        # Given egel-level attention coefficients for source and target nodes,\n",
    "        # we simply need to sum them up to \"emulate\" concatenation:\n",
    "        alpha = alpha_j if alpha_i is None else alpha_j + alpha_i\n",
    "\n",
    "        #alpha = F.leaky_relu(alpha, self.negative_slope)\n",
    "        alpha = torch.sigmoid(alpha)\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        self._alpha = alpha  # Save for later use.\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "        return x_j * alpha.unsqueeze(-1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, heads={})'.format(self.__class__.__name__,\n",
    "                                             self.in_channels,\n",
    "                                             self.out_channels, self.heads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STAGATE(torch.nn.Module):\n",
    "    def __init__(self, hidden_dims):\n",
    "        super(STAGATE, self).__init__()\n",
    "\n",
    "        [in_dim, num_hidden, out_dim] = hidden_dims\n",
    "        self.conv1 = STAGATEconv(in_dim, num_hidden, heads=1, concat=False,\n",
    "                             dropout=0, add_self_loops=False, bias=False)\n",
    "        self.conv2 = STAGATEconv(num_hidden, out_dim, heads=1, concat=False,\n",
    "                             dropout=0, add_self_loops=False, bias=False)\n",
    "        self.conv3 = STAGATEconv(out_dim, num_hidden, heads=1, concat=False,\n",
    "                             dropout=0, add_self_loops=False, bias=False)\n",
    "        self.conv4 = STAGATEconv(num_hidden, in_dim, heads=1, concat=False,\n",
    "                             dropout=0, add_self_loops=False, bias=False)\n",
    "\n",
    "    def forward(self, features, edge_index):\n",
    "\n",
    "        h1 = F.elu(self.conv1(features, edge_index))\n",
    "        h2 = self.conv2(h1, edge_index, attention=False)\n",
    "        self.conv3.lin_src.data = self.conv2.lin_src.transpose(0, 1)\n",
    "        self.conv3.lin_dst.data = self.conv2.lin_dst.transpose(0, 1)\n",
    "        self.conv4.lin_src.data = self.conv1.lin_src.transpose(0, 1)\n",
    "        self.conv4.lin_dst.data = self.conv1.lin_dst.transpose(0, 1)\n",
    "        h3 = F.elu(self.conv3(h2, edge_index, attention=True,\n",
    "                              tied_attention=self.conv1.attentions))\n",
    "        h4 = self.conv4(h3, edge_index, attention=False)\n",
    "\n",
    "        return h2, h4  # F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph_data_dict['13months-disease-replicate_1'].clone()\n",
    "# Test for a single forward pass\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "in_channels = data.x.size(-1)\n",
    "hidden_dims = [in_channels, 512, 30]\n",
    "\n",
    "model = STAGATE(hidden_dims).to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "# model(data.x, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_everything()\n",
    "random_seed=0\n",
    "seed=random_seed\n",
    "import random\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_epochs=1000\n",
    "lr=0.001\n",
    "key_added='STAGATE'\n",
    "gradient_clipping=5.\n",
    "weight_decay=0.0001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "loss_list = []\n",
    "for epoch in tqdm(range(1, n_epochs+1)):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z, out = model(data.x, data.edge_index)\n",
    "    loss = F.mse_loss(data.x, out) #F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    loss_list.append(loss.item())\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z, out = model(data.x, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adatas['13months-disease-replicate_1'].copy()\n",
    "STAGATE_rep = z.to('cpu').detach().numpy()\n",
    "adata.obsm[key_added] = STAGATE_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep=key_added, n_neighbors=30)\n",
    "sc.tl.leiden(adata, key_added=\"leiden_STAGATE\", resolution=0.1)\n",
    "sc.pl.spatial(adata, color=\"leiden_STAGATE\", spot_size=10, title=\"STAGATE Clustering\", ncols=3, frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 先尝试一下共享参数+转置矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class STAGATE_GAE_Tied(nn.Module):\n",
    "    \"\"\"\n",
    "    在你的 STAGATE_GAE 基础上增加“对称参数共享”的版本。\n",
    "    假设依旧使用单头 (heads=1, concat=False)，\n",
    "    这样每层 GATConv 中 lin_src / lin_dst 的形状都是 [out_channels, in_channels]。\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            heads_per_layer: list = [1, 1],\n",
    "            hidden_channels: list = [256, 256],\n",
    "            dropout: float = 0.0,\n",
    "    ):\n",
    "        super(STAGATE_GAE_Tied, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.heads_per_layer = heads_per_layer\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = len(hidden_channels)\n",
    "\n",
    "        self.encoder_convs = nn.ModuleList()\n",
    "        self.decoder_convs = nn.ModuleList()\n",
    "\n",
    "        # -------- 编码器 (Encoder) --------\n",
    "        for i in range(self.num_layers):\n",
    "            conv_in_channels = in_channels if i == 0 else hidden_channels[i - 1]\n",
    "            conv_out_channels = hidden_channels[i]\n",
    "            heads = heads_per_layer[i]\n",
    "            gat_conv = GATConv(\n",
    "                conv_in_channels,\n",
    "                conv_out_channels,\n",
    "                heads=heads,\n",
    "                dropout=dropout,\n",
    "                add_self_loops=True,\n",
    "                concat=False  # 保持 False，便于后面做转置共享\n",
    "            )\n",
    "            self.encoder_convs.append(gat_conv)\n",
    "\n",
    "        # -------- 解码器 (Decoder) --------\n",
    "        # “对称”指：第 i 层的输入正好是第 i 层 Encoder 的输出\n",
    "        # 且输出是上一层 Encoder 的输入，这样才能做转置共享\n",
    "        for i in range(self.num_layers - 1, -1, -1):\n",
    "            conv_in_channels = hidden_channels[i]\n",
    "            conv_out_channels = in_channels if i == 0 else hidden_channels[i - 1]\n",
    "            heads = heads_per_layer[i]\n",
    "            gat_conv = GATConv(\n",
    "                conv_in_channels,\n",
    "                conv_out_channels,\n",
    "                heads=heads,\n",
    "                dropout=dropout,\n",
    "                add_self_loops=True,\n",
    "                concat=False\n",
    "            )\n",
    "            self.decoder_convs.append(gat_conv)\n",
    "\n",
    "    def forward(self, data: Data, return_hidden=False):\n",
    "        \"\"\"\n",
    "        在 forward 中：\n",
    "          1. 先依次通过 Encoder；\n",
    "          2. 将 Decoder 对应层的 lin_src/lin_dst.weight = Encoder 相应层权重的转置；\n",
    "          3. 再依次通过 Decoder。\n",
    "        注意：self.decoder_convs[0] 对应 self.encoder_convs[-1]。\n",
    "        \"\"\"\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        hiddens_per_layer = []\n",
    "\n",
    "        # -------- 前向：Encoder --------\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.encoder_convs[i](x, edge_index)\n",
    "            x = F.elu(x)\n",
    "            hiddens_per_layer.append(x)\n",
    "        \n",
    "        # 到这里，x 是最后一层 Encoder 的输出（潜在表示）\n",
    "\n",
    "        # -------- 对称参数共享 (Tie Weights) --------\n",
    "        # encoder_convs[i] <--> decoder_convs[num_layers-1-i]\n",
    "        # 注意只演示 lin_* 的转置共享，attention (att) 这部分不做共享\n",
    "        for i in range(self.num_layers):\n",
    "            enc_layer = self.encoder_convs[i]\n",
    "            dec_layer = self.decoder_convs[self.num_layers - 1 - i]\n",
    "            \n",
    "            # lin_src\n",
    "            if enc_layer.lin_src is not None and dec_layer.lin_src is not None:\n",
    "                # 将 decoder 的权重设为 encoder 的转置\n",
    "                w_enc = enc_layer.lin_src.weight  # [out_enc, in_enc]\n",
    "                w_dec = dec_layer.lin_src.weight  # [out_dec, in_dec]\n",
    "                if w_enc is not None and w_dec is not None:\n",
    "                    # 设置 data，保证梯度可以正确反传\n",
    "                    # 也可以直接 dec_layer.lin_src.weight = nn.Parameter(w_enc.data.transpose(0,1))\n",
    "                    dec_layer.lin_src.weight.data = w_enc.data.transpose(0, 1)\n",
    "\n",
    "            # lin_dst（若与 lin_src 分别存在时也同理）\n",
    "            if enc_layer.lin_dst is not None and dec_layer.lin_dst is not None:\n",
    "                w_enc_dst = enc_layer.lin_dst.weight\n",
    "                w_dec_dst = dec_layer.lin_dst.weight\n",
    "                if w_enc_dst is not None and w_dec_dst is not None:\n",
    "                    dec_layer.lin_dst.weight.data = w_enc_dst.data.transpose(0, 1)\n",
    "\n",
    "        # -------- 前向：Decoder --------\n",
    "        # 继续从潜在表示 x -> Decoder\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.decoder_convs[i](x, edge_index)\n",
    "            x = F.elu(x)\n",
    "            hiddens_per_layer.append(x)\n",
    "\n",
    "        if return_hidden:\n",
    "            return x, hiddens_per_layer\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 训练过程定义：train_STAGATE_GAE\n",
    "# -------------------------------\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = True\n",
    "\n",
    "def train_STAGATE_mine(graph_data: Data,\n",
    "                       model = None,\n",
    "                      hidden_channels=[512, 30],\n",
    "                      n_epochs=1000,\n",
    "                      lr=0.001,\n",
    "                      weight_decay=0.0001,\n",
    "                      gradient_clipping=5.0,\n",
    "                      random_seed=0,\n",
    "                      verbose=True,\n",
    "                      device=None):\n",
    "    \"\"\"\n",
    "    训练图注意力自编码器（STAGATE_GAE）。\n",
    "\n",
    "    参数:\n",
    "    - graph_data: torch_geometric.data.Data 对象，包含节点特征 x 和边索引 edge_index。\n",
    "    - hidden_channels: 编码器各层的输出维度列表。\n",
    "    - n_epochs: 总训练轮数。\n",
    "    - lr: 学习率。\n",
    "    - weight_decay: 权重衰减。\n",
    "    - gradient_clipping: 梯度裁剪阈值。\n",
    "    - random_seed: 随机种子。\n",
    "    - verbose: 是否打印训练过程中日志信息。\n",
    "    - device: 设备，如果为 None，则自动选择 GPU (若可用) 或 CPU。\n",
    "\n",
    "    返回:\n",
    "    - model: 训练后的模型\n",
    "    - latent_rep: 节点的低维潜在表示（取自 encoder 最后一层的输出）\n",
    "    - loss_list: 各轮训练损失列表\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 设置随机种子\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "    # 将数据移动到设备上\n",
    "    graph_data = graph_data.to(device)\n",
    "\n",
    "    # 模型初始化：in_channels 为节点特征维度\n",
    "    in_channels = graph_data.x.size(-1)\n",
    "    # 注意：heads_per_layer 这里设为全 1，使得每层输出维度不改变（因 concat=False）\n",
    "    if model is None:\n",
    "        model = STAGATE_GAE(in_channels=in_channels,\n",
    "                            hidden_channels=hidden_channels,\n",
    "                            heads_per_layer=[1] * len(hidden_channels),\n",
    "                            dropout=0.0).to(device)\n",
    "    else:\n",
    "        model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_list = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(1, n_epochs + 1), desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播，获得重构后的节点特征\n",
    "        out = model(graph_data)\n",
    "        # 使用均方误差损失重构原始节点特征\n",
    "        loss = F.mse_loss(out, graph_data.x)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        if verbose and epoch % 100 == 0:\n",
    "            print(f\"Epoch: {epoch:4d}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # 训练结束后提取潜在表示\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 此处采用 forward(return_hidden=True) 得到所有层的隐藏表示，\n",
    "        # 我们选取 encoder 部分最后一层的输出作为节点的潜在表示\n",
    "        _, hiddens = model(graph_data, return_hidden=True)\n",
    "        # encoder 隐藏表示位于 hiddens[0] ~ hiddens[model.num_layers-1]\n",
    "        latent_rep = hiddens[model.num_layers - 1]\n",
    "    \n",
    "    latent_rep_np = latent_rep.cpu().numpy()\n",
    "\n",
    "    return model, latent_rep_np, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = STAGATE_GAE_Tied(\n",
    "    in_channels=data.x.size(-1),\n",
    "    hidden_channels=[512, 30],  # 两层：512->512->30，再解码 30->512->512\n",
    "    heads_per_layer=[1, 1],\n",
    "    dropout=0.0\n",
    ").to(device)\n",
    "\n",
    "out = model(data)\n",
    "print(\"Reconstructed shape:\", out.shape)  # should be [num_nodes, in_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph_data_dict['13months-disease-replicate_1'].clone()\n",
    "\n",
    "# 调用训练过程，hidden_channels 设为 [512, 30]\n",
    "model, latent_rep, loss_list = train_STAGATE_mine(\n",
    "        data,\n",
    "        model=model,\n",
    "        hidden_channels=[512, 30],\n",
    "        n_epochs=1000,  # 可根据需求增加训练轮数\n",
    "        lr=0.001,\n",
    "        weight_decay=0.0001,\n",
    "        gradient_clipping=5.0,\n",
    "        random_seed=42,\n",
    "        verbose=True,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss_list, label='Training Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# latent_rep 即为节点的低维表示，可供后续聚类或可视化使用\n",
    "print(\"Latent representation shape:\", latent_rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm['X_STAGATE'] = latent_rep\n",
    "sc.pp.neighbors(adata, use_rep=\"X_STAGATE\", n_neighbors=30)\n",
    "sc.tl.leiden(adata, key_added=\"leiden_STAGATE\", resolution=0.01)\n",
    "sc.pl.spatial(adata, color=\"leiden_STAGATE\", spot_size=10, title=\"STAGATE Clustering\", ncols=3, frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 尝试完全复刻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import (\n",
    "    remove_self_loops, add_self_loops, softmax\n",
    ")\n",
    "from torch_sparse import SparseTensor, set_diag\n",
    "from typing import Union, Tuple, Optional\n",
    "\n",
    "\n",
    "class STAGATEConv(MessagePassing):\n",
    "    r\"\"\"\n",
    "    自定义的 STAGATEConv，核心逻辑与原版保持一致：\n",
    "    - 使用手动定义的线性变换：lin_src、lin_dst\n",
    "    - 注意力参数：att_src、att_dst\n",
    "    - alpha = sigmoid(alpha_j + alpha_i) 后再 softmax\n",
    "    - 支持 tied_attention 来“复用”已有注意力分数\n",
    "    - 当 attention=False 时仅作线性映射（不更新注意力）\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        heads: int = 1,\n",
    "        concat: bool = True,\n",
    "        negative_slope: float = 0.2,  # 兼容保留\n",
    "        dropout: float = 0.0,\n",
    "        add_self_loops: bool = True,\n",
    "        bias: bool = True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        参数与原版相同，只是用更多的关键字进行包装。\n",
    "        \"\"\"\n",
    "        # 'aggr' = 'add'：原版中默认累加聚合\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super(STAGATEConv, self).__init__(node_dim=0, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.concat = concat\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        # 手动定义的可学习参数\n",
    "        # 原版是 in_channels -> heads * out_channels，但这里与原版完全对齐 (不考虑多头的话就 in->out)\n",
    "        # 如果需要多头，就改成 in_channels -> heads*out_channels，再 reshape\n",
    "        self.lin_src = nn.Parameter(torch.zeros((in_channels, out_channels)))\n",
    "        nn.init.xavier_normal_(self.lin_src.data, gain=1.414)\n",
    "        # 原版中 lin_dst = lin_src；若需要区分可以自行创建\n",
    "        self.lin_dst = self.lin_src\n",
    "\n",
    "        # 注意力参数: [1, heads, out_channels]\n",
    "        self.att_src = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        self.att_dst = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        nn.init.xavier_normal_(self.att_src, gain=1.414)\n",
    "        nn.init.xavier_normal_(self.att_dst, gain=1.414)\n",
    "\n",
    "        # 是否添加 bias\n",
    "        if bias:\n",
    "            if concat:\n",
    "                self.bias = Parameter(torch.Tensor(heads * out_channels))\n",
    "            else:\n",
    "                self.bias = Parameter(torch.Tensor(out_channels))\n",
    "            nn.init.zeros_(self.bias)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        # 用来临时保存注意力\n",
    "        self._alpha = None\n",
    "        # 存储本层计算出来的 alpha_src/alpha_dst\n",
    "        self.attentions = None\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        edge_index: Union[Tensor, SparseTensor],\n",
    "        size: Optional[Tuple[int, int]] = None,\n",
    "        return_attention_weights: bool = False,\n",
    "        attention: bool = True,\n",
    "        tied_attention: Optional[Tuple[Tensor, Tensor]] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        与原版相同，x: [num_nodes, in_channels]\n",
    "        \"\"\"\n",
    "        # 只支持 x 为 Tensor（对 bipartite 这里不再演示）\n",
    "        assert isinstance(x, Tensor), \"Static graphs not supported in 'STAGATEConv'\"\n",
    "\n",
    "        # 先做线性变换\n",
    "        # 如果 heads=1，可以直接 [N, in_channels] x [in_channels, out_channels] = [N, out_channels]\n",
    "        # 若 heads>1，需要 reshape -> [N, heads, out_channels]\n",
    "        if self.heads == 1:\n",
    "            x_src = torch.mm(x, self.lin_src)  # [N, out_channels]\n",
    "            x_src = x_src.unsqueeze(1)         # [N, 1, out_channels]\n",
    "            x_dst = x_src\n",
    "        else:\n",
    "            # in_channels -> heads * out_channels\n",
    "            # 这里要预先把 lin_src 改成 [in_channels, heads*out_channels] 再 reshape\n",
    "            raise NotImplementedError(\"多头情况请自行完善同原版一致\")\n",
    "\n",
    "        # 如果不需要计算注意力，直接返回线性映射结果\n",
    "        if not attention:\n",
    "            # 与原版一样，要把多头结果合并起来\n",
    "            if self.concat and self.heads > 1:\n",
    "                out_no_att = x_src.reshape(-1, self.heads * self.out_channels)\n",
    "                return out_no_att\n",
    "            else:\n",
    "                # single-head 或者 mean\n",
    "                out_no_att = x_src.mean(dim=1)  # single-head 就相当于 squeeze\n",
    "                return out_no_att\n",
    "\n",
    "        # 处理 tied_attention\n",
    "        if tied_attention is None:\n",
    "            # alpha_src, alpha_dst = (x_src * att_src).sum(dim=-1), (x_dst * att_dst).sum(dim=-1)\n",
    "            # 但原版默认 x_src=x_dst，所以 alpha_dst = alpha_src * att_dst\n",
    "            alpha_src = (x_src * self.att_src).sum(dim=-1)  # [N, heads]\n",
    "            alpha_dst = (x_dst * self.att_dst).sum(dim=-1) if x_dst is not None else None\n",
    "            self.attentions = (alpha_src, alpha_dst)\n",
    "        else:\n",
    "            # 复用其他层的注意力 (alpha_src, alpha_dst)\n",
    "            alpha_src, alpha_dst = tied_attention\n",
    "\n",
    "        # 根据是否加 self-loop\n",
    "        if self.add_self_loops:\n",
    "            if isinstance(edge_index, Tensor):\n",
    "                num_nodes = x.size(0)\n",
    "                edge_index, _ = remove_self_loops(edge_index)\n",
    "                edge_index, _ = add_self_loops(edge_index, num_nodes=num_nodes)\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                edge_index = set_diag(edge_index)\n",
    "\n",
    "        # 调用 propagate\n",
    "        out = self.propagate(\n",
    "            edge_index, \n",
    "            x=(x_src, x_dst), \n",
    "            alpha=(alpha_src, alpha_dst),\n",
    "            size=size\n",
    "        )\n",
    "\n",
    "        alpha = self._alpha\n",
    "        self._alpha = None  # 用完就清空\n",
    "\n",
    "        # 拼接或者平均\n",
    "        if self.concat and self.heads > 1:\n",
    "            out = out.view(-1, self.heads * self.out_channels)\n",
    "        else:\n",
    "            out = out.mean(dim=1)\n",
    "\n",
    "        # bias\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "\n",
    "        if return_attention_weights:\n",
    "            return out, (edge_index, alpha)\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def message(self, x_j: Tensor, alpha: Tuple[Tensor, Optional[Tensor]], index: Tensor, ptr: Optional[Tensor], size_i: Optional[int]):\n",
    "        alpha_src, alpha_dst = alpha\n",
    "        # 手动根据 edge_index 分别采集源节点与目标节点对应的注意力分数\n",
    "        alpha_j = alpha_src[index[0]]  # 假设 index[0] 是源节点索引\n",
    "        if alpha_dst is not None:\n",
    "            alpha_i = alpha_dst[index[1]]  # 假设 index[1] 是目标节点索引\n",
    "            alpha_ij = alpha_j + alpha_i\n",
    "        else:\n",
    "            alpha_ij = alpha_j\n",
    "        alpha_ij = torch.sigmoid(alpha_ij)\n",
    "        alpha_ij = softmax(alpha_ij, index[1] if alpha_dst is not None else index, ptr, size_i)\n",
    "        self._alpha = alpha_ij\n",
    "        alpha_ij = F.dropout(alpha_ij, p=self.dropout, training=self.training)\n",
    "        return x_j * alpha_ij.unsqueeze(-1)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"{self.__class__.__name__}(\"\n",
    "            f\"{self.in_channels}, {self.out_channels}, heads={self.heads}, \"\n",
    "            f\"concat={self.concat}, dropout={self.dropout})\"\n",
    "        )\n",
    "\n",
    "\n",
    "class STAGATE(nn.Module):\n",
    "    r\"\"\"\n",
    "    与原版类似，包含四层“对称”结构：\n",
    "    1) conv1: in_dim -> num_hidden\n",
    "    2) conv2: num_hidden -> out_dim\n",
    "    3) conv3: out_dim -> num_hidden (与 conv2 参数转置共享)\n",
    "    4) conv4: num_hidden -> in_dim  (与 conv1 参数转置共享)\n",
    "\n",
    "    并在 forward 中：\n",
    "    - h2 = conv2(h1, attention=False)\n",
    "    - conv3 用 tied_attention=conv1.attentions\n",
    "    - conv4 attention=False\n",
    "\n",
    "    这样即保留了原版的做法。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim: int, num_hidden: int, out_dim: int):\n",
    "        super(STAGATE, self).__init__()\n",
    "\n",
    "        # 初始化四层\n",
    "        self.conv1 = STAGATEConv(\n",
    "            in_channels=in_dim,\n",
    "            out_channels=num_hidden,\n",
    "            heads=1,\n",
    "            concat=False,\n",
    "            dropout=0.0,\n",
    "            add_self_loops=False,\n",
    "            bias=False\n",
    "        )\n",
    "        self.conv2 = STAGATEConv(\n",
    "            in_channels=num_hidden,\n",
    "            out_channels=out_dim,\n",
    "            heads=1,\n",
    "            concat=False,\n",
    "            dropout=0.0,\n",
    "            add_self_loops=False,\n",
    "            bias=False\n",
    "        )\n",
    "        self.conv3 = STAGATEConv(\n",
    "            in_channels=out_dim,\n",
    "            out_channels=num_hidden,\n",
    "            heads=1,\n",
    "            concat=False,\n",
    "            dropout=0.0,\n",
    "            add_self_loops=False,\n",
    "            bias=False\n",
    "        )\n",
    "        self.conv4 = STAGATEConv(\n",
    "            in_channels=num_hidden,\n",
    "            out_channels=in_dim,\n",
    "            heads=1,\n",
    "            concat=False,\n",
    "            dropout=0.0,\n",
    "            add_self_loops=False,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor):\n",
    "        # 1) conv1\n",
    "        h1 = F.elu(self.conv1(x, edge_index, attention=True))  # 这里默认 attention=True\n",
    "        # 2) conv2\n",
    "        h2 = self.conv2(h1, edge_index, attention=False)       # 原版对第二层关闭注意力\n",
    "\n",
    "        # 下面是权重共享: conv3 使用 conv2 的转置, conv4 使用 conv1 的转置\n",
    "        self.conv3.lin_src.data = self.conv2.lin_src.transpose(0, 1)\n",
    "        self.conv3.lin_dst.data = self.conv2.lin_dst.transpose(0, 1)\n",
    "        self.conv4.lin_src.data = self.conv1.lin_src.transpose(0, 1)\n",
    "        self.conv4.lin_dst.data = self.conv1.lin_dst.transpose(0, 1)\n",
    "\n",
    "        # 3) conv3\n",
    "        # tied_attention 指定使用 conv1 的 alpha，而不自己重新计算\n",
    "        h3 = F.elu(\n",
    "            self.conv3(\n",
    "                h2, \n",
    "                edge_index, \n",
    "                attention=True,\n",
    "                tied_attention=self.conv1.attentions\n",
    "            )\n",
    "        )\n",
    "        # 4) conv4\n",
    "        h4 = self.conv4(h3, edge_index, attention=False)\n",
    "\n",
    "        return h2, h4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a single forward pass\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_data = data.clone()\n",
    "\n",
    "model = STAGATE(\n",
    "    in_dim=test_data.x.size(-1),\n",
    "    num_hidden=512,\n",
    "    out_dim=30\n",
    ").to(device)\n",
    "\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "model(test_data.x, test_data.edge_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = graph_data_dict['8months-disease-replicate_1'].clone()\n",
    "adata = adatas['8months-disease-replicate_1'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#  1. 环境准备与导入\n",
    "########################################\n",
    "\n",
    "# 如果在Notebook中，需要时可取消注释后安装\n",
    "# %pip install torch torchvision torchaudio\n",
    "# %pip install torch-geometric\n",
    "# %pip install scanpy\n",
    "# %pip install tensorboard\n",
    "# %pip install pandas\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import scanpy as sc\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch.nn import Parameter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 如果在Notebook中，需要内嵌绘图\n",
    "%matplotlib inline\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 准备输出目录\n",
    "os.makedirs(\"./ablation_test\", exist_ok=True)\n",
    "\n",
    "\n",
    "########################################\n",
    "#  2. 定义可选消融的 STAGATEConv\n",
    "########################################\n",
    "\n",
    "class STAGATEConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    自定义的 GAT-like 算法，用于 STAGATE AE。\n",
    "    通过 ablation_flags 字典中的布尔值控制是否启用某些模块或更改激活。\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 ablation_flags=None,\n",
    "                 heads=1,\n",
    "                 concat=False,\n",
    "                 negative_slope=0.2,\n",
    "                 dropout=0.0,\n",
    "                 add_self_loops=True,\n",
    "                 bias=False):\n",
    "        super().__init__(node_dim=0, aggr='add')\n",
    "\n",
    "        if ablation_flags is None:\n",
    "            ablation_flags = {}\n",
    "        self.ablation_flags = ablation_flags\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.concat = concat\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        # (Ablation) 是否使用标准 Linear\n",
    "        if self.ablation_flags.get(\"use_standard_linear\", False):\n",
    "            self.lin_src = torch.nn.Linear(in_channels, out_channels, bias=False)\n",
    "            self.lin_dst = self.lin_src\n",
    "        else:\n",
    "            # 与题主类似的自定义参数\n",
    "            self.lin_src = Parameter(torch.zeros(size=(in_channels, out_channels)))\n",
    "            torch.nn.init.xavier_normal_(self.lin_src.data, gain=1.414)\n",
    "            self.lin_dst = self.lin_src\n",
    "\n",
    "        # 注意力参数\n",
    "        self.att_src = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        self.att_dst = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        torch.nn.init.xavier_normal_(self.att_src.data, gain=1.414)\n",
    "        torch.nn.init.xavier_normal_(self.att_dst.data, gain=1.414)\n",
    "\n",
    "        # 缓存中间注意力\n",
    "        self._alpha = None\n",
    "        self.attentions = None\n",
    "\n",
    "    def forward(self, x, edge_index, attention=True, tied_attention=None):\n",
    "        # 若 remove_attention 则不执行注意力机制\n",
    "        if self.ablation_flags.get(\"remove_attention\", False):\n",
    "            attention = False\n",
    "\n",
    "        H, C = self.heads, self.out_channels\n",
    "\n",
    "        # 线性变换\n",
    "        if isinstance(self.lin_src, torch.nn.Linear):\n",
    "            x_src = self.lin_src(x).view(-1, H, C)\n",
    "            x_dst = x_src\n",
    "        else:\n",
    "            x_src = torch.mm(x, self.lin_src).view(-1, H, C)\n",
    "            x_dst = x_src\n",
    "\n",
    "        if not attention:\n",
    "            # 不做注意力，直接返回均值\n",
    "            return x_src.mean(dim=1)\n",
    "\n",
    "        # 如果没有共享其他层的注意力，则自己计算\n",
    "        if tied_attention is None:\n",
    "            alpha_src = (x_src * self.att_src).sum(dim=-1)\n",
    "            alpha_dst = (x_dst * self.att_dst).sum(dim=-1)\n",
    "            alpha = (alpha_src, alpha_dst)\n",
    "            self.attentions = alpha\n",
    "        else:\n",
    "            alpha = tied_attention\n",
    "\n",
    "        # 加自环\n",
    "        if self.add_self_loops:\n",
    "            num_nodes = x_src.size(0)\n",
    "            edge_index, _ = remove_self_loops(edge_index)\n",
    "            edge_index, _ = add_self_loops(edge_index, num_nodes=num_nodes)\n",
    "\n",
    "        out = self.propagate(edge_index, x=(x_src, x_dst), alpha=alpha)\n",
    "        alpha = self._alpha\n",
    "        self._alpha = None\n",
    "\n",
    "        if self.concat:\n",
    "            out = out.view(-1, self.heads * self.out_channels)\n",
    "        else:\n",
    "            out = out.mean(dim=1)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
    "        # 将source、target的alpha相加\n",
    "        alpha = alpha_j if alpha_i is None else alpha_j + alpha_i\n",
    "\n",
    "        # 是否使用leaky_relu还是sigmoid\n",
    "        if self.ablation_flags.get(\"use_leaky_relu\", False):\n",
    "            alpha = F.leaky_relu(alpha, negative_slope=self.negative_slope)\n",
    "        else:\n",
    "            alpha = torch.sigmoid(alpha)\n",
    "\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        self._alpha = alpha\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "        return x_j * alpha.unsqueeze(-1)\n",
    "\n",
    "\n",
    "########################################\n",
    "#  3. 定义 STAGATE 自编码器\n",
    "########################################\n",
    "\n",
    "class STAGATE(torch.nn.Module):\n",
    "    def __init__(self, hidden_dims, ablation_flags=None):\n",
    "        super().__init__()\n",
    "        if ablation_flags is None:\n",
    "            ablation_flags = {}\n",
    "\n",
    "        [in_dim, num_hidden, out_dim] = hidden_dims\n",
    "        self.ablation_flags = ablation_flags\n",
    "\n",
    "        self.conv1 = STAGATEConv(in_dim, num_hidden,\n",
    "                                 ablation_flags=ablation_flags,\n",
    "                                 heads=1, concat=False,\n",
    "                                 dropout=0, add_self_loops=False, bias=False)\n",
    "        self.conv2 = STAGATEConv(num_hidden, out_dim,\n",
    "                                 ablation_flags=ablation_flags,\n",
    "                                 heads=1, concat=False,\n",
    "                                 dropout=0, add_self_loops=False, bias=False)\n",
    "        self.conv3 = STAGATEConv(out_dim, num_hidden,\n",
    "                                 ablation_flags=ablation_flags,\n",
    "                                 heads=1, concat=False,\n",
    "                                 dropout=0, add_self_loops=False, bias=False)\n",
    "        self.conv4 = STAGATEConv(num_hidden, in_dim,\n",
    "                                 ablation_flags=ablation_flags,\n",
    "                                 heads=1, concat=False,\n",
    "                                 dropout=0, add_self_loops=False, bias=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # 第一层\n",
    "        h1 = F.elu(self.conv1(x, edge_index, attention=not self.ablation_flags.get(\"remove_attention\", False)))\n",
    "        # 第二层 (不带注意力)\n",
    "        h2 = self.conv2(h1, edge_index, attention=False)\n",
    "\n",
    "        # 如果不移除权重转置共享，则执行\n",
    "        if not self.ablation_flags.get(\"remove_weight_transpose\", False):\n",
    "            if isinstance(self.conv2.lin_src, torch.nn.Linear):\n",
    "                # conv2.lin_src.weight.shape = [out_dim, in_dim]\n",
    "                # conv3.lin_src.weight.shape = [num_hidden, out_dim] （若定义和编码器对称）\n",
    "                # 如果想要conv3的权重是conv2的转置，则：\n",
    "                self.conv3.lin_src.weight.data = self.conv2.lin_src.weight.data.transpose(0, 1).clone()\n",
    "                self.conv3.lin_dst.weight.data = self.conv2.lin_dst.weight.data.transpose(0, 1).clone()\n",
    "\n",
    "                # 同理\n",
    "                self.conv4.lin_src.weight.data = self.conv1.lin_src.weight.data.transpose(0, 1).clone()\n",
    "                self.conv4.lin_dst.weight.data = self.conv1.lin_dst.weight.data.transpose(0, 1).clone()\n",
    "            else:\n",
    "                # 否则是原来的 Parameter 情况\n",
    "                self.conv3.lin_src.data = self.conv2.lin_src.transpose(0, 1)\n",
    "                self.conv3.lin_dst.data = self.conv2.lin_dst.transpose(0, 1)\n",
    "                self.conv4.lin_src.data = self.conv1.lin_src.transpose(0, 1)\n",
    "                self.conv4.lin_dst.data = self.conv1.lin_dst.transpose(0, 1)\n",
    "\n",
    "        # tied_attention\n",
    "        tied_attention = None\n",
    "        if not self.ablation_flags.get(\"remove_tied_attention\", False):\n",
    "            tied_attention = self.conv1.attentions\n",
    "\n",
    "        # 第三层\n",
    "        h3 = F.elu(self.conv3(h2, edge_index, attention=not self.ablation_flags.get(\"remove_attention\", False),\n",
    "                              tied_attention=tied_attention))\n",
    "        # 第四层\n",
    "        h4 = self.conv4(h3, edge_index, attention=False)\n",
    "\n",
    "        return h2, h4\n",
    "\n",
    "\n",
    "########################################\n",
    "#  4. 训练与评估 (AutoEncoder)\n",
    "########################################\n",
    "\n",
    "def train_and_evaluate_ae(\n",
    "    ablation_name,\n",
    "    ablation_flags,\n",
    "    graph_data,\n",
    "    adata,\n",
    "    num_epochs=200,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    save_dir=\"./ablation_test\"\n",
    "):\n",
    "    \"\"\"\n",
    "    训练STAGATE自编码器，并将中间隐层写回adata.obsm['X_STAGATE']；\n",
    "    然后使用scanpy进行聚类、可视化。\n",
    "    \"\"\"\n",
    "    writer_dir = os.path.join(save_dir, ablation_name)\n",
    "    os.makedirs(writer_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir=writer_dir)\n",
    "\n",
    "    # 准备数据\n",
    "    x = graph_data.x.to(device)\n",
    "    edge_index = graph_data.edge_index.to(device)\n",
    "\n",
    "    in_dim = x.shape[1]\n",
    "    hidden_dims = [in_dim, 64, 32]  # 可视需求修改\n",
    "    model = STAGATE(hidden_dims, ablation_flags=ablation_flags).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向：得到中间表示 h2 与重构输出 h4\n",
    "        h2, h4 = model(x, edge_index)\n",
    "        # 重构损失\n",
    "        loss = F.mse_loss(h4, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        writer.add_scalar(\"Loss/train\", loss.item(), epoch)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    # 训练结束后，获取最终表示\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        h2, h4 = model(x, edge_index)\n",
    "    latent_rep = h2.detach().cpu().numpy()\n",
    "\n",
    "    # 写回 adata.obsm\n",
    "    adata.obsm['X_STAGATE'] = latent_rep\n",
    "\n",
    "    # scanpy 聚类 & 可视化\n",
    "    sc.pp.neighbors(adata, use_rep=\"X_STAGATE\", n_neighbors=30)\n",
    "    sc.tl.leiden(adata, key_added=\"leiden_STAGATE\", resolution=0.1)\n",
    "\n",
    "    # 保存聚类图\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sc.pl.spatial(\n",
    "        adata,\n",
    "        color=\"leiden_STAGATE\",\n",
    "        spot_size=50,\n",
    "        ncols=1,\n",
    "        frameon=False,\n",
    "        show=False,\n",
    "        title=f\"{ablation_name} STAGATE Clustering\"\n",
    "    )\n",
    "    pdf_path = os.path.join(save_dir, f\"{ablation_name}_clustering.pdf\")\n",
    "    plt.savefig(pdf_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # 保存训练曲线图\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(range(num_epochs), train_losses, label='Train Reconstruction Loss')\n",
    "    plt.title(f\"{ablation_name} - AE Training Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    pdf_loss_path = os.path.join(save_dir, f\"{ablation_name}_loss.pdf\")\n",
    "    plt.savefig(pdf_loss_path)\n",
    "    plt.show()\n",
    "\n",
    "    # 返回结果\n",
    "    return {\n",
    "        \"ablation_name\": ablation_name,\n",
    "        \"final_loss\": train_losses[-1]\n",
    "    }\n",
    "\n",
    "\n",
    "########################################\n",
    "#  5. 逐一遍历“去除一个组件”的所有可能性 + 原始\n",
    "########################################\n",
    "\n",
    "# 需要您自己准备以下对象:\n",
    "# graph_data = ...\n",
    "# adata      = ...\n",
    "\n",
    "# 示例：假设您有 graph_data, adata\n",
    "# graph_data = your_graph_dict['8months-disease-replicate_1']\n",
    "# adata      = adatas['8months-disease-replicate_1']\n",
    "# 这里假设它们已准备好:\n",
    "# ----------------------------------\n",
    "# graph_data = ...\n",
    "# adata = ...\n",
    "# ----------------------------------\n",
    "\n",
    "# 我们的五项可选消融:\n",
    "#  1) remove_attention\n",
    "#  2) remove_tied_attention\n",
    "#  3) use_leaky_relu\n",
    "#  4) remove_weight_transpose\n",
    "#  5) use_standard_linear\n",
    "\n",
    "# 为了“遍历去除一个”的所有可能性，并且还包含原始不去除的对照，共计6项：\n",
    "experiments = [\n",
    "    {\n",
    "        \"name\": \"Original\",\n",
    "        \"flags\": {\n",
    "            \"remove_attention\": False,\n",
    "            \"remove_tied_attention\": False,\n",
    "            \"use_leaky_relu\": False,\n",
    "            \"remove_weight_transpose\": False,\n",
    "            \"use_standard_linear\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ablation_remove_attention\",\n",
    "        \"flags\": {\n",
    "            \"remove_attention\": True,\n",
    "            \"remove_tied_attention\": False,\n",
    "            \"use_leaky_relu\": False,\n",
    "            \"remove_weight_transpose\": False,\n",
    "            \"use_standard_linear\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ablation_remove_tied_attention\",\n",
    "        \"flags\": {\n",
    "            \"remove_attention\": False,\n",
    "            \"remove_tied_attention\": True,\n",
    "            \"use_leaky_relu\": False,\n",
    "            \"remove_weight_transpose\": False,\n",
    "            \"use_standard_linear\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ablation_use_leaky_relu\",\n",
    "        \"flags\": {\n",
    "            \"remove_attention\": False,\n",
    "            \"remove_tied_attention\": False,\n",
    "            \"use_leaky_relu\": True,\n",
    "            \"remove_weight_transpose\": False,\n",
    "            \"use_standard_linear\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ablation_remove_weight_transpose\",\n",
    "        \"flags\": {\n",
    "            \"remove_attention\": False,\n",
    "            \"remove_tied_attention\": False,\n",
    "            \"use_leaky_relu\": False,\n",
    "            \"remove_weight_transpose\": True,\n",
    "            \"use_standard_linear\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ablation_use_standard_linear\",\n",
    "        \"flags\": {\n",
    "            \"remove_attention\": False,\n",
    "            \"remove_tied_attention\": False,\n",
    "            \"use_leaky_relu\": False,\n",
    "            \"remove_weight_transpose\": False,\n",
    "            \"use_standard_linear\": True\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "results = []\n",
    "for exp in experiments:\n",
    "    print(f\"========== Running {exp['name']} ==========\")\n",
    "    res = train_and_evaluate_ae(\n",
    "        ablation_name=exp[\"name\"],\n",
    "        ablation_flags=exp[\"flags\"],\n",
    "        graph_data=graph_data,\n",
    "        adata=adata,\n",
    "        num_epochs=200,     # 可自行调整\n",
    "        lr=1e-3,            # 可自行调整\n",
    "        weight_decay=1e-5,  # 可自行调整\n",
    "        save_dir=\"./ablation_test\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "# 最终结果统计\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\n========= 单一消融 + 原始 的最终结果对比 =========\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#  1. 环境准备与导入\n",
    "########################################\n",
    "\n",
    "# 如果在Notebook中，需要时可取消注释后安装\n",
    "# %pip install torch torchvision torchaudio\n",
    "# %pip install torch-geometric\n",
    "# %pip install scanpy\n",
    "# %pip install tensorboard\n",
    "# %pip install pandas\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import scanpy as sc\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
    "from torch_geometric.nn import MessagePassing, GATConv\n",
    "from torch.nn import Parameter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 如果在Notebook中，需要内嵌绘图\n",
    "%matplotlib inline\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 准备输出目录\n",
    "os.makedirs(\"./ablation_test\", exist_ok=True)\n",
    "\n",
    "\n",
    "########################################\n",
    "#  2. 定义可选消融的自定义 STAGATEConv\n",
    "########################################\n",
    "\n",
    "class STAGATEConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    自定义的 GAT-like 算法，用于 STAGATE AE。\n",
    "    通过 ablation_flags 字典中的布尔值控制是否启用某些模块或更改激活。\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 ablation_flags=None,\n",
    "                 heads=1,\n",
    "                 concat=False,\n",
    "                 negative_slope=0.2,\n",
    "                 dropout=0.0,\n",
    "                 add_self_loops=True,\n",
    "                 bias=False):\n",
    "        super().__init__(node_dim=0, aggr='add')\n",
    "\n",
    "        if ablation_flags is None:\n",
    "            ablation_flags = {}\n",
    "        self.ablation_flags = ablation_flags\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.concat = concat\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        # (Ablation) 是否使用标准 Linear\n",
    "        if self.ablation_flags.get(\"use_standard_linear\", False):\n",
    "            self.lin_src = torch.nn.Linear(in_channels, out_channels, bias=False)\n",
    "            self.lin_dst = self.lin_src\n",
    "        else:\n",
    "            # 与题主类似的自定义参数\n",
    "            self.lin_src = Parameter(torch.zeros(size=(in_channels, out_channels)))\n",
    "            torch.nn.init.xavier_normal_(self.lin_src.data, gain=1.414)\n",
    "            self.lin_dst = self.lin_src\n",
    "\n",
    "        # 注意力参数\n",
    "        self.att_src = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        self.att_dst = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        torch.nn.init.xavier_normal_(self.att_src.data, gain=1.414)\n",
    "        torch.nn.init.xavier_normal_(self.att_dst.data, gain=1.414)\n",
    "\n",
    "        # 缓存中间注意力\n",
    "        self._alpha = None\n",
    "        self.attentions = None\n",
    "\n",
    "    def forward(self, x, edge_index, attention=True, tied_attention=None):\n",
    "        # 若 remove_attention 则不执行注意力机制\n",
    "        if self.ablation_flags.get(\"remove_attention\", False):\n",
    "            attention = False\n",
    "\n",
    "        H, C = self.heads, self.out_channels\n",
    "\n",
    "        # 线性变换\n",
    "        if isinstance(self.lin_src, torch.nn.Linear):\n",
    "            x_src = self.lin_src(x).view(-1, H, C)\n",
    "            x_dst = x_src\n",
    "        else:\n",
    "            x_src = torch.mm(x, self.lin_src).view(-1, H, C)\n",
    "            x_dst = x_src\n",
    "\n",
    "        if not attention:\n",
    "            # 不做注意力，直接返回均值\n",
    "            return x_src.mean(dim=1)\n",
    "\n",
    "        # 如果没有共享其他层的注意力，则自己计算\n",
    "        if tied_attention is None:\n",
    "            alpha_src = (x_src * self.att_src).sum(dim=-1)\n",
    "            alpha_dst = (x_dst * self.att_dst).sum(dim=-1)\n",
    "            alpha = (alpha_src, alpha_dst)\n",
    "            self.attentions = alpha\n",
    "        else:\n",
    "            alpha = tied_attention\n",
    "\n",
    "        # 加自环\n",
    "        if self.add_self_loops:\n",
    "            num_nodes = x_src.size(0)\n",
    "            edge_index, _ = remove_self_loops(edge_index)\n",
    "            edge_index, _ = add_self_loops(edge_index, num_nodes=num_nodes)\n",
    "\n",
    "        out = self.propagate(edge_index, x=(x_src, x_dst), alpha=alpha)\n",
    "        alpha = self._alpha\n",
    "        self._alpha = None\n",
    "\n",
    "        if self.concat:\n",
    "            out = out.view(-1, self.heads * self.out_channels)\n",
    "        else:\n",
    "            out = out.mean(dim=1)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
    "        # 将source、target的alpha相加\n",
    "        alpha = alpha_j if alpha_i is None else alpha_j + alpha_i\n",
    "\n",
    "        # 是否使用leaky_relu还是sigmoid\n",
    "        if self.ablation_flags.get(\"use_leaky_relu\", False):\n",
    "            alpha = F.leaky_relu(alpha, negative_slope=self.negative_slope)\n",
    "        else:\n",
    "            alpha = torch.sigmoid(alpha)\n",
    "\n",
    "        from torch_geometric.utils import softmax\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        self._alpha = alpha\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "        return x_j * alpha.unsqueeze(-1)\n",
    "\n",
    "\n",
    "########################################\n",
    "#  3A. 定义自定义 STAGATE 模型 (使用 STAGATEConv)\n",
    "########################################\n",
    "\n",
    "class STAGATE(torch.nn.Module):\n",
    "    def __init__(self, hidden_dims, ablation_flags=None):\n",
    "        super().__init__()\n",
    "        if ablation_flags is None:\n",
    "            ablation_flags = {}\n",
    "\n",
    "        [in_dim, num_hidden, out_dim] = hidden_dims\n",
    "        self.ablation_flags = ablation_flags\n",
    "\n",
    "        self.conv1 = STAGATEConv(in_dim, num_hidden,\n",
    "                                 ablation_flags=ablation_flags,\n",
    "                                 heads=1, concat=False,\n",
    "                                 dropout=0, add_self_loops=False, bias=False)\n",
    "        self.conv2 = STAGATEConv(num_hidden, out_dim,\n",
    "                                 ablation_flags=ablation_flags,\n",
    "                                 heads=1, concat=False,\n",
    "                                 dropout=0, add_self_loops=False, bias=False)\n",
    "        self.conv3 = STAGATEConv(out_dim, num_hidden,\n",
    "                                 ablation_flags=ablation_flags,\n",
    "                                 heads=1, concat=False,\n",
    "                                 dropout=0, add_self_loops=False, bias=False)\n",
    "        self.conv4 = STAGATEConv(num_hidden, in_dim,\n",
    "                                 ablation_flags=ablation_flags,\n",
    "                                 heads=1, concat=False,\n",
    "                                 dropout=0, add_self_loops=False, bias=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # 第一层\n",
    "        h1 = F.elu(self.conv1(x, edge_index,\n",
    "                              attention=not self.ablation_flags.get(\"remove_attention\", False)))\n",
    "        # 第二层 (不带注意力)\n",
    "        h2 = self.conv2(h1, edge_index, attention=False)\n",
    "\n",
    "        # 如果不移除权重转置共享，则执行\n",
    "        if not self.ablation_flags.get(\"remove_weight_transpose\", False):\n",
    "            # 当 conv2.lin_src 是 nn.Linear 时，需要对 weight 做 transpose\n",
    "            if isinstance(self.conv2.lin_src, torch.nn.Linear):\n",
    "                self.conv3.lin_src.weight.data = self.conv2.lin_src.weight.data.transpose(0, 1).clone()\n",
    "                self.conv3.lin_dst.weight.data = self.conv2.lin_dst.weight.data.transpose(0, 1).clone()\n",
    "\n",
    "                self.conv4.lin_src.weight.data = self.conv1.lin_src.weight.data.transpose(0, 1).clone()\n",
    "                self.conv4.lin_dst.weight.data = self.conv1.lin_dst.weight.data.transpose(0, 1).clone()\n",
    "            else:\n",
    "                self.conv3.lin_src.data = self.conv2.lin_src.transpose(0, 1)\n",
    "                self.conv3.lin_dst.data = self.conv2.lin_dst.transpose(0, 1)\n",
    "                self.conv4.lin_src.data = self.conv1.lin_src.transpose(0, 1)\n",
    "                self.conv4.lin_dst.data = self.conv1.lin_dst.transpose(0, 1)\n",
    "\n",
    "        # tied_attention\n",
    "        tied_attention = None\n",
    "        if not self.ablation_flags.get(\"remove_tied_attention\", False):\n",
    "            tied_attention = self.conv1.attentions\n",
    "\n",
    "        # 第三层\n",
    "        h3 = F.elu(self.conv3(h2, edge_index,\n",
    "                              attention=not self.ablation_flags.get(\"remove_attention\", False),\n",
    "                              tied_attention=tied_attention))\n",
    "        # 第四层\n",
    "        h4 = self.conv4(h3, edge_index, attention=False)\n",
    "\n",
    "        return h2, h4\n",
    "\n",
    "\n",
    "########################################\n",
    "#  3B. 定义基于 PyG GATConv 的 STAGATE 模型\n",
    "########################################\n",
    "\n",
    "class STAGATE_PyGGAT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    使用 PyG 原生 GATConv 来实现 4 层 Encoder-Decoder，并保留“权重转置共享”思路。\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dims, ablation_flags=None):\n",
    "        super().__init__()\n",
    "        if ablation_flags is None:\n",
    "            ablation_flags = {}\n",
    "\n",
    "        [in_dim, num_hidden, out_dim] = hidden_dims\n",
    "        self.ablation_flags = ablation_flags\n",
    "\n",
    "        # heads=1, concat=False, add_self_loops=False 等，与自定义保持一致\n",
    "        self.conv1 = GATConv(in_dim, num_hidden, heads=1, concat=False,\n",
    "                             dropout=0, add_self_loops=False, bias=False)\n",
    "        self.conv2 = GATConv(num_hidden, out_dim, heads=1, concat=False,\n",
    "                             dropout=0, add_self_loops=False, bias=False)\n",
    "        self.conv3 = GATConv(out_dim, num_hidden, heads=1, concat=False,\n",
    "                             dropout=0, add_self_loops=False, bias=False)\n",
    "        self.conv4 = GATConv(num_hidden, in_dim, heads=1, concat=False,\n",
    "                             dropout=0, add_self_loops=False, bias=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Encoder\n",
    "        h1 = F.elu(self.conv1(x, edge_index))\n",
    "        h2 = self.conv2(h1, edge_index)\n",
    "\n",
    "        # 如果不移除权重转置共享，则执行\n",
    "        # GATConv 中只有 self.lin (是 PyG 的 Linear)，\n",
    "        # 其权重可通过 self.conv2.lin.weight 访问，形状 (out_dim, num_hidden) 。\n",
    "        if not self.ablation_flags.get(\"remove_weight_transpose\", False):\n",
    "            # conv2 -> conv3\n",
    "            self.conv3.lin.weight.data = self.conv2.lin.weight.data.transpose(0, 1).clone()\n",
    "            # conv1 -> conv4\n",
    "            self.conv4.lin.weight.data = self.conv1.lin.weight.data.transpose(0, 1).clone()\n",
    "\n",
    "        # Decoder\n",
    "        h3 = F.elu(self.conv3(h2, edge_index))\n",
    "        h4 = self.conv4(h3, edge_index)\n",
    "\n",
    "        return h2, h4\n",
    "\n",
    "\n",
    "########################################\n",
    "#  4. 训练与评估 (AutoEncoder)\n",
    "########################################\n",
    "\n",
    "def train_and_evaluate_ae(\n",
    "    ablation_name,\n",
    "    ablation_flags,\n",
    "    graph_data,\n",
    "    adata,\n",
    "    num_epochs=200,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    save_dir=\"./ablation_test\"\n",
    "):\n",
    "    \"\"\"\n",
    "    训练STAGATE自编码器，并将中间隐层写回adata.obsm['X_STAGATE']；\n",
    "    然后使用scanpy进行聚类、可视化。\n",
    "    如果 ablation_flags[\"use_pyg_gatconv\"] 为 True，使用 PyG GATConv，否则用自定义 STAGATEConv。\n",
    "    \"\"\"\n",
    "    writer_dir = os.path.join(save_dir, ablation_name)\n",
    "    os.makedirs(writer_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir=writer_dir)\n",
    "\n",
    "    # 准备数据\n",
    "    x = graph_data.x.to(device)\n",
    "    edge_index = graph_data.edge_index.to(device)\n",
    "\n",
    "    in_dim = x.shape[1]\n",
    "    hidden_dims = [in_dim, 64, 32]  # 可按需调整\n",
    "\n",
    "    # 判断是否用 PyG GATConv\n",
    "    if ablation_flags.get(\"use_pyg_gatconv\", False):\n",
    "        model = STAGATE_PyGGAT(hidden_dims, ablation_flags=ablation_flags).to(device)\n",
    "    else:\n",
    "        model = STAGATE(hidden_dims, ablation_flags=ablation_flags).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向：得到中间表示 h2 与重构输出 h4\n",
    "        h2, h4 = model(x, edge_index)\n",
    "        # 重构损失\n",
    "        loss = F.mse_loss(h4, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        writer.add_scalar(\"Loss/train\", loss.item(), epoch)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    # 训练结束后，获取最终表示\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        h2, h4 = model(x, edge_index)\n",
    "    latent_rep = h2.detach().cpu().numpy()\n",
    "\n",
    "    # 写回 adata.obsm\n",
    "    adata.obsm['X_STAGATE'] = latent_rep\n",
    "\n",
    "    # scanpy 聚类 & 可视化\n",
    "    sc.pp.neighbors(adata, use_rep=\"X_STAGATE\", n_neighbors=30)\n",
    "    sc.tl.leiden(adata, key_added=\"leiden_STAGATE\", resolution=0.1)\n",
    "\n",
    "    # 保存聚类图\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sc.pl.spatial(\n",
    "        adata,\n",
    "        color=\"leiden_STAGATE\",\n",
    "        spot_size=50,\n",
    "        ncols=1,\n",
    "        frameon=False,\n",
    "        show=False,\n",
    "        title=f\"{ablation_name} STAGATE Clustering\"\n",
    "    )\n",
    "    pdf_path = os.path.join(save_dir, f\"{ablation_name}_clustering.pdf\")\n",
    "    plt.savefig(pdf_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # 保存训练曲线图\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(range(num_epochs), train_losses, label='Train Reconstruction Loss')\n",
    "    plt.title(f\"{ablation_name} - AE Training Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    pdf_loss_path = os.path.join(save_dir, f\"{ablation_name}_loss.pdf\")\n",
    "    plt.savefig(pdf_loss_path)\n",
    "    plt.show()\n",
    "\n",
    "    # 返回结果\n",
    "    return {\n",
    "        \"ablation_name\": ablation_name,\n",
    "        \"final_loss\": train_losses[-1]\n",
    "    }\n",
    "\n",
    "\n",
    "########################################\n",
    "#  5. 实验配置：单一消融+原始+PyG-GATConv\n",
    "########################################\n",
    "\n",
    "# 需要您自己准备以下对象:\n",
    "# graph_data = ...\n",
    "# adata      = ...\n",
    "\n",
    "# 示例：假设您有:\n",
    "# graph_data = your_graph_dict['8months-disease-replicate_1']\n",
    "# adata      = adatas['8months-disease-replicate_1']\n",
    "\n",
    "# 我们的五项可选消融:\n",
    "#   1) remove_attention\n",
    "#   2) remove_tied_attention\n",
    "#   3) use_leaky_relu\n",
    "#   4) remove_weight_transpose\n",
    "#   5) use_standard_linear\n",
    "#\n",
    "# 这里再添加一个 \"use_pyg_gatconv\" 以区分我们想跑的PyG版本\n",
    "\n",
    "experiments = [\n",
    "    {\n",
    "        \"name\": \"Original\",\n",
    "        \"flags\": {\n",
    "            \"remove_attention\": False,\n",
    "            \"remove_tied_attention\": False,\n",
    "            \"use_leaky_relu\": False,\n",
    "            \"remove_weight_transpose\": False,\n",
    "            \"use_standard_linear\": False,\n",
    "            \"use_pyg_gatconv\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ablation_remove_attention\",\n",
    "        \"flags\": {\n",
    "            \"remove_attention\": True,\n",
    "            \"remove_tied_attention\": False,\n",
    "            \"use_leaky_relu\": False,\n",
    "            \"remove_weight_transpose\": False,\n",
    "            \"use_standard_linear\": False,\n",
    "            \"use_pyg_gatconv\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ablation_remove_tied_attention\",\n",
    "        \"flags\": {\n",
    "            \"remove_attention\": False,\n",
    "            \"remove_tied_attention\": True,\n",
    "            \"use_leaky_relu\": False,\n",
    "            \"remove_weight_transpose\": False,\n",
    "            \"use_standard_linear\": False,\n",
    "            \"use_pyg_gatconv\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ablation_use_leaky_relu\",\n",
    "        \"flags\": {\n",
    "            \"remove_attention\": False,\n",
    "            \"remove_tied_attention\": False,\n",
    "            \"use_leaky_relu\": True,\n",
    "            \"remove_weight_transpose\": False,\n",
    "            \"use_standard_linear\": False,\n",
    "            \"use_pyg_gatconv\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ablation_remove_weight_transpose\",\n",
    "        \"flags\": {\n",
    "            \"remove_attention\": False,\n",
    "            \"remove_tied_attention\": False,\n",
    "            \"use_leaky_relu\": False,\n",
    "            \"remove_weight_transpose\": True,\n",
    "            \"use_standard_linear\": False,\n",
    "            \"use_pyg_gatconv\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ablation_use_standard_linear\",\n",
    "        \"flags\": {\n",
    "            \"remove_attention\": False,\n",
    "            \"remove_tied_attention\": False,\n",
    "            \"use_leaky_relu\": False,\n",
    "            \"remove_weight_transpose\": False,\n",
    "            \"use_standard_linear\": True,\n",
    "            \"use_pyg_gatconv\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ablation_use_pyg_gatconv\",\n",
    "        \"flags\": {\n",
    "            \"remove_attention\": False,\n",
    "            \"remove_tied_attention\": False,\n",
    "            \"use_leaky_relu\": False,\n",
    "            \"remove_weight_transpose\": False,\n",
    "            \"use_standard_linear\": False,\n",
    "            \"use_pyg_gatconv\": True  # <--- 新增 PyG GATConv 实验\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "results = []\n",
    "for exp in experiments:\n",
    "    print(f\"========== Running {exp['name']} ==========\")\n",
    "    res = train_and_evaluate_ae(\n",
    "        ablation_name=exp[\"name\"],\n",
    "        ablation_flags=exp[\"flags\"],\n",
    "        graph_data=graph_data,\n",
    "        adata=adata,\n",
    "        num_epochs=200,     # 可自行调整\n",
    "        lr=1e-3,            # 可自行调整\n",
    "        weight_decay=1e-5,  # 可自行调整\n",
    "        save_dir=\"./ablation_test\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "# 最终结果统计\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\n========= 单一消融 + 原始 + PyG GATConv 的最终结果对比 =========\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs['8months-disease-replicate_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "sc.pl.spatial(adata, color='leiden_STAGATE', spot_size=20, ncols=1, frameon=False, show=False, ax=ax)\n",
    "ax.imshow(imgs['8months-disease-replicate_1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (STAGATE)",
   "language": "python",
   "name": "stagate"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
