{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import skimage.io as io\n",
    "import random\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/public/home/jijh/diffusion_project/ADiffusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.preprocessing.data_process\n",
    "importlib.reload(src.preprocessing.data_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.data_process import extract_patches, create_graph_data_dict, construct_affinity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    \"\"\"Initialize random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# Set random seed for reproducibility\n",
    "random_seed = 0\n",
    "seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "file_dir = \"/public/home/jijh/st_project/cellbin_analysis/spatial_variation/wx_data/\"  # Directory containing the data files\n",
    "files = os.listdir(file_dir)  # List all files in the directory\n",
    "files = [i for i in files if i.endswith(\".h5ad\") and \"month\" in i]  # Filter files to include only those ending with \".h5ad\" and containing \"month\"\n",
    "file_paths = [os.path.join(file_dir, i) for i in files]  # Create full file paths for the filtered files\n",
    "adatas = {}  # Initialize an empty dictionary to store AnnData objects\n",
    "\n",
    "# Read each file and store the AnnData object in the dictionary\n",
    "for i in range(len(file_paths)):\n",
    "    adatas[files[i].split(\".\")[0]] = sc.read(file_paths[i])\n",
    "\n",
    "# Preprocess each AnnData object\n",
    "for key in tqdm(adatas.keys(), desc=\"Preprocessing datasets\"):\n",
    "    sc.pp.normalize_total(adatas[key], target_sum=1e4)  # Normalize counts per cell\n",
    "    sc.pp.log1p(adatas[key])  # Logarithmize the data\n",
    "    adatas[key].layers[\"raw\"] = adatas[key].X.copy()  # Store the raw data in the \"raw\" layer\n",
    "    # sc.pp.scale(adatas[key], max_value=10)  # Scale the data to have a maximum value of 10\n",
    "    # sc.tl.pca(adatas[key], svd_solver=\"arpack\")  # Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract spatial coordinates for each cell\n",
    "cell_coords = {}\n",
    "for key in adatas.keys():\n",
    "    cell_coords[key] = adatas[key].obsm[\"spatial\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = {}\n",
    "for key in cell_coords.keys():\n",
    "    neighbors[key] = construct_affinity_matrix(cell_coords[key], mode='radius', cutoff=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the plaque dataset\n",
    "img_dir = \"/public/home/jijh/st_project/cellbin_analysis/spatial_variation/wx_data/protein_seg_result/\"\n",
    "img_files = os.listdir(img_dir)\n",
    "img_files = [i for i in img_files if i.endswith(\".tiff\") and \"plaque\" in i]\n",
    "# Read the images\n",
    "\n",
    "imgs = {}\n",
    "for i in range(len(img_files)):\n",
    "    imgs[img_files[i].split(\".\")[0]] = io.imread(os.path.join(img_dir, img_files[i]))\n",
    "imgs.keys()\n",
    "# Rename the imgs to match the adata keys\n",
    "for key in list(imgs.keys()):\n",
    "    parts = key.split(\"_\")\n",
    "    if len(parts) > 1:\n",
    "        new_key = parts[1] + \"_\" + parts[2]\n",
    "        imgs[new_key] = imgs.pop(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches from the images\n",
    "patches = {}\n",
    "for key in imgs.keys():\n",
    "    patches[key] = extract_patches(imgs[key], cell_coords[key], patch_size=128)\n",
    "\n",
    "# Convert the patches to binary and calculate the area of positive pixels for each patch\n",
    "binary_patches = {}\n",
    "for key in patches.keys():\n",
    "    binary_patches[key] = [patch > 0 for patch in patches[key]]\n",
    "# Calculate the area of positive pixels for each patch\n",
    "areas = {}\n",
    "for key in binary_patches.keys():\n",
    "    areas[key] = [np.sum(patch) for patch in binary_patches[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 5 patches with non-zero area for each image and plot them\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the number of patches to plot\n",
    "n_patches = 5\n",
    "\n",
    "# Plot the patches\n",
    "fig, axes = plt.subplots(nrows=len(areas), ncols=n_patches, figsize=(15, 15))\n",
    "axes = np.atleast_2d(axes)  # Ensure axes is 2D for consistent indexing\n",
    "\n",
    "for i, key in enumerate(areas.keys()):\n",
    "    non_zero_indices = np.where(np.array(areas[key]) > 0)[0]\n",
    "    chosen_indices = random.sample(list(non_zero_indices), n_patches)\n",
    "    for j, idx in enumerate(chosen_indices):\n",
    "        axes[i, j].imshow(patches[key][idx], cmap=\"gray\")\n",
    "        axes[i, j].set_title(f\"Area: {areas[key][idx]}\")\n",
    "        axes[i, j].axis(\"off\")\n",
    "    axes[i, 0].set_ylabel(key, rotation=0, size=\"large\", labelpad=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph dictionary\n",
    "graph_data_dict = create_graph_data_dict(adatas, areas, neighbors, cell_coords, embeddings=[\"X\"])\n",
    "\n",
    "\n",
    "# Efficiently convert patches to tensors in batch\n",
    "for key, graph in tqdm(graph_data_dict.items(), desc=\"Adding patches to graph data\"):\n",
    "    # Ensure patches[key] is a list of NumPy arrays\n",
    "    patches_tensor = torch.tensor(np.array(patches[key]), dtype=torch.float)  # Convert patches to a single tensor efficiently\n",
    "    graph.patches = patches_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the edge_attr\n",
    "for key, graph in tqdm(graph_data_dict.items(), desc=\"Normalizing edge_attr\"):\n",
    "    graph.edge_attr = graph.edge_attr / graph.edge_attr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the values distribution of the node features\n",
    "node_features = torch.cat([graph.x for graph in graph_data_dict.values()], dim=0)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(node_features.numpy().flatten(), bins=100)\n",
    "plt.xlabel(\"Node feature values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of node features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Autoregressive Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATv2Conv, LayerNorm\n",
    "from tqdm import tqdm\n",
    "\n",
    "class GATv2EncoderLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, heads=4, edge_dim=None, dropout=0.1):\n",
    "        super(GATv2EncoderLayer, self).__init__()\n",
    "        self.gatv2 = GATv2Conv(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            heads=heads,\n",
    "            edge_dim=edge_dim,\n",
    "            concat=True,\n",
    "            dropout=dropout,\n",
    "            add_self_loops=True,\n",
    "            bias=True,\n",
    "            residual=True\n",
    "        )\n",
    "\n",
    "        # Learnable linear transformation layer\n",
    "        self.heads_transform = nn.Linear(out_channels * heads, out_channels)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "        )\n",
    "\n",
    "        self.norm1 = LayerNorm(out_channels * heads)  # After GATv2Conv\n",
    "        self.norm2 = LayerNorm(out_channels)  # After MLP\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # GATv2 forward pass\n",
    "        out = self.gatv2(x, edge_index, edge_attr)\n",
    "        out = self.norm1(out)  # Layer normalization after GATv2\n",
    "        out = self.dropout(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        # Learnable linear transformation\n",
    "        out = self.heads_transform(out)\n",
    "\n",
    "        # MLP with residual connection\n",
    "        residual_mlp = out\n",
    "        out = self.mlp(out)\n",
    "        out = out + residual_mlp  # Add residual connection for MLP\n",
    "        out = self.norm2(out)  # Layer normalization after MLP\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class MaskedNodePredictorWithEncoder(nn.Module):\n",
    "    def __init__(self, in_features, hidden_channels, edge_dim=None, heads=4, num_encoders=2, dropout=0.1):\n",
    "        super(MaskedNodePredictorWithEncoder, self).__init__()\n",
    "        self.encoders = nn.ModuleList()\n",
    "\n",
    "        # Add encoder layers\n",
    "        for i in range(num_encoders):\n",
    "            self.encoders.append(\n",
    "                GATv2EncoderLayer(\n",
    "                    in_channels=in_features if i == 0 else hidden_channels,\n",
    "                    out_channels=hidden_channels,\n",
    "                    heads=heads,\n",
    "                    edge_dim=edge_dim,\n",
    "                    dropout=dropout,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Prediction MLP\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_channels, in_features),  # Predict original features\n",
    "        )\n",
    "\n",
    "    def forward(self, data, mask):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = x.clone()  # To avoid modifying the original features\n",
    "\n",
    "        # # Apply masking\n",
    "        # x[mask] = 0  # Mask features (can use a learnable token here)\n",
    "\n",
    "        # Pass through encoder layers\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x, edge_index, edge_attr)\n",
    "\n",
    "        # Extract embeddings of masked nodes\n",
    "        masked_embeddings = x[mask]\n",
    "\n",
    "        # Predict original features\n",
    "        predictions = self.predictor(masked_embeddings)\n",
    "\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义加权 MSE 损失\n",
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self, pos_weight=10.0):\n",
    "        super(WeightedMSELoss, self).__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, prediction, target):\n",
    "        weight = (target != 0).float() * self.pos_weight + (target == 0).float()\n",
    "        loss = weight * (prediction - target) ** 2\n",
    "        return loss.mean()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATv2Conv, LayerNorm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Objective: Mimic BERT-style training (Masked Node Prediction)\n",
    "\n",
    "# Dataset preparation\n",
    "# Replace synthetic data with your dataset\n",
    "data = graph_data_dict['13months-disease-replicate_1'].clone().to(device)\n",
    "\n",
    "# Extract data dimensions\n",
    "num_nodes = data.x.size(0)\n",
    "in_features = data.x.size(1)\n",
    "hidden_channels = 64\n",
    "edge_dim = data.edge_attr.size(1) if data.edge_attr is not None else None\n",
    "heads = 4\n",
    "\n",
    "# Initialize model\n",
    "masked_pre_model = MaskedNodePredictorWithEncoder(\n",
    "    in_features=in_features,\n",
    "    hidden_channels=hidden_channels,\n",
    "    edge_dim=edge_dim,\n",
    "    heads=heads,\n",
    "    num_encoders=4,\n",
    "    dropout=0.2,\n",
    ").to(device)\n",
    "\n",
    "# Learning rate schedule parameters\n",
    "warmup_epochs = 200\n",
    "initial_lr = 1e-4\n",
    "warmup_lr = 1e-6\n",
    "epochs = 500\n",
    "eta_min = 1e-7\n",
    "\n",
    "# Initialize optimizer with warmup_lr\n",
    "optimizer = torch.optim.Adam(masked_pre_model.parameters(), lr=warmup_lr)\n",
    "\n",
    "# Create cosine scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=epochs - warmup_epochs, eta_min=eta_min)\n",
    "\n",
    "# Training loop with BERT-style masking\n",
    "loss_history = []\n",
    "lr_history = []\n",
    "smoothing_factor = 0.9\n",
    "smoothed_loss = None\n",
    "# 使用加权 MSE 损失\n",
    "criterion = WeightedMSELoss(pos_weight=10.0)\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\", leave=True):\n",
    "    masked_pre_model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Warmup learning rate\n",
    "    if epoch < warmup_epochs:\n",
    "        lr = warmup_lr + (initial_lr - warmup_lr) * epoch / warmup_epochs\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    else:\n",
    "        scheduler.step()\n",
    "\n",
    "    # Record current learning rate\n",
    "    lr_history.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    # Randomly select 15% of the nodes to mask\n",
    "    mask = torch.rand(num_nodes, device=device) < 0.15\n",
    "    target = data.x[mask]\n",
    "\n",
    "    # Apply BERT-style masking strategy\n",
    "    modified_data_x = data.x.clone()\n",
    "    for idx in torch.where(mask)[0]:\n",
    "        rand = random.random()\n",
    "        if rand < 0.8:  # 80% of the time, replace with [MASK] token (0)\n",
    "            modified_data_x[idx] = 0\n",
    "        elif rand < 0.9:  # 10% of the time, replace with a random value\n",
    "            modified_data_x[idx] = torch.randn_like(data.x[idx])\n",
    "        # 10% of the time, leave it unchanged\n",
    "\n",
    "    # Update the data object\n",
    "    data.x = modified_data_x\n",
    "\n",
    "    # Forward pass\n",
    "    predictions = masked_pre_model(data, mask)\n",
    "\n",
    "    # Compute weighted loss only for masked nodes\n",
    "    loss = criterion(predictions, target)\n",
    "\n",
    "    # Smooth loss using exponential moving average\n",
    "    if smoothed_loss is None:\n",
    "        smoothed_loss = loss.item()\n",
    "    else:\n",
    "        smoothed_loss = smoothing_factor * smoothed_loss + (1 - smoothing_factor) * loss.item()\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Log smoothed loss\n",
    "    loss_history.append(smoothed_loss)\n",
    "\n",
    "    # Update progress bar with loss info\n",
    "    if epoch % 50 == 0:\n",
    "        tqdm.write(f\"Epoch {epoch}/{epochs}, Loss: {smoothed_loss:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning rate schedule\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(lr_history, label='Learning Rate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the loss history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_history, label='Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss History')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the encoder part with parameters of the masked_pre_model as a new model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EncoderOnly(nn.Module):\n",
    "    def __init__(self, encoders):\n",
    "        \"\"\"\n",
    "        Initializes the EncoderOnly model.\n",
    "\n",
    "        Args:\n",
    "            encoders (nn.ModuleList): A list of encoder layers from the trained model.\n",
    "        \"\"\"\n",
    "        super(EncoderOnly, self).__init__()\n",
    "        self.encoders = encoders  # This should be a nn.ModuleList\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        Forward pass through the encoder layers.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Node feature matrix.\n",
    "            edge_index (Tensor): Graph connectivity.\n",
    "            edge_attr (Tensor): Edge feature matrix.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Encoded node features.\n",
    "        \"\"\"\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x, edge_index, edge_attr)\n",
    "        return x\n",
    "\n",
    "# Assuming masked_pre_model is already trained and on the correct device\n",
    "encoder_model = EncoderOnly(encoders=masked_pre_model.encoders).to(device)\n",
    "\n",
    "# It's a good practice to set the model to evaluation mode if you're using it for inference\n",
    "encoder_model.eval()\n",
    "\n",
    "# (Optional) Verify that the parameters are correctly copied\n",
    "for param_encoder, param_original in zip(encoder_model.parameters(), masked_pre_model.parameters()):\n",
    "    assert torch.equal(param_encoder, param_original), \"Parameters do not match!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.validate_prediction import collect_predictions, visualize_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect predictions and targets\n",
    "all_predictions, all_targets = collect_predictions(\n",
    "    model=masked_pre_model,\n",
    "    data=graph_data_dict['13months-disease-replicate_1'].clone().to(device),\n",
    "    num_evaluations=10,\n",
    "    mask_percentage=0.15,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform all visualizations\n",
    "visualize_all(all_predictions, all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform all visualizations\n",
    "visualize_all(all_predictions, all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph_data_dict['13months-disease-replicate_1'].clone().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x[0, :]\n",
    "\n",
    "# Visualize the values distribution one node feature\n",
    "node_feature_idx = 0\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(data.x[:, node_feature_idx].cpu().numpy(), bins=100)\n",
    "plt.xlabel(f\"Node feature {node_feature_idx} values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(f\"Distribution of node feature {node_feature_idx}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_embeddings = encoder_model(data.x, data.edge_index, data.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adata = adatas['13months-disease-replicate_1'].copy()\n",
    "test_adata.obsm[\"X_encoded\"] = encoded_embeddings.detach().cpu().numpy()\n",
    "\n",
    "# Step 1: Compute neighbors and UMAP for the 'X_encoded' representation\n",
    "sc.pp.neighbors(test_adata, use_rep=\"X_encoded\", n_neighbors=10)\n",
    "sc.tl.umap(test_adata)\n",
    "test_adata.obsm[\"X_umap_encoded\"] = test_adata.obsm[\"X_umap\"].copy()\n",
    "sc.tl.leiden(test_adata, resolution=1.0, key_added=\"leiden_X_encoded\")\n",
    "\n",
    "# Step 2: Compute neighbors and UMAP for the 'X' representation\n",
    "sc.pp.neighbors(test_adata, use_rep=\"X\", n_neighbors=10)\n",
    "sc.tl.umap(test_adata)\n",
    "test_adata.obsm[\"X_umap_X\"] = test_adata.obsm[\"X_umap\"].copy()\n",
    "sc.tl.leiden(test_adata, resolution=1.0, key_added=\"leiden_X\")\n",
    "\n",
    "# Step 3: Compute PCA, neighbors, and UMAP for the 'X_pca' representation\n",
    "sc.pp.pca(test_adata, n_comps=50)\n",
    "sc.pp.neighbors(test_adata, use_rep=\"X_pca\", n_neighbors=10)\n",
    "sc.tl.umap(test_adata)\n",
    "test_adata.obsm[\"X_umap_pca\"] = test_adata.obsm[\"X_umap\"].copy()\n",
    "sc.tl.leiden(test_adata, resolution=1.0, key_added=\"leiden_X_pca\")\n",
    "\n",
    "# Comput PCA for the 'X_encoded' representation, then use it for UMAP, neighbors, and leiden clustering\n",
    "# Step 1: Extract the 'X_encoded' representation\n",
    "X_encoded = test_adata.obsm[\"X_encoded\"]\n",
    "# Step 2: Compute PCA on the 'X_encoded' representation\n",
    "# Note: sc.pp.pca works directly on the AnnData object; for custom data, use sc.tl.pca\n",
    "pca_result = sc.tl.pca(X_encoded, n_comps=50, svd_solver='arpack', return_info=True)\n",
    "# Step 3: Store the PCA results in 'obsm'\n",
    "test_adata.obsm[\"X_encoded_pca\"] = pca_result[0]  # PCA coordinates\n",
    "sc.pp.neighbors(test_adata, use_rep=\"X_encoded_pca\", n_neighbors=10)\n",
    "sc.tl.umap(test_adata)\n",
    "test_adata.obsm[\"X_umap_encoded_pca\"] = test_adata.obsm[\"X_umap\"].copy()\n",
    "sc.tl.leiden(test_adata, resolution=1.0, key_added=\"leiden_X_encoded_pca\")\n",
    "\n",
    "# Plot UMAP for 'X_encoded' representation\n",
    "sc.pl.embedding(test_adata, basis=\"X_umap_encoded\", color=[\"top_level_cell_type_x\"], ncols=1, frameon=False, wspace=0.5)\n",
    "# Plot UMAP for 'X' representation\n",
    "sc.pl.embedding(test_adata, basis=\"X_umap_X\", color=[\"top_level_cell_type_x\"], ncols=1, frameon=False, wspace=0.5)\n",
    "# Plot UMAP for 'X' representation\n",
    "sc.pl.embedding(test_adata, basis=\"X_umap_pca\", color=[\"top_level_cell_type_x\"], ncols=1, frameon=False, wspace=0.5)\n",
    "# Plot UMAP for 'X_encoded_pca' representation\n",
    "sc.pl.embedding(test_adata, basis=\"X_umap_encoded_pca\", color=[\"top_level_cell_type_x\"], ncols=1, frameon=False, wspace=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(test_adata, resolution=0.1, key_added=\"leiden_X_encoded_pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Visualize clustering results on the 'spatial' basis\n",
    "# Assuming 'spatial' coordinates are stored in `test_adata.obsm['spatial']`\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "\n",
    "# Plot for 'X_encoded'\n",
    "sc.pl.embedding(\n",
    "    test_adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden_X_encoded\",\n",
    "    frameon=False,\n",
    "    ax=axes[0],\n",
    "    show=False,\n",
    "    title=\"Clusters: X_encoded\"\n",
    ")\n",
    "\n",
    "# Plot for 'X'\n",
    "sc.pl.embedding(\n",
    "    test_adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden_X\",\n",
    "    frameon=False,\n",
    "    ax=axes[1],\n",
    "    show=False,\n",
    "    title=\"Clusters: X\"\n",
    ")\n",
    "\n",
    "# Plot for 'X_pca'\n",
    "sc.pl.embedding(\n",
    "    test_adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden_X_pca\",\n",
    "    frameon=False,\n",
    "    ax=axes[2],\n",
    "    show=False,\n",
    "    title=\"Clusters: X_pca\"\n",
    ")\n",
    "\n",
    "# Plot for 'X_encoded_pca'\n",
    "sc.pl.embedding(\n",
    "    test_adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden_X_encoded_pca\",\n",
    "    frameon=False,\n",
    "    ax=axes[3],\n",
    "    show=False,\n",
    "    title=\"Clusters: X_encoded_pca\"\n",
    ")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT 优化后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATv2Conv, LayerNorm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# 定义模型\n",
    "class GATv2EncoderLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, heads=4, edge_dim=None, dropout=0.1):\n",
    "        super(GATv2EncoderLayer, self).__init__()\n",
    "        self.gatv2 = GATv2Conv(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            heads=heads,\n",
    "            edge_dim=edge_dim,\n",
    "            concat=True,\n",
    "            dropout=dropout,\n",
    "            add_self_loops=True,\n",
    "            bias=True,\n",
    "            residual=True\n",
    "        )\n",
    "\n",
    "        # Learnable linear transformation layer\n",
    "        self.heads_transform = nn.Linear(out_channels * heads, out_channels)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "        )\n",
    "\n",
    "        self.norm1 = LayerNorm(out_channels * heads)  # After GATv2Conv\n",
    "        self.norm2 = LayerNorm(out_channels)  # After MLP\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # GATv2 forward pass\n",
    "        out = self.gatv2(x, edge_index, edge_attr)\n",
    "        out = self.norm1(out)  # Layer normalization after GATv2\n",
    "        out = self.dropout(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        # Learnable linear transformation\n",
    "        out = self.heads_transform(out)\n",
    "\n",
    "        # MLP with residual connection\n",
    "        residual_mlp = out\n",
    "        out = self.mlp(out)\n",
    "        out = out + residual_mlp  # Add residual connection for MLP\n",
    "        out = self.norm2(out)  # Layer normalization after MLP\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class MaskedNodePredictorWithEncoder(nn.Module):\n",
    "    def __init__(self, in_features, hidden_channels, edge_dim=None, heads=4, num_encoders=2, dropout=0.1):\n",
    "        super(MaskedNodePredictorWithEncoder, self).__init__()\n",
    "        self.encoders = nn.ModuleList()\n",
    "\n",
    "        # Add encoder layers\n",
    "        for i in range(num_encoders):\n",
    "            self.encoders.append(\n",
    "                GATv2EncoderLayer(\n",
    "                    in_channels=in_features if i == 0 else hidden_channels,\n",
    "                    out_channels=hidden_channels,\n",
    "                    heads=heads,\n",
    "                    edge_dim=edge_dim,\n",
    "                    dropout=dropout,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Prediction MLP\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_channels, in_features),  # Predict original features\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Pass through encoder layers\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x, edge_index, edge_attr)\n",
    "\n",
    "        # Predict original features\n",
    "        predictions = self.predictor(x)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "# 定义损失函数\n",
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self, pos_weight=10.0):\n",
    "        super(WeightedMSELoss, self).__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, prediction, target):\n",
    "        # 计算每个特征是否为非零\n",
    "        weight = (target != 0).float() * self.pos_weight + (target == 0).float()\n",
    "        loss = weight * (prediction - target) ** 2\n",
    "        return loss.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, mse_weight=1.0, l1_weight=0.1):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.l1 = nn.L1Loss()\n",
    "        self.mse_weight = mse_weight\n",
    "        self.l1_weight = l1_weight\n",
    "\n",
    "    def forward(self, prediction, target):\n",
    "        return self.mse_weight * self.mse(prediction, target) + self.l1_weight * self.l1(prediction, target)\n",
    "\n",
    "# 初始化模型\n",
    "masked_pre_model = MaskedNodePredictorWithEncoder(\n",
    "    in_features=in_features,\n",
    "    hidden_channels=hidden_channels,\n",
    "    edge_dim=edge_dim,\n",
    "    heads=heads,\n",
    "    num_encoders=4,\n",
    "    dropout=0.2,\n",
    ").to(device)\n",
    "\n",
    "# 初始化损失函数\n",
    "criterion = CombinedLoss(mse_weight=1.0, l1_weight=0.1)\n",
    "\n",
    "# 优化器和学习率调度\n",
    "optimizer = torch.optim.Adam(masked_pre_model.parameters(), lr=1e-4, weight_decay=1e-5)  # 包含 L2 正则\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=300, eta_min=1e-7)  # 调整 T_max 以匹配 warmup 后的阶段\n",
    "\n",
    "# 训练循环\n",
    "loss_history = []\n",
    "lr_history = []\n",
    "smoothing_factor = 0.9\n",
    "smoothed_loss = None\n",
    "epochs = 100\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\", leave=True):\n",
    "    masked_pre_model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Warmup 学习率\n",
    "    if epoch < warmup_epochs:\n",
    "        lr = warmup_lr + (initial_lr - warmup_lr) * epoch / warmup_epochs\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    else:\n",
    "        scheduler.step()\n",
    "\n",
    "    # 记录当前学习率\n",
    "    lr_history.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    # 特征级别掩蔽\n",
    "    mask = torch.rand(data.x.size(), device=device) < 0.15  # 15% 的特征被掩蔽\n",
    "    target = data.x.clone()\n",
    "    target[~mask] = 0  # 只对被掩蔽的特征计算损失\n",
    "\n",
    "    # 应用掩蔽策略\n",
    "    modified_data_x = data.x.clone()\n",
    "    mask_indices = mask.nonzero(as_tuple=False)\n",
    "    for idx in mask_indices:\n",
    "        rand = random.random()\n",
    "        if rand < 0.8:  # 80% 的时候，用0替代\n",
    "            modified_data_x[idx[0], idx[1]] = 0\n",
    "        elif rand < 0.9:  # 10% 的时候，用随机值替代\n",
    "            modified_data_x[idx[0], idx[1]] = torch.randn_like(data.x[idx[0], idx[1]])\n",
    "        # 10% 的时候，保持原值不变\n",
    "\n",
    "    # 更新数据对象\n",
    "    data.x = modified_data_x\n",
    "\n",
    "    # 前向传播\n",
    "    predictions = masked_pre_model(data.x, data.edge_index, data.edge_attr)\n",
    "\n",
    "    # 计算损失，只对被掩蔽的特征\n",
    "    loss = criterion(predictions[mask], target[mask])\n",
    "\n",
    "    # 平滑损失\n",
    "    if smoothed_loss is None:\n",
    "        smoothed_loss = loss.item()\n",
    "    else:\n",
    "        smoothed_loss = smoothing_factor * smoothed_loss + (1 - smoothing_factor) * loss.item()\n",
    "\n",
    "    # 反向传播和优化\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 记录损失\n",
    "    loss_history.append(smoothed_loss)\n",
    "\n",
    "    # 每50个epoch打印一次损失和学习率\n",
    "    if epoch % 50 == 0:\n",
    "        tqdm.write(f\"Epoch {epoch}/{epochs}, Loss: {smoothed_loss:.6f}, LR: {optimizer.param_groups[0]['lr']:.8f}\")\n",
    "\n",
    "    # 恢复原始数据以防止累积掩蔽\n",
    "    data.x = target.clone()\n",
    "\n",
    "# 可选：保存训练历史\n",
    "torch.save({\n",
    "    'loss_history': loss_history,\n",
    "    'lr_history': lr_history,\n",
    "}, 'training_history.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming masked_pre_model is already trained and on the correct device\n",
    "encoder_model = EncoderOnly(encoders=masked_pre_model.encoders).to(device)\n",
    "\n",
    "# It's a good practice to set the model to evaluation mode if you're using it for inference\n",
    "encoder_model.eval()\n",
    "\n",
    "# (Optional) Verify that the parameters are correctly copied\n",
    "for param_encoder, param_original in zip(encoder_model.parameters(), masked_pre_model.parameters()):\n",
    "    assert torch.equal(param_encoder, param_original), \"Parameters do not match!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph_data_dict['13months-disease-replicate_1'].clone().to(device)\n",
    "encoded_embeddings = encoder_model(data.x, data.edge_index, data.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adata = adatas['13months-disease-replicate_1'].copy()\n",
    "test_adata.obsm[\"X_encoded\"] = encoded_embeddings.detach().cpu().numpy()\n",
    "\n",
    "# Step 1: Compute neighbors and UMAP for the 'X_encoded' representation\n",
    "sc.pp.neighbors(test_adata, use_rep=\"X_encoded\", n_neighbors=10)\n",
    "sc.tl.umap(test_adata)\n",
    "test_adata.obsm[\"X_umap_encoded\"] = test_adata.obsm[\"X_umap\"].copy()\n",
    "sc.tl.leiden(test_adata, resolution=1.0, key_added=\"leiden_X_encoded\")\n",
    "\n",
    "# Step 2: Compute neighbors and UMAP for the 'X' representation\n",
    "sc.pp.neighbors(test_adata, use_rep=\"X\", n_neighbors=10)\n",
    "sc.tl.umap(test_adata)\n",
    "test_adata.obsm[\"X_umap_X\"] = test_adata.obsm[\"X_umap\"].copy()\n",
    "sc.tl.leiden(test_adata, resolution=1.0, key_added=\"leiden_X\")\n",
    "\n",
    "# Step 3: Compute PCA, neighbors, and UMAP for the 'X_pca' representation\n",
    "sc.pp.pca(test_adata, n_comps=50)\n",
    "sc.pp.neighbors(test_adata, use_rep=\"X_pca\", n_neighbors=10)\n",
    "sc.tl.umap(test_adata)\n",
    "test_adata.obsm[\"X_umap_pca\"] = test_adata.obsm[\"X_umap\"].copy()\n",
    "sc.tl.leiden(test_adata, resolution=1.0, key_added=\"leiden_X_pca\")\n",
    "\n",
    "# Comput PCA for the 'X_encoded' representation, then use it for UMAP, neighbors, and leiden clustering\n",
    "# Step 1: Extract the 'X_encoded' representation\n",
    "X_encoded = test_adata.obsm[\"X_encoded\"]\n",
    "# Step 2: Compute PCA on the 'X_encoded' representation\n",
    "# Note: sc.pp.pca works directly on the AnnData object; for custom data, use sc.tl.pca\n",
    "pca_result = sc.tl.pca(X_encoded, n_comps=50, svd_solver='arpack', return_info=True)\n",
    "# Step 3: Store the PCA results in 'obsm'\n",
    "test_adata.obsm[\"X_encoded_pca\"] = pca_result[0]  # PCA coordinates\n",
    "sc.pp.neighbors(test_adata, use_rep=\"X_encoded_pca\", n_neighbors=10)\n",
    "sc.tl.umap(test_adata)\n",
    "test_adata.obsm[\"X_umap_encoded_pca\"] = test_adata.obsm[\"X_umap\"].copy()\n",
    "sc.tl.leiden(test_adata, resolution=1.0, key_added=\"leiden_X_encoded_pca\")\n",
    "\n",
    "# Plot UMAP for 'X_encoded' representation\n",
    "sc.pl.embedding(test_adata, basis=\"X_umap_encoded\", color=[\"top_level_cell_type_x\"], ncols=1, frameon=False, wspace=0.5)\n",
    "# Plot UMAP for 'X' representation\n",
    "sc.pl.embedding(test_adata, basis=\"X_umap_X\", color=[\"top_level_cell_type_x\"], ncols=1, frameon=False, wspace=0.5)\n",
    "# Plot UMAP for 'X' representation\n",
    "sc.pl.embedding(test_adata, basis=\"X_umap_pca\", color=[\"top_level_cell_type_x\"], ncols=1, frameon=False, wspace=0.5)\n",
    "# Plot UMAP for 'X_encoded_pca' representation\n",
    "sc.pl.embedding(test_adata, basis=\"X_umap_encoded_pca\", color=[\"top_level_cell_type_x\"], ncols=1, frameon=False, wspace=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Visualize clustering results on the 'spatial' basis\n",
    "# Assuming 'spatial' coordinates are stored in `test_adata.obsm['spatial']`\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "\n",
    "# Plot for 'X_encoded'\n",
    "sc.pl.embedding(\n",
    "    test_adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden_X_encoded\",\n",
    "    frameon=False,\n",
    "    ax=axes[0],\n",
    "    show=False,\n",
    "    title=\"Clusters: X_encoded\"\n",
    ")\n",
    "\n",
    "# Plot for 'X'\n",
    "sc.pl.embedding(\n",
    "    test_adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden_X\",\n",
    "    frameon=False,\n",
    "    ax=axes[1],\n",
    "    show=False,\n",
    "    title=\"Clusters: X\"\n",
    ")\n",
    "\n",
    "# Plot for 'X_pca'\n",
    "sc.pl.embedding(\n",
    "    test_adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden_X_pca\",\n",
    "    frameon=False,\n",
    "    ax=axes[2],\n",
    "    show=False,\n",
    "    title=\"Clusters: X_pca\"\n",
    ")\n",
    "\n",
    "# Plot for 'X_encoded_pca'\n",
    "sc.pl.embedding(\n",
    "    test_adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden_X_encoded_pca\",\n",
    "    frameon=False,\n",
    "    ax=axes[3],\n",
    "    show=False,\n",
    "    title=\"Clusters: X_encoded_pca\"\n",
    ")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect predictions and targets\n",
    "all_predictions, all_targets = collect_predictions(\n",
    "    model=masked_pre_model,\n",
    "    data=graph_data_dict['13months-disease-replicate_1'].clone().to(device),\n",
    "    num_evaluations=10,\n",
    "    mask_percentage=0.15,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "file_dir = \"/public/home/jijh/st_project/cellbin_analysis/spatial_variation/wx_data/\"  # Directory containing the data files\n",
    "files = os.listdir(file_dir)  # List all files in the directory\n",
    "files = [i for i in files if i.endswith(\".h5ad\") and \"month\" in i]  # Filter files to include only those ending with \".h5ad\" and containing \"month\"\n",
    "file_paths = [os.path.join(file_dir, i) for i in files]  # Create full file paths for the filtered files\n",
    "adatas = {}  # Initialize an empty dictionary to store AnnData objects\n",
    "\n",
    "# Read each file and store the AnnData object in the dictionary\n",
    "for i in range(len(file_paths)):\n",
    "    adatas[files[i].split(\".\")[0]] = sc.read(file_paths[i])\n",
    "\n",
    "# Preprocess each AnnData object\n",
    "for key in tqdm(adatas.keys(), desc=\"Preprocessing datasets\"):\n",
    "    sc.pp.normalize_total(adatas[key], target_sum=1e4)  # Normalize counts per cell\n",
    "    sc.pp.log1p(adatas[key])  # Logarithmize the data\n",
    "    adatas[key].layers[\"raw\"] = adatas[key].X.copy()  # Store the raw data in the \"raw\" layer\n",
    "    sc.pp.scale(adatas[key], max_value=10)  # Scale the data to have a maximum value of 10\n",
    "    sc.tl.pca(adatas[key], svd_solver=\"arpack\")  # Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract spatial coordinates for each cell\n",
    "cell_coords = {}\n",
    "for key in adatas.keys():\n",
    "    cell_coords[key] = adatas[key].obsm[\"spatial\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = {}\n",
    "for key in cell_coords.keys():\n",
    "    neighbors[key] = construct_affinity_matrix(cell_coords[key], mode='radius', cutoff=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the plaque dataset\n",
    "img_dir = \"/public/home/jijh/st_project/cellbin_analysis/spatial_variation/wx_data/protein_seg_result/\"\n",
    "img_files = os.listdir(img_dir)\n",
    "img_files = [i for i in img_files if i.endswith(\".tiff\") and \"plaque\" in i]\n",
    "# Read the images\n",
    "\n",
    "imgs = {}\n",
    "for i in range(len(img_files)):\n",
    "    imgs[img_files[i].split(\".\")[0]] = io.imread(os.path.join(img_dir, img_files[i]))\n",
    "imgs.keys()\n",
    "# Rename the imgs to match the adata keys\n",
    "for key in list(imgs.keys()):\n",
    "    parts = key.split(\"_\")\n",
    "    if len(parts) > 1:\n",
    "        new_key = parts[1] + \"_\" + parts[2]\n",
    "        imgs[new_key] = imgs.pop(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches from the images\n",
    "patches = {}\n",
    "for key in imgs.keys():\n",
    "    patches[key] = extract_patches(imgs[key], cell_coords[key], patch_size=128)\n",
    "\n",
    "# Convert the patches to binary and calculate the area of positive pixels for each patch\n",
    "binary_patches = {}\n",
    "for key in patches.keys():\n",
    "    binary_patches[key] = [patch > 0 for patch in patches[key]]\n",
    "# Calculate the area of positive pixels for each patch\n",
    "areas = {}\n",
    "for key in binary_patches.keys():\n",
    "    areas[key] = [np.sum(patch) for patch in binary_patches[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph dictionary\n",
    "graph_data_dict = create_graph_data_dict(adatas, areas, neighbors, cell_coords, embeddings=[\"X_pca\"])\n",
    "\n",
    "\n",
    "# Efficiently convert patches to tensors in batch\n",
    "for key, graph in tqdm(graph_data_dict.items(), desc=\"Adding patches to graph data\"):\n",
    "    # Ensure patches[key] is a list of NumPy arrays\n",
    "    patches_tensor = torch.tensor(np.array(patches[key]), dtype=torch.float)  # Convert patches to a single tensor efficiently\n",
    "    graph.patches = patches_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the edge_attr\n",
    "for key, graph in tqdm(graph_data_dict.items(), desc=\"Normalizing edge_attr\"):\n",
    "    graph.edge_attr = graph.edge_attr / graph.edge_attr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATv2Conv, LayerNorm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Objective: Mimic BERT-style training (Masked Node Prediction)\n",
    "\n",
    "# Dataset preparation\n",
    "# Replace synthetic data with your dataset\n",
    "data = graph_data_dict['13months-disease-replicate_1'].clone().to(device)\n",
    "\n",
    "# Extract data dimensions\n",
    "num_nodes = data.x.size(0)\n",
    "in_features = data.x.size(1)\n",
    "hidden_channels = 64\n",
    "edge_dim = data.edge_attr.size(1) if data.edge_attr is not None else None\n",
    "heads = 4\n",
    "\n",
    "# Initialize model\n",
    "masked_pre_model = MaskedNodePredictorWithEncoder(\n",
    "    in_features=in_features,\n",
    "    hidden_channels=hidden_channels,\n",
    "    edge_dim=edge_dim,\n",
    "    heads=heads,\n",
    "    num_encoders=4,\n",
    "    dropout=0.2,\n",
    ").to(device)\n",
    "\n",
    "# Learning rate schedule parameters\n",
    "warmup_epochs = 200\n",
    "initial_lr = 1e-4\n",
    "warmup_lr = 1e-6\n",
    "epochs = 500\n",
    "eta_min = 1e-7\n",
    "\n",
    "# Initialize optimizer with warmup_lr\n",
    "optimizer = torch.optim.Adam(masked_pre_model.parameters(), lr=warmup_lr)\n",
    "\n",
    "# Create cosine scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=epochs - warmup_epochs, eta_min=eta_min)\n",
    "\n",
    "# Training loop with BERT-style masking\n",
    "loss_history = []\n",
    "lr_history = []\n",
    "smoothing_factor = 0.9\n",
    "smoothed_loss = None\n",
    "# 使用加权 MSE 损失\n",
    "criterion = WeightedMSELoss(pos_weight=10.0)\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\", leave=True):\n",
    "    masked_pre_model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Warmup learning rate\n",
    "    if epoch < warmup_epochs:\n",
    "        lr = warmup_lr + (initial_lr - warmup_lr) * epoch / warmup_epochs\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    else:\n",
    "        scheduler.step()\n",
    "\n",
    "    # Record current learning rate\n",
    "    lr_history.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    # Randomly select 15% of the nodes to mask\n",
    "    mask = torch.rand(num_nodes, device=device) < 0.15\n",
    "    target = data.x[mask]\n",
    "\n",
    "    # Apply BERT-style masking strategy\n",
    "    modified_data_x = data.x.clone()\n",
    "    for idx in torch.where(mask)[0]:\n",
    "        rand = random.random()\n",
    "        if rand < 0.8:  # 80% of the time, replace with [MASK] token (0)\n",
    "            modified_data_x[idx] = 0\n",
    "        elif rand < 0.9:  # 10% of the time, replace with a random value\n",
    "            modified_data_x[idx] = torch.randn_like(data.x[idx])\n",
    "        # 10% of the time, leave it unchanged\n",
    "\n",
    "    # Update the data object\n",
    "    data.x = modified_data_x\n",
    "\n",
    "    # Forward pass\n",
    "    predictions = masked_pre_model(data, mask)\n",
    "\n",
    "    # Compute weighted loss only for masked nodes\n",
    "    loss = criterion(predictions, target)\n",
    "\n",
    "    # Smooth loss using exponential moving average\n",
    "    if smoothed_loss is None:\n",
    "        smoothed_loss = loss.item()\n",
    "    else:\n",
    "        smoothed_loss = smoothing_factor * smoothed_loss + (1 - smoothing_factor) * loss.item()\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Log smoothed loss\n",
    "    loss_history.append(smoothed_loss)\n",
    "\n",
    "    # Update progress bar with loss info\n",
    "    if epoch % 50 == 0:\n",
    "        tqdm.write(f\"Epoch {epoch}/{epochs}, Loss: {smoothed_loss:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect predictions and targets\n",
    "all_predictions, all_targets = collect_predictions(\n",
    "    model=masked_pre_model,\n",
    "    data=graph_data_dict['13months-disease-replicate_1'].clone().to(device),\n",
    "    num_evaluations=10,\n",
    "    mask_percentage=0.15,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(src.visualization.validate_prediction)\n",
    "\n",
    "from src.visualization.validate_prediction import visualize_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform all visualizations\n",
    "visualize_all(all_predictions, all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming masked_pre_model is already trained and on the correct device\n",
    "encoder_model = EncoderOnly(encoders=masked_pre_model.encoders).to(device)\n",
    "\n",
    "# It's a good practice to set the model to evaluation mode if you're using it for inference\n",
    "encoder_model.eval()\n",
    "\n",
    "# (Optional) Verify that the parameters are correctly copied\n",
    "for param_encoder, param_original in zip(encoder_model.parameters(), masked_pre_model.parameters()):\n",
    "    assert torch.equal(param_encoder, param_original), \"Parameters do not match!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph_data_dict['13months-disease-replicate_1'].clone().to(device)\n",
    "encoded_embeddings = encoder_model(data.x, data.edge_index, data.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adata = adatas['13months-disease-replicate_1'].copy()\n",
    "test_adata.obsm[\"X_encoded\"] = encoded_embeddings.detach().cpu().numpy()\n",
    "\n",
    "# Step 1: Compute neighbors and UMAP for the 'X_encoded' representation\n",
    "sc.pp.neighbors(test_adata, use_rep=\"X_encoded\", n_neighbors=10)\n",
    "sc.tl.umap(test_adata)\n",
    "test_adata.obsm[\"X_umap_encoded\"] = test_adata.obsm[\"X_umap\"].copy()\n",
    "sc.tl.leiden(test_adata, resolution=1.0, key_added=\"leiden_X_encoded\")\n",
    "\n",
    "# Step 2: Compute neighbors and UMAP for the 'X' representation\n",
    "sc.pp.neighbors(test_adata, use_rep=\"X\", n_neighbors=10)\n",
    "sc.tl.umap(test_adata)\n",
    "test_adata.obsm[\"X_umap_X\"] = test_adata.obsm[\"X_umap\"].copy()\n",
    "sc.tl.leiden(test_adata, resolution=1.0, key_added=\"leiden_X\")\n",
    "\n",
    "# Step 3: Compute PCA, neighbors, and UMAP for the 'X_pca' representation\n",
    "sc.pp.pca(test_adata, n_comps=50)\n",
    "sc.pp.neighbors(test_adata, use_rep=\"X_pca\", n_neighbors=10)\n",
    "sc.tl.umap(test_adata)\n",
    "test_adata.obsm[\"X_umap_pca\"] = test_adata.obsm[\"X_umap\"].copy()\n",
    "sc.tl.leiden(test_adata, resolution=1.0, key_added=\"leiden_X_pca\")\n",
    "\n",
    "# Comput PCA for the 'X_encoded' representation, then use it for UMAP, neighbors, and leiden clustering\n",
    "# Step 1: Extract the 'X_encoded' representation\n",
    "X_encoded = test_adata.obsm[\"X_encoded\"]\n",
    "# Step 2: Compute PCA on the 'X_encoded' representation\n",
    "# Note: sc.pp.pca works directly on the AnnData object; for custom data, use sc.tl.pca\n",
    "pca_result = sc.tl.pca(X_encoded, n_comps=50, svd_solver='arpack', return_info=True)\n",
    "# Step 3: Store the PCA results in 'obsm'\n",
    "test_adata.obsm[\"X_encoded_pca\"] = pca_result[0]  # PCA coordinates\n",
    "sc.pp.neighbors(test_adata, use_rep=\"X_encoded_pca\", n_neighbors=10)\n",
    "sc.tl.umap(test_adata)\n",
    "test_adata.obsm[\"X_umap_encoded_pca\"] = test_adata.obsm[\"X_umap\"].copy()\n",
    "sc.tl.leiden(test_adata, resolution=1.0, key_added=\"leiden_X_encoded_pca\")\n",
    "\n",
    "# Plot UMAP for 'X_encoded' representation\n",
    "sc.pl.embedding(test_adata, basis=\"X_umap_encoded\", color=[\"top_level_cell_type_x\"], ncols=1, frameon=False, wspace=0.5)\n",
    "# Plot UMAP for 'X' representation\n",
    "sc.pl.embedding(test_adata, basis=\"X_umap_X\", color=[\"top_level_cell_type_x\"], ncols=1, frameon=False, wspace=0.5)\n",
    "# Plot UMAP for 'X' representation\n",
    "sc.pl.embedding(test_adata, basis=\"X_umap_pca\", color=[\"top_level_cell_type_x\"], ncols=1, frameon=False, wspace=0.5)\n",
    "# Plot UMAP for 'X_encoded_pca' representation\n",
    "sc.pl.embedding(test_adata, basis=\"X_umap_encoded_pca\", color=[\"top_level_cell_type_x\"], ncols=1, frameon=False, wspace=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Visualize clustering results on the 'spatial' basis\n",
    "# Assuming 'spatial' coordinates are stored in `test_adata.obsm['spatial']`\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "\n",
    "# Plot for 'X_encoded'\n",
    "sc.pl.embedding(\n",
    "    test_adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden_X_encoded\",\n",
    "    frameon=False,\n",
    "    ax=axes[0],\n",
    "    show=False,\n",
    "    title=\"Clusters: X_encoded\"\n",
    ")\n",
    "\n",
    "# Plot for 'X'\n",
    "sc.pl.embedding(\n",
    "    test_adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden_X\",\n",
    "    frameon=False,\n",
    "    ax=axes[1],\n",
    "    show=False,\n",
    "    title=\"Clusters: X\"\n",
    ")\n",
    "\n",
    "# Plot for 'X_pca'\n",
    "sc.pl.embedding(\n",
    "    test_adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden_X_pca\",\n",
    "    frameon=False,\n",
    "    ax=axes[2],\n",
    "    show=False,\n",
    "    title=\"Clusters: X_pca\"\n",
    ")\n",
    "\n",
    "# Plot for 'X_encoded_pca'\n",
    "sc.pl.embedding(\n",
    "    test_adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden_X_encoded_pca\",\n",
    "    frameon=False,\n",
    "    ax=axes[3],\n",
    "    show=False,\n",
    "    title=\"Clusters: X_encoded_pca\"\n",
    ")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 两步训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# 生成 “零 or 非零” 的标签矩阵\n",
    "##################################################\n",
    "# Z[i, d] = 1 if X[i,d]!=0 else 0\n",
    "Z = (data.x != 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoStepGATModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        hidden_channels,\n",
    "        edge_dim=None,\n",
    "        heads=4,\n",
    "        num_encoders=2,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        包含:\n",
    "         1) GATv2 编码器 (多个encoder layer堆叠)\n",
    "         2) classifier_head: 用来预测 0/1 (zero or non-zero)\n",
    "         3) regressor_head : 用来预测数值大小\n",
    "        \"\"\"\n",
    "        super(TwoStepGATModel, self).__init__()\n",
    "        self.encoders = nn.ModuleList()\n",
    "        for i in range(num_encoders):\n",
    "            self.encoders.append(\n",
    "                GATv2EncoderLayer(\n",
    "                    in_channels=in_features if i == 0 else hidden_channels,\n",
    "                    out_channels=hidden_channels,\n",
    "                    heads=heads,\n",
    "                    edge_dim=edge_dim,\n",
    "                    dropout=dropout,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Head 1: 分类(是否为零)，在多标签问题上，每个特征维度输出一个logit\n",
    "        self.classifier_head = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_channels, in_features)  # 最终输出 [N, D]\n",
    "        )\n",
    "\n",
    "        # Head 2: 回归(如果是非零，输出值)，也是 [N, D]\n",
    "        self.regressor_head = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_channels, in_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x:         [N, D] 节点特征\n",
    "          edge_index: 图结构\n",
    "          edge_attr:  边特征 (可选)\n",
    "        Returns:\n",
    "          logits_class:  [N, D], (是否为零)的logits\n",
    "          pred_reg:      [N, D], (数值回归)的输出\n",
    "        \"\"\"\n",
    "        # 1) 先过 encoder\n",
    "        h = x.clone()\n",
    "        for encoder in self.encoders:\n",
    "            h = encoder(h, edge_index, edge_attr)\n",
    "\n",
    "        # 2) 分别走分类和回归两个头\n",
    "        logits_class = self.classifier_head(h)   # zero vs non-zero logits\n",
    "        pred_reg = self.regressor_head(h)        # regression for actual values\n",
    "\n",
    "        return logits_class, pred_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroNonZeroLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    多任务Loss:\n",
    "      1) 分类损失(零 or 非零): BCEWithLogitsLoss\n",
    "      2) 回归损失: MSE，只在真实非零位置\n",
    "    \"\"\"\n",
    "    def __init__(self, lambda_cls=0.5, lambda_reg=0.5, pos_weight=5.0):\n",
    "        super(ZeroNonZeroLoss, self).__init__()\n",
    "        self.lambda_cls = lambda_cls\n",
    "        self.lambda_reg = lambda_reg\n",
    "        # 用BCEWithLogitsLoss带pos_weight\n",
    "        self.criterion_cls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))\n",
    "        # 回归损失也可自定义\n",
    "        self.criterion_reg = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    def forward(self, logits_class, pred_reg, x, z):\n",
    "        \"\"\"\n",
    "        logits_class: [N, D], classifier输出 (logits)\n",
    "        pred_reg:     [N, D], regressor输出\n",
    "        x:            [N, D], 节点特征(原始真值)\n",
    "        z:            [N, D], 0/1指示 (是否非零)\n",
    "        Returns:\n",
    "          total_loss\n",
    "        \"\"\"\n",
    "        # 1) 分类损失\n",
    "        loss_cls = self.criterion_cls(logits_class, z)\n",
    "\n",
    "        # 2) 回归损失: 只在 z==1 的地方计算\n",
    "        mask_nonzero = (z == 1)\n",
    "        if mask_nonzero.sum() > 0:\n",
    "            loss_reg = self.criterion_reg(pred_reg[mask_nonzero], x[mask_nonzero])\n",
    "        else:\n",
    "            # 万一数据全是0，那就不算reg了\n",
    "            loss_reg = torch.tensor(0.0, device=x.device)\n",
    "\n",
    "        return self.lambda_cls * loss_cls + self.lambda_reg * loss_reg\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLossWithLogits(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss for binary classification (per-label).\n",
    "    Accepts logits as input, applies sigmoid internally.\n",
    "    Allows a 'pos_weight' for class imbalance.\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=2.0, alpha=1.0, pos_weight=1.0, reduction='mean'):\n",
    "        super(FocalLossWithLogits, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.pos_weight = pos_weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        \"\"\"\n",
    "        logits: [N, D] (raw, un-sigmoided)\n",
    "        targets: [N, D] in {0,1}\n",
    "        \"\"\"\n",
    "        # BCE with logits\n",
    "        bce_term = F.binary_cross_entropy_with_logits(\n",
    "            logits, targets, pos_weight=torch.tensor(self.pos_weight, device=logits.device),\n",
    "            reduction='none'\n",
    "        )\n",
    "        # p = sigmoid(logits)\n",
    "        p = torch.sigmoid(logits)\n",
    "        # focal weight\n",
    "        pt = p * targets + (1 - p) * (1 - targets)\n",
    "        focal_factor = (1 - pt).pow(self.gamma)\n",
    "\n",
    "        loss = self.alpha * focal_factor * bce_term\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "class ZeroNonZeroFocalMultiTaskLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    多任务Loss:\n",
    "      1) 分类损失(零 or 非零): FocalLossWithLogits\n",
    "      2) 回归损失: MSE，只在真实非零处计算\n",
    "    \"\"\"\n",
    "    def __init__(self, lambda_cls=0.5, lambda_reg=0.5, focal_gamma=2.0, focal_alpha=1.0, focal_pos_weight=20.0):\n",
    "        super(ZeroNonZeroFocalMultiTaskLoss, self).__init__()\n",
    "        self.lambda_cls = lambda_cls\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.focal_loss = FocalLossWithLogits(\n",
    "            gamma=focal_gamma,\n",
    "            alpha=focal_alpha,\n",
    "            pos_weight=focal_pos_weight,\n",
    "            reduction='mean'\n",
    "        )\n",
    "        self.criterion_reg = nn.MSELoss(reduction='mean')  # 回归用普通 MSE\n",
    "\n",
    "    def forward(self, logits_class, pred_reg, x, z):\n",
    "        \"\"\"\n",
    "        logits_class: [N, D], classifier输出 (logits)\n",
    "        pred_reg:     [N, D], regressor输出\n",
    "        x:            [N, D], 节点特征(真实值)\n",
    "        z:            [N, D], 0/1指示 (是否非零)\n",
    "        \"\"\"\n",
    "        # 1) 分类损失 (Focal Loss)\n",
    "        loss_cls = self.focal_loss(logits_class, z)\n",
    "\n",
    "        # 2) 回归损失：只在 z==1 的地方\n",
    "        mask_nonzero = (z == 1)\n",
    "        if mask_nonzero.sum() > 0:\n",
    "            loss_reg = self.criterion_reg(pred_reg[mask_nonzero], x[mask_nonzero])\n",
    "        else:\n",
    "            loss_reg = torch.tensor(0.0, device=x.device)\n",
    "\n",
    "        return self.lambda_cls * loss_cls + self.lambda_reg * loss_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "hidden_channels = 64\n",
    "heads = 4\n",
    "num_encoders = 4\n",
    "dropout = 0.2\n",
    "\n",
    "model = TwoStepGATModel(\n",
    "    in_features=in_features,\n",
    "    hidden_channels=hidden_channels,\n",
    "    edge_dim=edge_dim,\n",
    "    heads=heads,\n",
    "    num_encoders=num_encoders,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "# 定义优化器与Scheduler\n",
    "warmup_epochs = 500\n",
    "initial_lr = 1e-3\n",
    "warmup_lr = 1e-5\n",
    "epochs = 1000\n",
    "eta_min = 1e-5\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=warmup_lr)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=epochs - warmup_epochs, eta_min=eta_min)\n",
    "\n",
    "# 1) 初始化 Loss\n",
    "criterion_multi = ZeroNonZeroFocalMultiTaskLoss(\n",
    "    lambda_cls=1,\n",
    "    lambda_reg=0,\n",
    "    focal_gamma=2.0,\n",
    "    focal_alpha=1.0,\n",
    "    focal_pos_weight=20.0  # 适当增大\n",
    ").to(device)\n",
    "\n",
    "loss_history = []\n",
    "lr_history = []\n",
    "smoothing_factor = 0.9\n",
    "smoothed_loss = None\n",
    "\n",
    "# 训练循环\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\", leave=True):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Warmup learning rate\n",
    "    if epoch < warmup_epochs:\n",
    "        lr = warmup_lr + (initial_lr - warmup_lr) * epoch / warmup_epochs\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    else:\n",
    "        scheduler.step()\n",
    "\n",
    "    lr_history.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    ###########################\n",
    "    # 1) 构造随机mask (例如15%)\n",
    "    ###########################\n",
    "    mask = torch.rand(num_nodes, device=device) < 0.15\n",
    "    # 对被mask掉的节点特征进行处理(与之前BERT-style做法类似)\n",
    "    target_x = data.x[mask]           # 真实值(仅mask节点)\n",
    "    target_z = Z[mask]               # 零/非零标签(仅mask节点)\n",
    "\n",
    "    modified_data_x = data.x.clone()\n",
    "    for idx in torch.where(mask)[0]:\n",
    "        rand = random.random()\n",
    "        if rand < 0.8:\n",
    "            modified_data_x[idx] = 0\n",
    "        elif rand < 0.9:\n",
    "            modified_data_x[idx] = torch.randn_like(data.x[idx])\n",
    "        # else: 保持原值\n",
    "\n",
    "    # 更新 data.x\n",
    "    data.x = modified_data_x\n",
    "\n",
    "    ###########################\n",
    "    # 2) 前向计算\n",
    "    ###########################\n",
    "    logits_class, pred_reg = model(\n",
    "        x=data.x,\n",
    "        edge_index=data.edge_index,\n",
    "        edge_attr=data.edge_attr\n",
    "    )\n",
    "    # 只拿mask节点的输出\n",
    "    logits_class_masked = logits_class[mask]\n",
    "    pred_reg_masked     = pred_reg[mask]\n",
    "\n",
    "    ###########################\n",
    "    # 3) 计算损失并反向传播\n",
    "    ###########################\n",
    "    loss = criterion_multi(\n",
    "        logits_class_masked,  # [num_masked, D]\n",
    "        pred_reg_masked,      # [num_masked, D]\n",
    "        target_x,             # [num_masked, D]\n",
    "        target_z              # [num_masked, D]\n",
    "    )\n",
    "\n",
    "    # 平滑loss\n",
    "    if smoothed_loss is None:\n",
    "        smoothed_loss = loss.item()\n",
    "    else:\n",
    "        smoothed_loss = smoothing_factor * smoothed_loss + (1 - smoothing_factor) * loss.item()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_history.append(smoothed_loss)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        tqdm.write(f\"Epoch {epoch}/{epochs}, Loss: {smoothed_loss:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "\n",
    "# 可视化学习率和损失\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(lr_history, label='Learning Rate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(loss_history, label='Train Loss (smoothed)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def visualize_zero_nonzero_classification(model, data, Z, threshold=0.5, sample_ratio=1.0):\n",
    "    \"\"\"\n",
    "    可视化 zero/non-zero 分类效果。\n",
    "    \n",
    "    Args:\n",
    "        model:          训练好的模型(包含分类头)\n",
    "        data:           图数据对象(data.x, data.edge_index, data.edge_attr)\n",
    "        Z:              零/非零标签 [N, D], 0 or 1\n",
    "        threshold:      用于将预测概率 -> 0/1 的阈值\n",
    "        sample_ratio:   如果数据太多，可以只采样一部分(0,1], 默认1.0表示不采样\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 得到分类 logits\n",
    "        logits_class, _ = model(\n",
    "            x=data.x, \n",
    "            edge_index=data.edge_index, \n",
    "            edge_attr=data.edge_attr\n",
    "        )\n",
    "    \n",
    "    # 计算概率\n",
    "    probs = torch.sigmoid(logits_class)  # [N, D], in [0,1]\n",
    "    \n",
    "    # 把数据拉平，得到 1D 向量\n",
    "    true_label = Z.view(-1).cpu().numpy()      # [N*D]\n",
    "    pred_prob  = probs.view(-1).cpu().numpy()  # [N*D]\n",
    "    \n",
    "    # 可选：只采样部分数据做可视化(若非常巨大)\n",
    "    total_size = len(true_label)\n",
    "    if sample_ratio < 1.0:\n",
    "        idx = np.random.choice(total_size, int(sample_ratio * total_size), replace=False)\n",
    "        true_label = true_label[idx]\n",
    "        pred_prob  = pred_prob[idx]\n",
    "    \n",
    "    # 1) 绘制预测概率分布直方图\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    # 分别取真值为0 和 真值为1\n",
    "    prob_for_0 = pred_prob[true_label == 0]\n",
    "    prob_for_1 = pred_prob[true_label == 1]\n",
    "    \n",
    "    ax.hist(prob_for_0, bins=50, alpha=0.5, label='True=0', density=True, color='blue')\n",
    "    ax.hist(prob_for_1, bins=50, alpha=0.5, label='True=1', density=True, color='red')\n",
    "    ax.set_xlabel(\"Predicted Probability\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(\"Distribution of Predicted Probability (Zero vs Non-Zero)\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2) 混淆矩阵 (基于 threshold=0.5)\n",
    "    pred_label = (pred_prob >= threshold).astype(int)\n",
    "    cm = confusion_matrix(true_label, pred_label, labels=[0,1])\n",
    "    \n",
    "    # 可视化混淆矩阵\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Pred=0','Pred=1'],\n",
    "                yticklabels=['True=0','True=1'])\n",
    "    plt.title(f\"Confusion Matrix (threshold={threshold})\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 3) 分类报告\n",
    "    print(\"Classification Report (threshold={:.2f}):\".format(threshold))\n",
    "    print(classification_report(true_label, pred_label, digits=4))\n",
    "    \n",
    "    # 4) (可选) Plot Precision-Recall / ROC 曲线\n",
    "    # 这里示例 Precision-Recall\n",
    "    precision, recall, _ = precision_recall_curve(true_label, pred_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(recall, precision, label=f'PR curve (AUC={pr_auc:.4f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 也可以加 ROC\n",
    "    fpr, tpr, _ = roc_curve(true_label, pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC={roc_auc:.4f})')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设以下变量已准备好:\n",
    "#  model       : 训练好的 TwoStepGATModel (或者别的包含分类头的模型)\n",
    "#  data        : 数据(含x, edge_index, edge_attr等)\n",
    "#  Z           : [N, D]的0/1矩阵 (指示某特征维度是否为非零)\n",
    "#  device      : cuda 或 cpu\n",
    "\n",
    "# 确保 model 和 data 在同一个 device 上\n",
    "model.to(device)\n",
    "data = data.to(device)\n",
    "Z = Z.to(device)  # [N, D]\n",
    "\n",
    "visualize_zero_nonzero_classification(model, data, Z, threshold=0.5, sample_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GPU",
   "language": "python",
   "name": "gpu_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
