<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Diagnosing and Fixing Stagnant CLIP Model Loss / 诊断和解决停滞的CLIP模型损失</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Noto+Sans+SC:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        html {
            background-color: #f0f2f5; /* Outermost background - a very light, neutral grey */
            scroll-behavior: smooth;
        }
        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
            margin: 0;
            padding: 0;
            background-color: #f0f2f5; /* Consistent with html or slightly different for effect */
            color: #333d47; /* Darker, more saturated text for better readability */
            line-height: 1.75; /* Increased line height for readability */
            font-size: 17px; /* Slightly larger base font size */
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }
        .container {
            max-width: 1000px; /* Optimal width for reading */
            margin: 50px auto; /* More vertical margin */
            padding: 45px 55px; /* Increased padding */
            background-color: #ffffff;
            box-shadow: 0 10px 30px rgba(0, 30, 80, 0.08); /* Softer, more diffused shadow */
            border-radius: 16px; /* More pronounced rounding */
            border: 1px solid #e6e8eb; /* Subtle border */
        }
        h1, h2, h3 {
            color: #1a2b48; /* Deep, sophisticated blue-black */
            margin-top: 2.2em;
            margin-bottom: 1em;
            font-weight: 700;
            line-height: 1.3;
        }
        h1 {
            text-align: center;
            font-size: 2.5rem; /* Responsive unit */
            color: #0c1f3e;
            padding-bottom: 0.7em;
            margin-bottom: 1.5em;
        }
        h2 {
            font-size: 1.9rem;
            padding-bottom: 0.5em;
            margin-top: 2.8em;
            border-bottom: 1px solid #dfe3e8; /* Lighter, subtle border */
            color: #1d3557; /* Slightly lighter than h1 */
        }
        h3 {
            font-size: 1.5rem;
            color: #457b9d; /* Softer, yet distinct blue for h3 */
            font-weight: 600;
            margin-top: 2em;
        }
        p, li {
            margin-bottom: 1.2em;
            color: #4a5568; /* Softer grey for paragraph text */
        }
        ul, ol {
            padding-left: 25px;
        }
        strong, b {
            font-weight: 600;
            color: #2c3e50; /* Darker for emphasized text */
        }

        .lang-toggle {
            margin-bottom: 1.8em;
            padding: 20px 25px;
            border: 1px solid #e9edf2; /* Softer, lighter border */
            background-color: #fcfdff; /* Almost white, very clean */
            border-radius: 10px;
            box-shadow: 0 3px 10px rgba(0, 20, 60, 0.04); /* Very subtle card shadow */
        }
        .lang-toggle .en {
            margin-bottom: 0.6em;
            color: #333d47;
        }
        .lang-toggle .zh {
            font-family: 'Noto Sans SC', 'Inter', sans-serif;
            color: #434d56;
            font-size: 0.98em; /* Slightly adjust for Chinese font rendering */
        }
        .lang-toggle li .zh {
            font-size: 1em; /* Reset for list items if needed */
        }

        .code-block {
            background-color: #2a2f3a; /* A slightly more muted dark theme */
            color: #c5c8c6; /* Off-white code text */
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
            font-size: 0.92em;
            margin-top: 1.2em;
            margin-bottom: 1.8em;
            border: 1px solid #383f4a; /* Subtle border for code block */
        }
        .code-block code {
            white-space: pre;
            line-height: 1.5;
        }
        .highlight {
            background-color: #ffefcc; /* Softer yellow highlight */
            padding: 0.2em 0.5em;
            border-radius: 5px;
            font-weight: 600;
            color: #7a5f00;
            border: 1px solid #ffe3a1; /* Subtle border for highlight */
        }
        .note {
            background-color: #e6f9f5; /* Soft teal/mint */
            border: 1px solid #a6e9d9;
            color: #135246;
            padding: 18px 22px;
            border-radius: 8px;
            margin-top: 1.5em;
            margin-bottom: 1.5em;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        }
        .note strong {
            color: #004d40;
            font-weight: 600;
        }
        .section-divider {
            height: 1px;
            background-color: #e9edf2;
            border: none;
            margin-top: 3.5em;
            margin-bottom: 3.5em;
        }

        .improvement-case {
            border: 1px solid #dce4ec;
            padding: 28px 32px;
            margin-top: 1.8em;
            margin-bottom: 2.2em;
            border-radius: 12px;
            background-color: #f9fafc; /* Slightly off-white for distinction */
            box-shadow: 0 6px 18px rgba(0, 30, 70, 0.06);
        }
        .improvement-case strong.case-title {
            display: block;
            margin-bottom: 15px;
            font-size: 1.3em;
            color: #2e6da4; /* Distinct blue for case titles */
            font-weight: 700;
            padding-bottom: 10px;
            border-bottom: 1px solid #e1e8f0;
        }
        .bilingual-title .en-title { display: block; line-height: 1.2; }
        .bilingual-title .zh-title { display: block; font-size: 0.82em; color: #6c757d; font-weight: 400; font-family: 'Noto Sans SC', 'Inter', sans-serif; margin-top: 5px;}

        /* Specific list styling inside lang-toggle for better spacing */
        .lang-toggle ul, .lang-toggle ol {
            padding-left: 20px;
        }
        .lang-toggle ul li, .lang-toggle ol li {
            margin-bottom: 0.7em; /* Tighter spacing for list items within these blocks */
        }
        .lang-toggle ul ul, .lang-toggle ol ol {
            margin-top: 0.5em; /* Space before nested lists */
            margin-bottom: 0.5em;
        }
        .lang-toggle ul li .en, .lang-toggle ul li .zh {
             display: block; /* Ensure each language takes its own line in list items */
        }
         .lang-toggle ul li .en + .zh { /* Add a small space if English is followed by Chinese in the same li */
            margin-top: 0.3em;
        }

    </style>
</head>
<body>
    <div class="container">
        <h1>
            <span class="bilingual-title">
                <span class="en-title">Diagnosing and Fixing Stagnant CLIP Model Loss</span>
                <span class="zh-title">诊断和解决停滞的CLIP模型损失</span>
            </span>
        </h1>

        <div class="lang-toggle">
            <p class="en">It's definitely a common frustration when your model's loss plateaus, especially when it's stuck at a level suggesting it's not learning much! A loss around 4.2 for a batch size of 64 (or 128 if you consider the global batch size across GPUs) is indeed very close to <code>log(batch_size)</code>, which is what you'd expect if the model is essentially guessing randomly.</p>
            <p class="zh">当您的模型损失停滞不前时，这无疑是一种常见的挫败感，尤其是当它停留在一个表明学习效果不佳的水平上时！对于64的批量大小（如果考虑跨GPU的全局批量大小，则为128），约4.2的损失确实非常接近 <code>log(batch_size)</code>，这与模型基本上在随机猜测时的预期情况相符。</p>
        </div>
        <div class="lang-toggle">
            <p class="en">Let's break this down intuitively and then look at some practical examples and improvements.</p>
            <p class="zh">让我们直观地分解这个问题，然后看一些实际的例子和改进方法。</p>
        </div>

        <h2>
             <span class="bilingual-title">
                <span class="en-title">Why is my CLIP Loss Stuck? (The "Matching Game" Analogy)</span>
                <span class="zh-title">为什么我的CLIP损失停滞不前？（“配对游戏”类比）</span>
            </span>
        </h2>
        <div class="lang-toggle">
            <p class="en">Think of contrastive learning, like CLIP's InfoNCE loss, as a "matching game."</p>
            <p class="zh">将对比学习（如CLIP的InfoNCE损失）想象成一个“配对游戏”。</p>
            <ul>
                <li><span class="en">You have a batch of, say, 64 gene expression graphs (let's call them "recipes") and 64 corresponding image patches from GigaPath (let's call them "food photos").</span><span class="zh">假设您有一批（比如64个）基因表达图（我们称之为“食谱”）和64个相应的GigaPath图像块（我们称之为“食物照片”）。</span></li>
                <li><span class="en">For each "recipe," its true corresponding "food photo" is the <strong>positive pair</strong>.</span><span class="zh">对于每个“食谱”，其真正对应的“食物照片”是<strong>正样本对</strong>。</span></li>
                <li><span class="en">All other 63 "food photos" in the batch are <strong>negative pairs</strong> for that specific "recipe."</span><span class="zh">该批次中所有其他63张“食物照片”对于该特定“食谱”而言都是<strong>负样本对</strong>。</span></li>
                <li><span class="en">The model's job is to learn an embedding (a numerical fingerprint) for each recipe and each photo such that:</span><span class="zh">模型的任务是为每个食谱和每张照片学习一个嵌入（数值指纹），使得：</span>
                    <ul>
                        <li><span class="en">The fingerprint of a recipe is <strong>very similar</strong> to the fingerprint of its true matching photo.</span><span class="zh">食谱的指纹与其真正匹配的照片的指纹<strong>非常相似</strong>。</span></li>
                        <li><span class="en">The fingerprint of a recipe is <strong>very different</strong> from the fingerprints of all the non-matching photos.</span><span class="zh">食谱的指纹与所有不匹配照片的指纹<strong>非常不同</strong>。</span></li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="lang-toggle">
            <p class="en">The loss function penalizes the model if:</p>
            <p class="zh">如果出现以下情况，损失函数会惩罚模型：</p>
            <ul>
                <li><span class="en">A recipe's fingerprint is far from its true photo's fingerprint.</span><span class="zh">食谱的指纹远离其真实照片的指纹。</span></li>
                <li><span class="en">A recipe's fingerprint is close to a non-matching photo's fingerprint.</span><span class="zh">食谱的指纹接近不匹配照片的指纹。</span></li>
            </ul>
        </div>

        <h3>
            <span class="bilingual-title">
                <span class="en-title">When the Loss Stays High (like your ~4.2):</span>
                <span class="zh-title">当损失居高不下时（比如您的约4.2）：</span>
            </span>
        </h3>
        <div class="lang-toggle">
            <p class="en">If the loss stays around <code>log(batch_size)</code>, it means your model is saying, "For any given recipe, all the food photos in this batch look equally (un)likely to be the match." It hasn't learned any specific features that link a particular gene expression pattern to a particular visual histology pattern. It's like a player in the matching game who is just randomly flipping cards hoping for a match – no skill, just chance.</p>
            <p class="zh">如果损失停留在 <code>log(batch_size)</code> 附近，这意味着您的模型在说：“对于任何给定的食谱，这批次中的所有食物照片看起来都同样（不）可能是匹配项。”它没有学到任何特定的特征来将特定的基因表达模式与特定的视觉组织学模式联系起来。这就像配对游戏中的一个玩家，只是随机翻牌希望匹配成功——没有技巧，只有运气。</p>
        </div>
        <div class="lang-toggle">
            <p class="en">This is <strong class="highlight">not normal</strong> for a well-functioning CLIP-style training process if there's a learnable relationship in your data. You should see a clear and sustained decrease in loss over epochs.</p>
            <p class="zh">如果您的数据中存在可学习的关系，那么对于一个运行良好的CLIP式训练过程来说，这是<strong class="highlight">不正常的</strong>。您应该在多个轮次中看到损失明显且持续的下降。</p>
        </div>

        <hr class="section-divider">

        <h2>
            <span class="bilingual-title">
                <span class="en-title">Common Reasons for Stagnant Loss & How to Investigate</span>
                <span class="zh-title">损失停滞的常见原因及调查方法</span>
            </span>
        </h2>

        <h3>
            <span class="bilingual-title">
                <span class="en-title">1. Weak Signal or Mismatched Pairs: "Are these <em>truly</em> a match?"</span>
                <span class="zh-title">1. 信号弱或配对错误：“这些<em>真的</em>是匹配的吗？”</span>
            </span>
        </h3>
        <div class="lang-toggle">
            <p class="en"><strong>Intuition:</strong> Imagine you're trying to teach a child to match a detailed textual description of a specific car (e.g., "a 2023 red Toyota Camry with a dent on the left fender and a roof rack") to a picture.</p>
            <p class="zh"><strong>直观解释：</strong> 想象一下，您正尝试教一个孩子将一辆特定汽车的详细文字描述（例如，“一辆2023年红色丰田凯美瑞，左挡泥板有凹痕，带车顶行李架”）与一张图片匹配起来。</p>
            <ul>
                <li><span class="en"><strong>Strong Signal:</strong> The picture clearly shows that exact car.</span><span class="zh"><strong>强信号：</strong> 图片清晰地显示了那辆确切的汽车。</span></li>
                <li><span class="en"><strong>Weak Signal:</strong> The picture is a blurry photo of <em>a</em> red car, or a photo of just a tire from that car. The specific details aren't visible.</span><span class="zh"><strong>弱信号：</strong> 图片是一张模糊的<em>红色</em>汽车照片，或者只是那辆车一个轮胎的照片。具体细节不可见。</span></li>
                <li><span class="en"><strong>Mismatched Pair:</strong> The description is for the Camry, but the photo is of a blue Ford truck.</span><span class="zh"><strong>配对错误：</strong> 描述是凯美瑞，但照片是一辆蓝色福特卡车。</span></li>
            </ul>
            <p class="en"><strong>Your Scenario:</strong> Are the GigaPath image features (from a specific tile) truly and strongly representative of the underlying gene expression graph (derived from spatial transcriptomics for <em>that same tile</em>)? The GigaPath features represent visual morphology. The graph represents gene activity. While spatially co-located, the direct information overlap might be subtle or noisy. Are there any errors in your data pipeline that could cause a mismatch?</p>
            <p class="zh"><strong>您的场景：</strong> GigaPath图像特征（来自特定图块）是否真正且强烈地代表了底层的基因表达图（源自<em>该相同图块</em>的空间转录组学数据）？GigaPath特征代表视觉形态，而图代表基因活动。尽管它们在空间上共存，但直接的信息重叠可能很微妙或充满噪声。您的数据流程中是否存在任何可能导致不匹配的错误？</p>
        </div>
        <div class="improvement-case">
            <strong class="case-title"><span class="en">Improvement Case Study & Action:</span><span class="zh">改进案例与行动：</span></strong>
            <div class="lang-toggle">
                <p class="en"><strong>Verify Data Alignment:</strong> Manually inspect a few dozen pairs. Take a <code>graph_data.pt</code> file, get its <code>sample_id</code> and a specific <code>node_idx</code>. From the <code>node_idx</code>, get the coordinates (<code>x_coord_str</code>, <code>y_coord_str</code>) used to construct the GigaPath feature path. Separately, visualize the original histology image tile and the gene expression for that node. <strong>Ask:</strong> Does it intuitively make sense that <em>this</em> visual patch corresponds to <em>this</em> gene activity? Your script's graph data validation (Cell 1 in "Precomputation") is a good start. Ensure that <code>latent_paths</code> (or the derived GigaPath feature paths) correctly map to the features you are actually loading.</p>
                <p class="zh"><strong>验证数据对齐：</strong> 手动检查几十对样本。取一个 <code>graph_data.pt</code> 文件，获取其 <code>sample_id</code> 和特定的 <code>node_idx</code>。从 <code>node_idx</code> 获取用于构建GigaPath特征路径的坐标（<code>x_coord_str</code>, <code>y_coord_str</code>）。分别可视化原始的组织学图像图块和该节点的基因表达（例如，其PCA特征或关键基因的点图）。<strong>反思：</strong><em>这个</em>视觉图块对应于<em>这个</em>基因活动，这在直觉上合理吗？您的脚本中的图数据验证（“预计算”中的单元格1）是一个很好的起点。确保 <code>latent_paths</code> （或派生的GigaPath特征路径）正确映射到您实际加载的特征。</p>
                <p class="en"><strong>Consider Feature Granularity:</strong> GigaPath features are from image patches. Your graph nodes represent individual spots/cells or small regions. Is the scale of information compatible?</p>
                <p class="zh"><strong>考虑特征粒度：</strong> GigaPath特征来自图像块。您的图节点代表单个点/细胞或小区域。信息尺度是否兼容？</p>
            </div>
        </div>

        <h3>
            <span class="bilingual-title">
                <span class="en-title">2. The "Language Barrier" (Modality Gap): "Do these two 'languages' have enough common ground?"</span>
                <span class="zh-title">2. “语言障碍”（模态鸿沟）：“这两种‘语言’有足够的共同点吗？”</span>
            </span>
        </h3>
        <div class="lang-toggle">
            <p class="en"><strong>Intuition:</strong> You're trying to find similarities between a paragraph in English (graph embedding) and a paragraph in Russian (image embedding) by simply comparing them word-for-word without a translator. You need a "translator" or a common "concept space."</p>
            <p class="zh"><strong>直观解释：</strong> 您试图在没有翻译的情况下，通过逐字比较来找出一段英文（图嵌入）和一段俄文（图像嵌入）之间的相似之处。您需要一个“翻译器”或一个共同的“概念空间”。</p>
            <p class="en"><strong>Your Scenario:</strong> The raw output of your GNN and the GigaPath model live in very different "embedding spaces." Your MLP projection heads are supposed to act as these translators, mapping both to a shared "CLIP embedding space." If these translators are too simple or not well-initialized, they might not be powerful enough.</p>
            <p class="zh"><strong>您的场景：</strong> 您的GNN和GigaPath模型的原始输出位于非常不同的“嵌入空间”中。您的MLP投影头应该充当这些翻译器，将两者映射到一个共享的“CLIP嵌入空间”。如果这些翻译器太简单或初始化不佳，它们可能不够强大。</p>
        </div>
        <div class="improvement-case">
            <strong class="case-title"><span class="en">Improvement Case Study & Action:</span><span class="zh">改进案例与行动：</span></strong>
            <div class="lang-toggle">
                <p class="en"><strong>More Powerful Projection Heads:</strong> Your <code>GigapathFeatureEncoder</code> is <code>[GigaPath_dim, 1024, CLIP_dim]</code>. Your <code>GraphConditioner</code> outputs to <code>CLIP_EMBED_DIM</code>. Ensure both have sufficient expressive power. Consider adding another layer or adjusting hidden dimensions if one projection seems simpler than the other. For instance, a common MLP is <code>Input -> Hidden -> NonLinearity -> Hidden -> Output_CLIP_Dim</code>.</p>
                <p class="zh"><strong>更强大的投影头：</strong> 您的 <code>GigapathFeatureEncoder</code> 是 <code>[GigaPath_dim, 1024, CLIP_dim]</code>。您的 <code>GraphConditioner</code> 输出到 <code>CLIP_EMBED_DIM</code>。确保两者都具有足够的表达能力。如果一个投影看起来比另一个简单，可以考虑增加一个层或调整隐藏维度。例如，常见的MLP结构是 <code>输入 -> 隐藏层 -> 非线性激活 -> 隐藏层 -> CLIP输出维度</code>。</p>
                <p class="en"><strong>Normalization:</strong> Ensure outputs from both projection heads are L2 normalized <em>before</em> calculating the dot product. Your <code>GraphGigapathCLIP</code> model does this correctly, which is crucial.</p>
                <p class="zh"><strong>归一化：</strong> 确保在计算点积之前，两个投影头的输出都经过L2归一化。您的 <code>GraphGigapathCLIP</code> 模型正确地执行了此操作，这至关重要。</p>
            </div>
        </div>

        <h3>
            <span class="bilingual-title">
                <span class="en-title">3. Not Enough "Wrong" Examples (Poor Negative Sampling): "How can I learn what's right if I don't see enough of what's wrong?"</span>
                <span class="zh-title">3. “错误”样本不足（负采样不佳）：“如果我看不到足够多的错误示例，我怎么能学会什么是正确的？”</span>
            </span>
        </h3>
        <div class="lang-toggle">
            <p class="en"><strong>Intuition:</strong> If you're teaching "this is a cat," and only show 5 other animals (4 are cat breeds, one is a cat-like dog), the learner might get confused. They need a wide variety of "not cats" to understand.</p>
            <p class="zh"><strong>直观解释：</strong> 如果您在教“这是一只猫”，却只展示了5种其他动物（其中4种是猫的品种，1种是像猫的狗），学习者可能会感到困惑。他们需要看到各种各样的“非猫”才能理解。</p>
            <p class="en"><strong>Your Scenario:</strong> Your effective batch size for negative sampling is <code>(batch_size_per_gpu * num_gpus_clip) - 1</code>. This might be too small. Contrastive learning thrives on many diverse negatives.</p>
            <p class="zh"><strong>您的场景：</strong> 您用于负采样的有效批量大小是 <code>(每GPU批量大小 * CLIP所用GPU数量) - 1</code>。这个数量可能太小。对比学习依赖于大量且多样化的负样本。</p>
        </div>
        <div class="improvement-case">
            <strong class="case-title"><span class="en">Improvement Case Study & Action:</span><span class="zh">改进案例与行动：</span></strong>
            <div class="lang-toggle">
                <p class="en"><strong>Increase Batch Size:</strong> Max out GPU memory. Your <code>CLIP_BATCH_SIZE_PER_GPU = 64</code> is a start, but larger is often better.</p>
                <p class="zh"><strong>增加批量大小：</strong> 最大限度地利用GPU内存。您当前的 <code>CLIP_BATCH_SIZE_PER_GPU = 64</code> 是一个起点，但如果可能，通常越大越好。</p>
                <p class="en"><strong>Multi-GPU Training & All-Gather (Advanced):</strong> You use DDP. If loss is calculated per GPU, negatives are limited. For more negatives, gather embeddings from all GPUs before loss calculation (<code>dist.all_gather</code>). This makes labels and loss calculation more complex but increases negatives to <code>(batch_size_per_gpu * world_size) - 1</code>. Your current per-GPU loss is standard; be aware of its negative sample size limitation.</p>
                <p class="zh"><strong>多GPU训练与All-Gather（高级）：</strong> 您正在使用DDP。如果损失是在每个GPU上计算的，则负样本数量有限。要获得更多负样本，可以在计算损失之前从所有GPU收集嵌入（使用<code>dist.all_gather</code>）。这会使标签和损失计算更加复杂，但会将负样本数量增加到 <code>(每GPU批量大小 * world_size) - 1</code>。您当前的每GPU损失计算是标准做法；请注意其负样本数量的限制。</p>
            </div>
        </div>

        <h3>
            <span class="bilingual-title">
                <span class="en-title">4. The Graph "Whispering Game" (GNN Issues - Over-smoothing, Complexity): "Is my graph 'student' too confused or too simplistic?"</span>
                <span class="zh-title">4. 图的“传话游戏”（GNN问题 - 过度平滑、复杂度）：“我的图‘学生’是太困惑还是太简单了？”</span>
            </span>
        </h3>
        <div class="lang-toggle">
            <p class="en"><strong>Intuition (Over-smoothing):</strong> Like a game of telephone, after too many GNN layers, node features can become indistinguishable.</p>
            <p class="zh"><strong>直观解释（过度平滑）：</strong> 就像传话游戏一样，经过太多GNN层后，节点特征可能会变得难以区分。</p>
            <p class="en"><strong>Your Scenario:</strong> Your <code>GraphConditioner</code> uses <code>CONDITIONER_N_LAYERS = 4</code> GPSConv layers. Input node features are PCA components (`PCA_N_COMPS = 50`). Are these discriminative enough?</p>
            <p class="zh"><strong>您的场景：</strong> 您的 <code>GraphConditioner</code> 使用 <code>CONDITIONER_N_LAYERS = 4</code> 个GPSConv层。输入节点特征是PCA分量（<code>PCA_N_COMPS = 50</code>）。这些分量是否足够具有区分性？</p>
        </div>
        <div class="improvement-case">
            <strong class="case-title"><span class="en">Improvement Case Study & Action:</span><span class="zh">改进案例与行动：</span></strong>
            <div class="lang-toggle">
                <p class="en"><strong>Experiment with GNN Depth:</strong> Try reducing <code>CONDITIONER_N_LAYERS</code> to 2 or 3. Sometimes shallower GNNs work better.</p>
                <p class="zh"><strong>实验GNN深度：</strong> 尝试将 <code>CONDITIONER_N_LAYERS</code> 减少到2或3。有时较浅的GNN效果更好。</p>
                <p class="en"><strong>Graph Data Augmentation (GraphCL-style, Advanced):</strong> Create two "views" of each graph (e.g., by randomly dropping nodes/edges) and force similar embeddings for these views.</p>
                <p class="zh"><strong>图数据增强（GraphCL风格，高级）：</strong> 为每个图创建两个“视图”（例如，通过随机删除节点/边），并强制这些视图产生相似的嵌入。</p>
                <p class="en"><strong>Node Feature Quality:</strong> Revisit your PCA. Does <code>n_comps=50</code> capture enough variance? Could using raw (but high-variance) gene expressions or a different feature selection work better?</p>
                <p class="zh"><strong>节点特征质量：</strong> 重新审视您的PCA。<code>n_comps=50</code> 是否捕获了足够的方差？直接使用原始（但高方差）的基因表达或不同的特征选择方法是否效果更好？</p>
            </div>
        </div>

        <h3>
            <span class="bilingual-title">
                <span class="en-title">5. The "Stubborn Teacher" (Fixed Image Encoder & Asymmetric Learning): "Is the fixed image 'language' too hard for my graph 'student' to learn?"</span>
                <span class="zh-title">5. “固执的老师”（固定的图像编码器与非对称学习）：“固定的图像‘语言’对我的图‘学生’来说太难学了吗？”</span>
            </span>
        </h3>
        <div class="lang-toggle">
            <p class="en"><strong>Intuition:</strong> A novice student trying to learn from a Picasso who only shows one style and gives no feedback. The student does all the work.</p>
            <p class="zh"><strong>直观解释：</strong> 一个新手学生试图向一位只展示一种风格且不提供任何反馈的毕加索学习。学生承担了所有的学习任务。</p>
            <p class="en"><strong>Your Scenario:</strong> The GigaPath model is frozen. All learning pressure is on the graph encoder.</p>
            <p class="zh"><strong>您的场景：</strong> GigaPath模型是固定的。所有的学习压力都在图编码器上。</p>
        </div>
        <div class="improvement-case">
            <strong class="case-title"><span class="en">Improvement Case Study & Action:</span><span class="zh">改进案例与行动：</span></strong>
            <div class="lang-toggle">
                <p class="en"><strong>Fine-tune Image Encoder (Later Stage):</strong> If loss remains stuck, consider *gently* fine-tuning the last few layers of GigaPath (or its projection head) with a smaller learning rate. Caution: can lead to "forgetting."</p>
                <p class="zh"><strong>微调图像编码器（后期阶段）：</strong> 如果损失仍然停滞，考虑以较小的学习率*温和地*微调GigaPath的最后几层（或其投影头）。注意：这可能导致“遗忘”。</p>
                <p class="en"><strong>Ensure GigaPath Features are Optimal:</strong> Confirm <code>prov-gigapath</code> is best for capturing morphology relevant to gene expression. Are features from the correct layer?</p>
                <p class="zh"><strong>确保GigaPath特征最优：</strong> 确认 <code>prov-gigapath</code> 是捕获与基因表达相关的形态学的最佳选择。特征是否来自正确的层？</p>
            </div>
        </div>

        <h3>
            <span class="bilingual-title">
                <span class="en-title">6. The "Thermometer" (Logit Scale / Temperature <code>t</code>): "Is the comparison too strict or too loose?"</span>
                <span class="zh-title">6. “温度计”（Logit Scale / 温度 <code>t</code>）：“比较是太严格还是太宽松了？”</span>
            </span>
        </h3>
        <div class="lang-toggle">
            <p class="en"><strong>Intuition:</strong> <code>logit_scale</code> (inverse of temperature <code>t</code>) controls the "sharpness" of the similarity distribution. High <code>logit_scale</code> (low temp) is sensitive; low <code>logit_scale</code> (high temp) is softer.</p>
            <p class="zh"><strong>直观解释：</strong> <code>logit_scale</code>（温度 <code>t</code> 的倒数）控制相似性分布的“锐度”。高 <code>logit_scale</code>（低温）敏感；低 <code>logit_scale</code>（高温）更平滑。</p>
            <p class="en"><strong>Your Scenario:</strong> Initialized with <code>np.log(1 / 0.07)</code> (standard CLIP) and learnable.</p>
            <p class="zh"><strong>您的场景：</strong> 使用 <code>np.log(1 / 0.07)</code>（标准CLIP值）初始化，并且是可学习的。</p>
        </div>
        <div class="improvement-case">
            <strong class="case-title"><span class="en">Improvement Case Study & Action:</span><span class="zh">改进案例与行动：</span></strong>
            <div class="lang-toggle">
                <p class="en"><strong>Monitor & Clip <code>logit_scale</code>:</strong> Log its value. Is it exploding or vanishing? OpenAI clips its value (e.g., <code>logit_scale.data.clamp_(-np.log(100), np.log(100))</code>) to prevent extremes. Your <code>logit_scale.exp()</code> in forward is correct.</p>
                <p class="zh"><strong>监控和裁剪 <code>logit_scale</code>：</strong> 记录其值。它是否在急剧增大或消失？OpenAI会裁剪其值（例如，<code>logit_scale.data.clamp_(-np.log(100), np.log(100))</code>）以防止极端情况。您在前向传播中使用 <code>logit_scale.exp()</code> 是正确的。</p>
            </div>
        </div>

        <h3>
            <span class="bilingual-title">
                <span class="en-title">7. Flawed "School Supplies" (Bugs, Learning Rate, Optimizer, etc.): "Are my basic tools broken?"</span>
                <span class="zh-title">7. “学习用品”有缺陷（错误、学习率、优化器等）：“我的基本工具是否损坏了？”</span>
            </span>
        </h3>
        <div class="lang-toggle">
            <p class="en"><strong>Intuition:</strong> Trying to learn with a broken pencil or the wrong textbook.</p>
            <p class="zh"><strong>直观解释：</strong> 试图用坏掉的铅笔或错误的教科书学习。</p>
            <p class="en"><strong>Your Scenario:</strong> Potential bugs in data loading, model, DDP, loss. Learning rate <code>1e-4</code> with AdamW is a common start.</p>
            <p class="zh"><strong>您的场景：</strong> 数据加载、模型、DDP、损失计算中可能存在错误。使用AdamW优化器，学习率为 <code>1e-4</code> 是一个常见的起点。</p>
        </div>
        <div class="improvement-case">
            <strong class="case-title"><span class="en">Improvement Case Study & Action:</span><span class="zh">改进案例与行动：</span></strong>
            <div class="lang-toggle">
                <p class="en"><strong>Drastically Lower Learning Rate:</strong> Try <code>1e-5</code> or <code>5e-6</code>. If loss moves, initial LR might be too high.</p>
                <p class="zh"><strong>大幅降低学习率：</strong> 尝试 <code>1e-5</code> 或 <code>5e-6</code>。如果损失开始变化，初始学习率可能过高。</p>
                <p class="en"><strong>Sanity Check Data Loading:</strong> In <code>GraphGigapathFeatureDataset</code> and <code>clip_collate_fn</code>, add extensive prints for a single batch: shapes, structure, NaNs/Infs. Are these what models expect?</p>
                <p class="zh"><strong>健全性检查数据加载：</strong> 在 <code>GraphGigapathFeatureDataset</code> 和 <code>clip_collate_fn</code> 中，为单个批次添加详尽的打印语句：形状、结构、NaN/Inf值。这些是否符合模型的预期？</p>
                <p class="en"><strong>Gradient Checking:</strong> Are gradients flowing? Check for NaN/Inf gradients or zero gradients for learnable parameters.</p>
                <p class="zh"><strong>梯度检查：</strong> 梯度是否在流动？检查是否存在NaN/Inf梯度或可学习参数的梯度为零的情况。</p>
                 <div class="code-block"><code><span class="en"># After loss.backward() and before optimizer.step()</span>
<span class="zh"># 在 loss.backward() 之后，optimizer.step() 之前</span>
<span class="en">for name, param in clip_model.named_parameters():</span>
<span class="en">    if param.grad is not None:</span>
<span class="en">        if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():</span>
<span class="en">            if rank == 0: print(f"WARNING: NaN/Inf gradient in {name}")</span>
<span class="en">    elif param.requires_grad:</span>
<span class="en">        if rank == 0: print(f"WARNING: No gradient for learnable parameter {name}")</span>
</code></div>
            </div>
        </div>

        <hr class="section-divider">

        <h2>
            <span class="bilingual-title">
                <span class="en-title">Small-Scale Experiments to Pinpoint the Problem</span>
                <span class="zh-title">用于定位问题的小规模实验</span>
            </span>
        </h2>
        <div class="lang-toggle">
            <p class="en">Before making big changes, try these quick checks:</p>
            <p class="zh">在进行重大更改之前，请尝试以下快速检查：</p>
        </div>

        <ol>
            <li>
                <strong><span class="en">Overfit on a Tiny Batch:</span><span class="zh">在小批量数据上过拟合：</span></strong>
                <div class="lang-toggle">
                    <p class="en"><strong>Action:</strong> Take 1-2 graphs, 2-4 nodes per graph (a tiny batch of 2-8 items). Train for many iterations.</p>
                    <p class="zh"><strong>行动：</strong> 取1-2个图，每个图2-4个节点（一个2-8项的小批量）。训练多个迭代周期。</p>
                    <p class="en"><strong>Goal:</strong> Can the model memorize these and drive loss to near zero? If not, fundamental issue.</p>
                    <p class="zh"><strong>目标：</strong> 模型能否记住这些样本并将损失降至接近零？如果不能，则存在根本性问题。</p>
                </div>
            </li>
            <li>
                <strong><span class="en">Fake "Perfect Match" Task:</span><span class="zh">伪造“完美匹配”任务：</span></strong>
                <div class="lang-toggle">
                    <p class="en"><strong>Action:</strong> Create a dummy task where the "image feature" for a graph node is a copy of its own graph node embedding.</p>
                    <p class="zh"><strong>行动：</strong> 创建一个虚拟任务，其中图节点的“图像特征”是其自身图节点嵌入的副本。</p>
                    <p class="en"><strong>Goal:</strong> Model should trivially learn this; loss should plummet. If not, problem in core contrastive logic.</p>
                    <p class="zh"><strong>目标：</strong> 模型应该能够轻易学会这个任务；损失应该急剧下降。如果不是，则核心对比逻辑存在问题。</p>
                </div>
            </li>
            <li>
                <strong><span class="en">Simpler Models First:</span><span class="zh">先使用更简单的模型：</span></strong>
                <div class="lang-toggle">
                    <p class="en"><strong>Action:</strong> Replace GPSConv GNN with a very simple GNN (1-2 GCNConv layers) or even a per-node MLP.</p>
                    <p class="zh"><strong>行动：</strong> 用非常简单的GNN（1-2层GCNConv）甚至每个节点的MLP替换GPSConv GNN。</p>
                    <p class="en"><strong>Goal:</strong> Does a simpler model show any learning? If yes, complex GNN might be the issue. If no, more fundamental problem.</p>
                    <p class="zh"><strong>目标：</strong> 更简单的模型是否显示任何学习迹象？如果是，则复杂的GNN可能是问题所在。如果不是，则问题更根本。</p>
                </div>
            </li>
            <li>
                <strong><span class="en">Visualize Embeddings & Similarities:</span><span class="zh">可视化嵌入和相似性：</span></strong>
                <div class="lang-toggle">
                    <p class="en"><strong>Action:</strong> After a few hundred steps, get <code>image_embeddings</code> and <code>text_embeddings</code> (graph embeddings). Calculate cosine similarity matrix. Are diagonal elements (positives) higher than off-diagonals? Log average similarity of positive vs. negative pairs.</p>
                    <p class="zh"><strong>行动：</strong> 几百步之后，获取 <code>image_embeddings</code> 和 <code>text_embeddings</code>（图嵌入）。计算余弦相似度矩阵。对角线元素（正样本）是否高于非对角线元素？记录正负样本对的平均相似度。</p>
                    <p class="en"><strong>Goal:</strong> See if there's *any* separation, even if loss doesn't reflect it strongly yet.</p>
                    <p class="zh"><strong>目标：</strong> 查看是否存在<em>任何</em>分离，即使损失尚未强烈反映出来。</p>
                </div>
            </li>
        </ol>

        <hr class="section-divider">
        <h2>
            <span class="bilingual-title">
                <span class="en-title">Summary of Key Initial Actions</span>
                <span class="zh-title">关键初步行动总结</span>
            </span>
        </h2>
        <div class="lang-toggle">
            <ol>
                <li><span class="en"><strong>Verify Data:</strong> Double-check alignment and sanity of graph-node-to-GigaPath-feature pairing. Your dataset construction logic for <code>constructed_gp_feature_path</code> is critical. Ensure it perfectly matches how GigaPath features were saved (subdirectories, filenames like <code>SAMPLE_ID_X_Y.pt</code>).</span><span class="zh"><strong>验证数据：</strong> 仔细检查图节点到GigaPath特征配对的对齐情况和健全性。您用于构建 <code>constructed_gp_feature_path</code> 的数据集逻辑至关重要。确保它与GigaPath特征的保存方式（子目录、类似 <code>SAMPLE_ID_X_Y.pt</code> 的文件名）完全匹配。</span></li>
                <li><span class="en"><strong>Simplify & Overfit:</strong> Try the tiny batch overfitting test.</span><span class="zh"><strong>简化与过拟合：</strong> 尝试小批量过拟合测试。</span></li>
                <li><span class="en"><strong>Check Gradients & LR:</strong> Ensure gradients are flowing and try a significantly lower learning rate.</span><span class="zh"><strong>检查梯度和学习率：</strong> 确保梯度正常流动，并尝试大幅降低学习率。</span></li>
                <li><span class="en"><strong>Monitor <code>logit_scale</code>:</strong> Add clipping for stability.</span><span class="zh"><strong>监控 <code>logit_scale</code>：</strong> 添加裁剪以确保稳定性。</span></li>
            </ol>
            <p class="en">Start with these, and the behavior will give you strong clues about where the problem lies. Good luck!</p>
            <p class="zh">从这些步骤开始，模型的行为将为您提供有关问题所在的有力线索。祝您好运！</p>
        </div>

    </div>
</body>
</html>