{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import skimage.io as io\n",
    "import random\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/public/home/jijh/diffusion_project/ADiffusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.data_process import extract_patches, create_graph_data_dict, construct_affinity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    \"\"\"Initialize random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# Set random seed for reproducibility\n",
    "random_seed = 0\n",
    "seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "file_dir = \"/public/home/jijh/st_project/cellbin_analysis/spatial_variation/wx_data/\"  # Directory containing the data files\n",
    "files = os.listdir(file_dir)  # List all files in the directory\n",
    "files = [i for i in files if i.endswith(\".h5ad\") and \"month\" in i]  # Filter files to include only those ending with \".h5ad\" and containing \"month\"\n",
    "file_paths = [os.path.join(file_dir, i) for i in files]  # Create full file paths for the filtered files\n",
    "adatas = {}  # Initialize an empty dictionary to store AnnData objects\n",
    "\n",
    "# Read each file and store the AnnData object in the dictionary\n",
    "for i in range(len(file_paths)):\n",
    "    adatas[files[i].split(\".\")[0]] = sc.read(file_paths[i])\n",
    "\n",
    "# Preprocess each AnnData object\n",
    "for key in tqdm(adatas.keys(), desc=\"Preprocessing datasets\"):\n",
    "    sc.pp.normalize_total(adatas[key], target_sum=1e4)  # Normalize counts per cell\n",
    "    sc.pp.log1p(adatas[key])  # Logarithmize the data\n",
    "    adatas[key].layers[\"raw\"] = adatas[key].X.copy()  # Store the raw data in the \"raw\" layer\n",
    "    sc.pp.scale(adatas[key])  # Scale the data to unit variance\n",
    "    sc.tl.pca(adatas[key], svd_solver=\"arpack\")  # Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GPU",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
